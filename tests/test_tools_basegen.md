# Codebase Snapshot: tools
Generated by: base_gen_agent_v1.1 on 2025-06-25 05:38:43 
Source Directory (resolved): `/home/luvai/MINDXbuilds/production/mindX/tools`

## Directory Structure

```text
tools/
  __init__.py
  agent_factory_tool.py
  audit_and_improve_tool.py
  augmentic_intelligence_tool.py
  base_gen_agent.py
  cli_command_tool.py
  identity_sync_tool.py
  llm_tool_manager.py
  memory_analysis_tool.py
  note_taking_tool.py
  optimized_audit_gen_agent.py
  registry_manager_tool.py
  registry_sync_tool.py
  shell_command_tool.py
  summarization_tool.py
  system_analyzer_tool.py
  system_health_tool.py
  tool_factory_tool.py
  tool_registry_manager.py
  tree_agent.py
  web_search_tool.py
```

## File Contents

### `__init__.py`

```python

```

### `agent_factory_tool.py`

```python
# mindx/tools/agent_factory_tool.py
"""
Agent Factory Tool for MindX.
This tool enables the BDI agent to create new agents with proper lifecycle management.
"""

import json
import time
from pathlib import Path
from typing import Dict, Any, Tuple, Optional

from core.bdi_agent import BaseTool
from core.id_manager_agent import IDManagerAgent
from agents.guardian_agent import GuardianAgent
from agents.memory_agent import MemoryAgent
from utils.config import Config, PROJECT_ROOT
from utils.logging_config import get_logger

logger = get_logger(__name__)

class AgentFactoryTool(BaseTool):
    """Tool for creating new agents with full lifecycle management."""
    
    def __init__(self, 
                 memory_agent: MemoryAgent,
                 coordinator_ref: Optional[Any] = None,
                 guardian_ref: Optional[GuardianAgent] = None,
                 config: Optional[Config] = None,
                 **kwargs):
        super().__init__(config=config, **kwargs)
        self.memory_agent = memory_agent
        self.coordinator_ref = coordinator_ref
        self.guardian_ref = guardian_ref
        self.config = config or Config()
        
        # Agent templates directory
        self.agent_templates_dir = PROJECT_ROOT / "agents" / "templates"
        self.agent_templates_dir.mkdir(parents=True, exist_ok=True)
        
        self.log_prefix = "AgentFactoryTool:"
        logger.info(f"{self.log_prefix} Initialized with agent creation capabilities.")

    async def execute(self, 
                     action: str,
                     agent_type: str = None,
                     agent_id: str = None,
                     agent_config: Optional[Dict[str, Any]] = None,
                     **kwargs) -> Tuple[bool, Any]:
        """Execute agent factory operations."""
        try:
            if action == "create_agent":
                return await self._create_agent(agent_type, agent_id, agent_config or {})
            elif action == "validate_agent":
                return await self._validate_agent(agent_id)
            else:
                return False, f"Unknown action: {action}"
                
        except Exception as e:
            logger.error(f"{self.log_prefix} Error executing action '{action}': {e}", exc_info=True)
            return False, f"Agent factory error: {e}"

    async def _create_agent(self, agent_type: str, agent_id: str, agent_config: Dict[str, Any]) -> Tuple[bool, Any]:
        """Create a new agent with full lifecycle management."""
        logger.info(f"{self.log_prefix} Creating new agent: {agent_id} of type {agent_type}")
        
        try:
            # Step 1: Get ID Manager and create identity
            id_manager = await IDManagerAgent.get_instance()
            public_key, env_var_name = await id_manager.create_new_wallet(entity_id=agent_id)
            
            # Step 2: Guardian validation
            if self.guardian_ref:
                guardian_validation = await self._validate_with_guardian(agent_id, public_key)
                if not guardian_validation[0]:
                    return False, f"Guardian validation failed: {guardian_validation[1]}"
            
            # Step 3: Create agent workspace
            agent_workspace = self.memory_agent.get_agent_data_directory(agent_id)
            agent_workspace.mkdir(parents=True, exist_ok=True)
            
            # Step 4: Generate agent code
            agent_code_path = await self._generate_agent_code(agent_type, agent_id, agent_config)
            
            # Step 5: Register with coordinator
            if self.coordinator_ref:
                registration_result = await self.coordinator_ref.create_and_register_agent(
                    agent_type, agent_id, agent_config
                )
                if registration_result.get("status") != "SUCCESS":
                    return False, f"Coordinator registration failed: {registration_result}"
            
            # Step 6: Create agent metadata
            agent_metadata = {
                "agent_id": agent_id,
                "agent_type": agent_type,
                "public_key": public_key,
                "env_var_name": env_var_name,
                "workspace_path": str(agent_workspace),
                "code_path": str(agent_code_path) if agent_code_path else None,
                "created_at": time.time(),
                "created_by": "agent_factory_tool",
                "config": agent_config,
                "status": "active"
            }
            
            # Step 7: Save agent metadata
            metadata_path = agent_workspace / "agent_metadata.json"
            with metadata_path.open("w", encoding="utf-8") as f:
                json.dump(agent_metadata, f, indent=2)
            
            logger.info(f"{self.log_prefix} Successfully created agent {agent_id}")
            return True, agent_metadata
            
        except Exception as e:
            logger.error(f"{self.log_prefix} Failed to create agent {agent_id}: {e}", exc_info=True)
            return False, f"Agent creation failed: {e}"

    async def _validate_with_guardian(self, agent_id: str, public_key: str) -> Tuple[bool, Any]:
        """Validate new agent with Guardian agent."""
        try:
            if not self.guardian_ref:
                return True, "No guardian validation required"
            
            # Get challenge from guardian
            challenge = self.guardian_ref.get_challenge(agent_id)
            
            # Sign challenge with agent's private key
            id_manager = await IDManagerAgent.get_instance()
            signature = await id_manager.sign_message(agent_id, challenge)
            
            if not signature:
                return False, "Failed to sign challenge"
            
            # Verify with guardian
            private_key = await self.guardian_ref.get_private_key(agent_id, challenge, signature)
            
            if private_key:
                logger.info(f"{self.log_prefix} Guardian validation successful for {agent_id}")
                return True, "Guardian validation successful"
            else:
                return False, "Guardian validation failed"
                
        except Exception as e:
            logger.error(f"{self.log_prefix} Guardian validation error for {agent_id}: {e}")
            return False, f"Guardian validation error: {e}"

    async def _generate_agent_code(self, agent_type: str, agent_id: str, agent_config: Dict[str, Any]) -> Optional[Path]:
        """Generate agent code from template."""
        try:
            agent_class_name = f"{agent_id.replace('_', '').title()}Agent"
            agent_description = agent_config.get("description", f"Dynamically created {agent_type}")
            
            agent_code = f'''# mindx/agents/{agent_id}.py
"""
{agent_class_name} - Dynamically created agent.
Type: {agent_type}
Description: {agent_description}
"""

import time
from typing import Dict, Any, Optional

from core.id_manager_agent import IDManagerAgent
from agents.memory_agent import MemoryAgent
from utils.config import Config
from utils.logging_config import get_logger

logger = get_logger(__name__)

class {agent_class_name}:
    """Dynamically created {agent_type} agent."""
    
    def __init__(self, 
                 agent_id: str = "{agent_id}",
                 config: Optional[Config] = None,
                 memory_agent: Optional[MemoryAgent] = None,
                 **kwargs):
        self.agent_id = agent_id
        self.config = config or Config()
        self.memory_agent = memory_agent or MemoryAgent(config=self.config)
        self.log_prefix = f"{agent_class_name}:"
        
        # Initialize identity
        self._init_identity()
        
        logger.info(f"{{self.log_prefix}} Initialized agent {{self.agent_id}}")
    
    def _init_identity(self):
        """Initialize agent identity."""
        try:
            from core.id_manager_agent import IDManagerAgent
            id_manager = IDManagerAgent.get_instance()
            id_manager.create_new_wallet(entity_id=self.agent_id)
        except Exception as e:
            logger.error(f"{{self.log_prefix}} Failed to initialize identity: {{e}}")
    
    async def execute_task(self, task: str, context: Dict[str, Any] = None) -> Dict[str, Any]:
        """Execute a task assigned to this agent."""
        logger.info(f"{{self.log_prefix}} Executing task: {{task}}")
        
        try:
            # Basic task execution logic
            result = {{
                "status": "SUCCESS",
                "agent_id": self.agent_id,
                "task": task,
                "context": context or {{}},
                "result": f"Task '{{task}}' executed successfully",
                "timestamp": time.time()
            }}
            
            # Log to memory
            await self.memory_agent.save_timestampmemory(
                self.agent_id,
                "TASK_EXECUTION",
                result,
                importance="MEDIUM"
            )
            
            return result
            
        except Exception as e:
            logger.error(f"{{self.log_prefix}} Task execution failed: {{e}}")
            return {{
                "status": "ERROR",
                "agent_id": self.agent_id,
                "task": task,
                "error": str(e),
                "timestamp": time.time()
            }}

# Factory function for easy instantiation
async def create_{agent_id}(**kwargs) -> {agent_class_name}:
    """Factory function to create {agent_class_name} instance."""
    return {agent_class_name}(**kwargs)
'''
            
            # Save to agents directory
            agent_code_path = PROJECT_ROOT / "agents" / f"{agent_id}.py"
            with agent_code_path.open("w", encoding="utf-8") as f:
                f.write(agent_code)
            
            logger.info(f"{self.log_prefix} Generated agent code at {agent_code_path}")
            return agent_code_path
            
        except Exception as e:
            logger.error(f"{self.log_prefix} Failed to generate agent code: {e}")
            return None

    async def _validate_agent(self, agent_id: str) -> Tuple[bool, Any]:
        """Validate agent identity and workspace."""
        try:
            # Check if agent has valid identity
            id_manager = await IDManagerAgent.get_instance()
            public_key = await id_manager.get_public_address(agent_id)
            if not public_key:
                return False, "No valid identity found"
            
            # Check if agent workspace exists
            agent_workspace = self.memory_agent.get_agent_data_directory(agent_id)
            if not agent_workspace.exists():
                return False, "Agent workspace not found"
            
            # Check if agent code exists
            agent_code_path = PROJECT_ROOT / "agents" / f"{agent_id}.py"
            if not agent_code_path.exists():
                return False, "Agent code not found"
            
            return True, {
                "agent_id": agent_id,
                "public_key": public_key,
                "workspace_path": str(agent_workspace),
                "code_path": str(agent_code_path),
                "validation_status": "PASSED"
            }
            
        except Exception as e:
            logger.error(f"{self.log_prefix} Agent validation failed for {agent_id}: {e}")
            return False, f"Agent validation error: {e}"
```

### `audit_and_improve_tool.py`

```python
# mindx/tools/audit_and_improve_tool.py
"""
A tool for auditing and improving code, using a BaseGenAgent summary as context,
with a fallback to raw code for resilience.
"""
import json
from pathlib import Path
from typing import Dict, Any, Optional

from core.bdi_agent import BaseTool
from llm.llm_interface import LLMHandlerInterface
from utils.config import Config
from agents.memory_agent import MemoryAgent
from agents.automindx_agent import AutoMINDXAgent
from .base_gen_agent import BaseGenAgent

class AuditAndImproveTool(BaseTool):
    """
    A tool for auditing and improving code, using a BaseGenAgent summary as context,
    with a fallback to raw code for resilience.
    """

    def __init__(self, memory_agent: MemoryAgent, base_gen_agent: BaseGenAgent, automindx_agent: AutoMINDXAgent, config: Optional[Config] = None, llm_handler: Optional[LLMHandlerInterface] = None, **kwargs):
        super().__init__(config=config, llm_handler=llm_handler, **kwargs)
        self.memory_agent = memory_agent
        self.base_gen_agent = base_gen_agent
        self.automindx_agent = automindx_agent
        if not self.llm_handler:
            raise ValueError("AuditAndImproveTool requires an LLMHandler.")

    async def execute(self, target_path: str, prompt: str) -> Dict[str, Any]:
        """
        Audits and improves the code at the given path using a resilient, multi-step process.
        """
        workspace_dir = self.memory_agent.get_agent_data_directory("audit_and_improve_tool")
        context_content = ""
        context_source = ""
        status_details = "OK" # New variable to track operational status

        # Step 1: Attempt to generate and use a documentation snapshot as the primary context.
        try:
            self.logger.info(f"Attempting to generate BaseGen summary for {target_path}")
            summary_report = self.base_gen_agent.generate_markdown_summary(
                root_path_str=target_path,
                output_file_str=str(workspace_dir / f"analysis_context_{Path(target_path).name}.md")
            )
            if summary_report["status"] != "SUCCESS":
                raise ValueError(f"BaseGenAgent failed: {summary_report['message']}")
            
            summary_file_path = Path(summary_report["output_file"])
            with open(summary_file_path, "r", encoding="utf-8") as f:
                context_content = f.read()
            context_source = f"BaseGen Summary: {summary_file_path.name}"
            self.logger.info(f"Successfully used BaseGen summary as context.")

        except Exception as e:
            # Step 2: Fallback to using raw file content if BaseGen fails.
            self.logger.warning(f"BaseGen step failed ('{e}'). Falling back to raw file content for resilience.")
            status_details = "DEGRADED_CONTEXT_FALLBACK" # Update status
            path = Path(target_path)
            if not path.exists() or path.is_dir():
                return {"status": "ERROR", "message": f"Target path does not exist or is a directory: {target_path}"}
            try:
                with open(path, "r", encoding="utf-8") as f:
                    context_content = f.read()
                context_source = f"Raw File Content (Fallback): {path.name}"
            except Exception as read_e:
                return {"status": "ERROR", "message": f"Fallback failed: Could not read raw file '{target_path}': {read_e}"}

        # Step 3: Use the acquired context and the persona from AutoMINDX to generate the improvement.
        persona = self.automindx_agent.get_persona("AUDIT_AND_IMPROVE")
        if not persona:
            return {"status": "ERROR", "message": "Could not retrieve AUDIT_AND_IMPROVE persona from AutoMINDX."}

        full_prompt = (
            f"{persona}\n\n"
            f"**Improvement Request:** {prompt}\n\n"
            f"**Context from {context_source}:**\n```\n{context_content}\n```"
        )

        # Step 4: Generate and save the improved code.
        try:
            response_str = await self.llm_handler.generate_text(full_prompt, json_mode=True)
            response_data = json.loads(response_str)

            updated_code = response_data.get("updated_code")
            summary = response_data.get("summary")
            limitations = response_data.get("limitations")

            if not updated_code:
                return {"status": "ERROR", "message": "LLM did not provide updated code."}

            output_path = workspace_dir / f"improved_{Path(target_path).name}"
            with open(output_path, "w", encoding="utf-8") as f:
                f.write(updated_code)

            # Step 5: Log the successful operation.
            log_data = {
                "target_path": target_path,
                "prompt": prompt,
                "summary": summary,
                "limitations": limitations,
                "context_source": context_source,
                "output_path": str(output_path)
            }
            await self.memory_agent.log_process("audit_and_improve_tool_execution", log_data, {"agent_id": "audit_and_improve_tool"})

            return {
                "status": "SUCCESS",
                "status_details": status_details, # Include the operational status
                "summary": summary,
                "limitations": limitations,
                "output_path": str(output_path),
                "context_used": context_source
            }
        except Exception as e:
            return {"status": "ERROR", "message": f"An error occurred during the LLM improvement step: {e}"}
```

### `augmentic_intelligence_tool.py`

```python
# mindx/tools/augmentic_intelligence_tool.py
"""
Augmentic Intelligence Tool for MindX.
This tool provides the BDI agent with comprehensive access to all system capabilities
for self-improvement and agent/tool creation.
"""

import json
import time
import asyncio
from pathlib import Path
from typing import Dict, Any, Tuple, Optional, List

from core.bdi_agent import BaseTool
from core.id_manager_agent import IDManagerAgent
from agents.guardian_agent import GuardianAgent
from agents.memory_agent import MemoryAgent
from utils.config import Config, PROJECT_ROOT
from utils.logging_config import get_logger

logger = get_logger(__name__)

class AugmenticIntelligenceTool(BaseTool):
    """
    Comprehensive tool providing access to all MindX capabilities:
    - Agent creation and management
    - Tool creation and management
    - System orchestration
    - Self-improvement loops
    - Registry management
    """
    
    def __init__(self, 
                 memory_agent: MemoryAgent,
                 coordinator_ref: Optional[Any] = None,
                 mastermind_ref: Optional[Any] = None,
                 guardian_ref: Optional[GuardianAgent] = None,
                 config: Optional[Config] = None,
                 **kwargs):
        super().__init__(config=config, **kwargs)
        self.memory_agent = memory_agent
        self.coordinator_ref = coordinator_ref
        self.mastermind_ref = mastermind_ref
        self.guardian_ref = guardian_ref
        self.config = config or Config()
        
        # Set log prefix before initializing sub-tools
        self.log_prefix = "AugmenticIntelligenceTool:"
        
        # Initialize sub-tools
        self._init_sub_tools()
        
        logger.info(f"{self.log_prefix} Initialized with full system access.")

    def _init_sub_tools(self):
        """Initialize sub-tools for different capabilities."""
        try:
            # Import and initialize factory tools
            from tools.agent_factory_tool import AgentFactoryTool
            from tools.tool_factory_tool import ToolFactoryTool
            
            self.agent_factory = AgentFactoryTool(
                memory_agent=self.memory_agent,
                coordinator_ref=self.coordinator_ref,
                guardian_ref=self.guardian_ref,
                config=self.config
            )
            
            self.tool_factory = ToolFactoryTool(
                memory_agent=self.memory_agent,
                config=self.config
            )
            
            logger.info(f"{self.log_prefix} Sub-tools initialized successfully.")
            
        except Exception as e:
            logger.error(f"{self.log_prefix} Failed to initialize sub-tools: {e}")
            self.agent_factory = None
            self.tool_factory = None

    async def execute(self, 
                     capability: str,
                     action: str,
                     parameters: Optional[Dict[str, Any]] = None,
                     **kwargs) -> Tuple[bool, Any]:
        """
        Execute augmentic intelligence operations.
        
        Args:
            capability: The capability to use ('agent_management', 'tool_management', 'system_orchestration', 'self_improvement')
            action: The specific action to perform
            parameters: Parameters for the action
        """
        try:
            parameters = parameters or {}
            
            if capability == "agent_management":
                return await self._handle_agent_management(action, parameters)
            elif capability == "tool_management":
                return await self._handle_tool_management(action, parameters)
            elif capability == "system_orchestration":
                return await self._handle_system_orchestration(action, parameters)
            elif capability == "self_improvement":
                return await self._handle_self_improvement(action, parameters)
            elif capability == "registry_management":
                return await self._handle_registry_management(action, parameters)
            elif capability == "skills_management":
                return await self._handle_skills_management(action, parameters)
            else:
                return False, f"Unknown capability: {capability}"
                
        except Exception as e:
            logger.error(f"{self.log_prefix} Error executing {capability}.{action}: {e}", exc_info=True)
            return False, f"Augmentic intelligence error: {e}"

    async def _handle_agent_management(self, action: str, parameters: Dict[str, Any]) -> Tuple[bool, Any]:
        """Handle agent management operations."""
        if not self.agent_factory:
            return False, "Agent factory not available"
        
        if action == "create_agent":
            agent_type = parameters.get("agent_type")
            agent_id = parameters.get("agent_id")
            agent_config = parameters.get("agent_config", {})
            
            if not agent_type or not agent_id:
                return False, "Missing agent_type or agent_id"
            
            result = await self.agent_factory.execute("create_agent", agent_type, agent_id, agent_config)
            
            # If successful, add to BDI agent skills
            if result[0] and self.coordinator_ref:
                skills_result = await self._add_agent_to_skills(agent_id, agent_type, result[1])
                result[1]["skills_integration"] = skills_result
            
            return result
            
        elif action == "validate_agent":
            agent_id = parameters.get("agent_id")
            if not agent_id:
                return False, "Missing agent_id"
            return await self.agent_factory.execute("validate_agent", agent_id=agent_id)
            
        elif action == "list_agents":
            return await self._list_all_agents()
            
        else:
            return False, f"Unknown agent management action: {action}"

    async def _handle_tool_management(self, action: str, parameters: Dict[str, Any]) -> Tuple[bool, Any]:
        """Handle tool management operations."""
        if not self.tool_factory:
            return False, "Tool factory not available"
        
        if action == "create_tool":
            tool_id = parameters.get("tool_id")
            tool_config = parameters.get("tool_config", {})
            
            if not tool_id:
                return False, "Missing tool_id"
            
            result = await self.tool_factory.execute("create_tool", tool_id, tool_config)
            
            # If successful, reload tools registry for BDI agent
            if result[0]:
                reload_result = await self._reload_tools_registry()
                result[1]["registry_reload"] = reload_result
            
            return result
            
        elif action == "list_tools":
            return await self._list_all_tools()
            
        else:
            return False, f"Unknown tool management action: {action}"

    async def _handle_system_orchestration(self, action: str, parameters: Dict[str, Any]) -> Tuple[bool, Any]:
        """Handle system orchestration operations."""
        if action == "execute_command":
            command = parameters.get("command")
            args = parameters.get("args", {})
            
            if not command:
                return False, "Missing command"
            
            return await self._execute_system_command(command, args)
            
        elif action == "get_system_status":
            return await self._get_comprehensive_system_status()
            
        elif action == "coordinate_agents":
            agent_ids = parameters.get("agent_ids", [])
            task = parameters.get("task")
            
            if not task:
                return False, "Missing task"
            
            return await self._coordinate_multiple_agents(agent_ids, task)
            
        else:
            return False, f"Unknown system orchestration action: {action}"

    async def _handle_self_improvement(self, action: str, parameters: Dict[str, Any]) -> Tuple[bool, Any]:
        """Handle self-improvement operations."""
        if action == "analyze_performance":
            return await self._analyze_system_performance()
            
        elif action == "identify_improvements":
            focus_area = parameters.get("focus_area", "general")
            return await self._identify_improvement_opportunities(focus_area)
            
        elif action == "implement_improvement":
            improvement_id = parameters.get("improvement_id")
            improvement_config = parameters.get("improvement_config", {})
            
            if not improvement_id:
                return False, "Missing improvement_id"
            
            return await self._implement_improvement(improvement_id, improvement_config)
            
        elif action == "start_improvement_loop":
            loop_config = parameters.get("loop_config", {})
            return await self._start_self_improvement_loop(loop_config)
            
        else:
            return False, f"Unknown self-improvement action: {action}"

    async def _handle_registry_management(self, action: str, parameters: Dict[str, Any]) -> Tuple[bool, Any]:
        """Handle registry management operations."""
        if action == "sync_registries":
            return await self._sync_all_registries()
            
        elif action == "validate_identities":
            return await self._validate_all_identities()
            
        elif action == "update_registry":
            registry_type = parameters.get("registry_type")
            registry_data = parameters.get("registry_data", {})
            
            if not registry_type:
                return False, "Missing registry_type"
            
            return await self._update_registry(registry_type, registry_data)
            
        else:
            return False, f"Unknown registry management action: {action}"

    async def _handle_skills_management(self, action: str, parameters: Dict[str, Any]) -> Tuple[bool, Any]:
        """Handle skills management for BDI agent."""
        if action == "add_skill":
            skill_name = parameters.get("skill_name")
            skill_config = parameters.get("skill_config", {})
            
            if not skill_name:
                return False, "Missing skill_name"
            
            return await self._add_skill_to_bdi(skill_name, skill_config)
            
        elif action == "list_skills":
            return await self._list_bdi_skills()
            
        elif action == "update_skill":
            skill_name = parameters.get("skill_name")
            skill_config = parameters.get("skill_config", {})
            
            if not skill_name:
                return False, "Missing skill_name"
            
            return await self._update_bdi_skill(skill_name, skill_config)
            
        else:
            return False, f"Unknown skills management action: {action}"

    async def _add_agent_to_skills(self, agent_id: str, agent_type: str, agent_metadata: Dict[str, Any]) -> Tuple[bool, Any]:
        """Add newly created agent to BDI agent skills."""
        try:
            skill_config = {
                "agent_id": agent_id,
                "agent_type": agent_type,
                "capabilities": agent_metadata.get("capabilities", []),
                "public_key": agent_metadata.get("public_key"),
                "workspace_path": agent_metadata.get("workspace_path"),
                "created_at": agent_metadata.get("created_at"),
                "skill_type": "agent_delegation"
            }
            
            return await self._add_skill_to_bdi(f"delegate_to_{agent_id}", skill_config)
            
        except Exception as e:
            logger.error(f"{self.log_prefix} Failed to add agent to skills: {e}")
            return False, f"Skills integration error: {e}"

    async def _add_skill_to_bdi(self, skill_name: str, skill_config: Dict[str, Any]) -> Tuple[bool, Any]:
        """Add a skill to the BDI agent."""
        try:
            # Save skill to memory
            skill_data = {
                "skill_name": skill_name,
                "config": skill_config,
                "added_at": time.time(),
                "status": "active"
            }
            
            await self.memory_agent.save_timestampmemory(
                "bdi_agent_skills",
                "SKILL_ADDED",
                skill_data,
                importance="HIGH"
            )
            
            logger.info(f"{self.log_prefix} Added skill '{skill_name}' to BDI agent")
            return True, skill_data
            
        except Exception as e:
            logger.error(f"{self.log_prefix} Failed to add skill: {e}")
            return False, f"Skill addition error: {e}"

    async def _list_bdi_skills(self) -> Tuple[bool, Any]:
        """List all BDI agent skills."""
        try:
            # Get skills from memory
            skills_memories = await self.memory_agent.get_recent_timestampmemories(
                "bdi_agent_skills", count=100
            )
            
            skills = []
            for memory in skills_memories:
                if memory.get("memory_type") == "SKILL_ADDED":
                    skills.append(memory.get("content", {}))
            
            return True, {"skills": skills, "count": len(skills)}
            
        except Exception as e:
            logger.error(f"{self.log_prefix} Failed to list skills: {e}")
            return False, f"Skills listing error: {e}"

    async def _execute_system_command(self, command: str, args: Dict[str, Any]) -> Tuple[bool, Any]:
        """Execute system-level commands through mastermind."""
        try:
            if not self.mastermind_ref:
                return False, "Mastermind reference not available"
            
            # Map common commands to mastermind methods
            if command == "evolve":
                directive = args.get("directive")
                if not directive:
                    return False, "Missing directive for evolve command"
                result = await self.mastermind_ref.manage_mindx_evolution(top_level_directive=directive)
                return True, result
                
            elif command == "deploy":
                directive = args.get("directive")
                if not directive:
                    return False, "Missing directive for deploy command"
                result = await self.mastermind_ref.manage_agent_deployment(top_level_directive=directive)
                return True, result
                
            elif command == "analyze_codebase":
                path = args.get("path")
                focus = args.get("focus", "General analysis")
                if not path:
                    return False, "Missing path for codebase analysis"
                
                directive = f"Analyze codebase at '{path}' focusing on '{focus}'"
                result = await self.mastermind_ref.manage_mindx_evolution(top_level_directive=directive)
                return True, result
                
            else:
                return False, f"Unknown system command: {command}"
                
        except Exception as e:
            logger.error(f"{self.log_prefix} Failed to execute system command: {e}")
            return False, f"System command error: {e}"

    async def _get_comprehensive_system_status(self) -> Tuple[bool, Any]:
        """Get comprehensive system status."""
        try:
            status = {
                "timestamp": time.time(),
                "agents": {},
                "tools": {},
                "registries": {},
                "memory": {},
                "performance": {}
            }
            
            # Get agent registry status
            if self.coordinator_ref:
                status["agents"] = {
                    "registered_count": len(self.coordinator_ref.agent_registry),
                    "agents": list(self.coordinator_ref.agent_registry.keys())
                }
            
            # Get tools registry status
            tools_registry_path = PROJECT_ROOT / "data" / "config" / "official_tools_registry.json"
            if tools_registry_path.exists():
                with tools_registry_path.open("r") as f:
                    tools_registry = json.load(f)
                    status["tools"] = {
                        "registered_count": len(tools_registry.get("registered_tools", {})),
                        "tools": list(tools_registry.get("registered_tools", {}).keys())
                    }
            
            # Get memory status
            memory_stats = await self.memory_agent.get_memory_statistics()
            status["memory"] = memory_stats
            
            return True, status
            
        except Exception as e:
            logger.error(f"{self.log_prefix} Failed to get system status: {e}")
            return False, f"System status error: {e}"

    async def _start_self_improvement_loop(self, loop_config: Dict[str, Any]) -> Tuple[bool, Any]:
        """Start a self-improvement loop."""
        try:
            loop_id = f"improvement_loop_{int(time.time())}"
            
            # Default loop configuration
            default_config = {
                "interval_seconds": 3600,  # 1 hour
                "max_iterations": 10,
                "focus_areas": ["performance", "capabilities", "efficiency"],
                "auto_implement": False
            }
            
            config = {**default_config, **loop_config}
            
            # Start the improvement loop
            loop_task = asyncio.create_task(self._run_improvement_loop(loop_id, config))
            
            loop_info = {
                "loop_id": loop_id,
                "config": config,
                "started_at": time.time(),
                "status": "running"
            }
            
            # Save loop info to memory
            await self.memory_agent.save_timestampmemory(
                "self_improvement_loops",
                "LOOP_STARTED",
                loop_info,
                importance="HIGH"
            )
            
            logger.info(f"{self.log_prefix} Started self-improvement loop {loop_id}")
            return True, loop_info
            
        except Exception as e:
            logger.error(f"{self.log_prefix} Failed to start improvement loop: {e}")
            return False, f"Improvement loop error: {e}"

    async def _run_improvement_loop(self, loop_id: str, config: Dict[str, Any]):
        """Run the self-improvement loop."""
        try:
            iterations = 0
            max_iterations = config.get("max_iterations", 10)
            interval = config.get("interval_seconds", 3600)
            
            while iterations < max_iterations:
                logger.info(f"{self.log_prefix} Running improvement loop iteration {iterations + 1}")
                
                # Analyze performance
                performance_result = await self._analyze_system_performance()
                
                # Identify improvements
                improvements_result = await self._identify_improvement_opportunities("general")
                
                # Log iteration results
                iteration_data = {
                    "loop_id": loop_id,
                    "iteration": iterations + 1,
                    "performance_analysis": performance_result[1] if performance_result[0] else None,
                    "improvements_identified": improvements_result[1] if improvements_result[0] else None,
                    "timestamp": time.time()
                }
                
                await self.memory_agent.save_timestampmemory(
                    "self_improvement_loops",
                    "LOOP_ITERATION",
                    iteration_data,
                    importance="MEDIUM"
                )
                
                iterations += 1
                
                if iterations < max_iterations:
                    await asyncio.sleep(interval)
            
            # Mark loop as completed
            completion_data = {
                "loop_id": loop_id,
                "completed_at": time.time(),
                "total_iterations": iterations,
                "status": "completed"
            }
            
            await self.memory_agent.save_timestampmemory(
                "self_improvement_loops",
                "LOOP_COMPLETED",
                completion_data,
                importance="HIGH"
            )
            
            logger.info(f"{self.log_prefix} Completed self-improvement loop {loop_id}")
            
        except Exception as e:
            logger.error(f"{self.log_prefix} Error in improvement loop {loop_id}: {e}")

    async def _analyze_system_performance(self) -> Tuple[bool, Any]:
        """Analyze system performance."""
        try:
            # Get memory statistics
            memory_stats = await self.memory_agent.get_memory_statistics()
            
            # Get agent performance metrics
            agent_metrics = {}
            if self.coordinator_ref:
                for agent_id in self.coordinator_ref.agent_registry.keys():
                    agent_memories = await self.memory_agent.get_recent_timestampmemories(agent_id, count=10)
                    agent_metrics[agent_id] = {
                        "recent_activity_count": len(agent_memories),
                        "last_activity": agent_memories[0].get("timestamp") if agent_memories else None
                    }
            
            performance_analysis = {
                "timestamp": time.time(),
                "memory_stats": memory_stats,
                "agent_metrics": agent_metrics,
                "system_health": "healthy"  # Simplified for now
            }
            
            return True, performance_analysis
            
        except Exception as e:
            logger.error(f"{self.log_prefix} Failed to analyze performance: {e}")
            return False, f"Performance analysis error: {e}"

    async def _identify_improvement_opportunities(self, focus_area: str) -> Tuple[bool, Any]:
        """Identify improvement opportunities."""
        try:
            opportunities = []
            
            # Check for missing capabilities
            if focus_area in ["general", "capabilities"]:
                # Check if we have enough tools
                tools_registry_path = PROJECT_ROOT / "data" / "config" / "official_tools_registry.json"
                if tools_registry_path.exists():
                    with tools_registry_path.open("r") as f:
                        tools_registry = json.load(f)
                        tool_count = len(tools_registry.get("registered_tools", {}))
                        if tool_count < 20:  # Arbitrary threshold
                            opportunities.append({
                                "type": "capability_gap",
                                "description": "System could benefit from more specialized tools",
                                "priority": "medium",
                                "suggested_action": "create_specialized_tools"
                            })
                
                # Check if we have enough agents
                if self.coordinator_ref:
                    agent_count = len(self.coordinator_ref.agent_registry)
                    if agent_count < 10:  # Arbitrary threshold
                        opportunities.append({
                            "type": "agent_diversity",
                            "description": "System could benefit from more specialized agents",
                            "priority": "medium",
                            "suggested_action": "create_specialized_agents"
                        })
            
            # Check for performance issues
            if focus_area in ["general", "performance"]:
                memory_stats = await self.memory_agent.get_memory_statistics()
                if memory_stats.get("total_memories", 0) > 10000:  # Arbitrary threshold
                    opportunities.append({
                        "type": "memory_optimization",
                        "description": "Memory system may need optimization for large datasets",
                        "priority": "high",
                        "suggested_action": "optimize_memory_system"
                    })
            
            improvement_analysis = {
                "focus_area": focus_area,
                "opportunities": opportunities,
                "timestamp": time.time(),
                "total_opportunities": len(opportunities)
            }
            
            return True, improvement_analysis
            
        except Exception as e:
            logger.error(f"{self.log_prefix} Failed to identify improvements: {e}")
            return False, f"Improvement identification error: {e}"

    async def _reload_tools_registry(self) -> Tuple[bool, Any]:
        """Reload tools registry for BDI agent."""
        try:
            # This would need to be implemented in the BDI agent
            # For now, just return success
            return True, "Tools registry reload requested"
            
        except Exception as e:
            logger.error(f"{self.log_prefix} Failed to reload tools registry: {e}")
            return False, f"Registry reload error: {e}"

    async def _list_all_agents(self) -> Tuple[bool, Any]:
        """List all agents in the system."""
        try:
            agents = {}
            
            if self.coordinator_ref:
                agents["coordinator_registry"] = self.coordinator_ref.agent_registry
            
            # Also check agents directory
            agents_dir = PROJECT_ROOT / "agents"
            agent_files = []
            if agents_dir.exists():
                for agent_file in agents_dir.glob("*.py"):
                    if not agent_file.name.startswith("__"):
                        agent_files.append(agent_file.stem)
            
            agents["agent_files"] = agent_files
            
            return True, agents
            
        except Exception as e:
            logger.error(f"{self.log_prefix} Failed to list agents: {e}")
            return False, f"Agent listing error: {e}"

    async def _list_all_tools(self) -> Tuple[bool, Any]:
        """List all tools in the system."""
        try:
            tools = {}
            
            # Load tools registry
            tools_registry_path = PROJECT_ROOT / "data" / "config" / "official_tools_registry.json"
            if tools_registry_path.exists():
                with tools_registry_path.open("r") as f:
                    tools_registry = json.load(f)
                    tools["registry"] = tools_registry.get("registered_tools", {})
            
            # Also check tools directory
            tools_dir = PROJECT_ROOT / "tools"
            tool_files = []
            if tools_dir.exists():
                for tool_file in tools_dir.glob("*.py"):
                    if not tool_file.name.startswith("__"):
                        tool_files.append(tool_file.stem)
            
            tools["tool_files"] = tool_files
            
            return True, tools
            
        except Exception as e:
            logger.error(f"{self.log_prefix} Failed to list tools: {e}")
            return False, f"Tool listing error: {e}"
```

### `base_gen_agent.py`

```python
# tttools/base_gen_agent.py
"""
BaseGenAgent (Codebase Documentation Generator): Generates Markdown
documentation from a codebase directory.
"""
import argparse
import fnmatch
import pathlib # Keep this for using pathlib.Path if preferred
from pathlib import Path # Explicitly import Path for direct use
import sys
import os
import json
from typing import List, Optional, Dict, Tuple, Any
from datetime import datetime
import copy

# Requires: pip install pathspec
try:
    import pathspec
except ImportError: # pragma: no cover
    print("CRITICAL ERROR: 'pathspec' library not found. Please run 'pip install pathspec'", file=sys.stderr)
    pathspec = None


# Import from sibling top-level package 'utils'
# This assumes 'tools' and 'utils' are sibling directories under PROJECT_ROOT
# and PROJECT_ROOT is in sys.path
try:
    from utils.config import Config, PROJECT_ROOT
    from utils.logging_config import get_logger
    from core.belief_system import BeliefSystem, BeliefSource
    from agents.memory_agent import MemoryAgent
    logger = get_logger(__name__)
except ImportError as e: # pragma: no cover
    # Fallback if run standalone or utils not found, very basic logging
    import logging
    logging.basicConfig(level=logging.INFO, format='[%(levelname)s] %(name)s: %(message)s')
    logger = logging.getLogger(__name__)
    logger.warning(f"Could not import from 'utils' package ({e}). Using fallback PROJECT_ROOT and basic Config.")
    # Try to determine PROJECT_ROOT assuming this file is in /tools/
    # This makes it /home/luvai/mindX if structure is mindX/tools/base_gen_agent.py
    PROJECT_ROOT = Path(__file__).resolve().parent.parent
    class Config:
        def get(self, key, default=None):
            # Provide minimal defaults if global Config is not available
            if key == "base_gen_agent.config_file_path": return None
            return default


class BaseGenAgent:
    # Default path if no override is given AND the global Config doesn't specify one for it.
    # This should align with where your main basegen_config.json is.
    DEFAULT_AGENT_CONFIG_FILE_PATH_RELATIVE = Path("data") / "config" / "basegen_config.json"

    INTERNAL_FALLBACK_CONFIG_DATA: Dict[str, Any] = {
        "HARD_CODED_EXCLUDES": [
            "*.md", "*.txt", "*.pdf", "*.doc", "*.docx", "*.odt", "*.rtf",
            "*.png", "*.jpg", "*.jpeg", "*.gif", "*.bmp", "*.tiff", "*.svg", "*.ico", "*.webp",
            "*.mp3", "*.wav", "*.ogg", "*.flac", "*.aac", "*.mp4", "*.mov", "*.avi", "*.mkv", "*.webm", "*.flv",
            "*.zip", "*.tar", "*.tar.gz", "*.tar.bz2", "*.rar", "*.7z", "*.gz", "*.bz2", "*.xz",
            "*.o", "*.so", "*.a", "*.dylib", "*.dll", "*.exe", "*.com", "*.msi", "*.deb", "*.rpm", "*.app",
            "*.class", "*.jar", "*.war", "*.ear", "*.pyc", "*.pyo", "*.pyd",
            "__pycache__/", ".pytest_cache/", ".mypy_cache/", ".ruff_cache/", "build/", "dist/", "target/",
            "package-lock.json", "yarn.lock", "poetry.lock", "Pipfile.lock", "composer.lock",
            "node_modules/", "bower_components/", "vendor/", "vendors/",
            "venv/", ".venv/", "env/", ".env", ".env.*",
            "output/", "out/", "bin/", "obj/", ".git/", ".hg/", ".svn/", ".bzr/",
            ".DS_Store", "Thumbs.db", "*.log", "*.log.*", "*.tmp", "*.temp", "*.swp", "*.swo",
            ".idea/", ".vscode/", "*.sublime-project", "*.sublime-workspace",
            "coverage.xml", ".coverage", "nosetests.xml", "pytestdebug.log",
            "*.bak", "*.old", "*.orig", ".gitattributes", ".gitmodules",
            "LICENSE", "LICENSE.*", "CONTRIBUTING.md", "CODE_OF_CONDUCT.md", "SECURITY.md",
            "poetry.toml", "setup.cfg", "MANIFEST.in", "mkdocs.yml"
        ],
        "LANGUAGE_MAPPING": {
            ".py": "python", ".js": "javascript", ".jsx": "javascript", ".ts": "typescript", ".tsx": "typescript",
            ".java": "java", ".kt": "kotlin", ".swift": "swift", ".c": "c", ".h": "c", ".cpp": "cpp", ".hpp": "cpp",
            ".cs": "csharp", ".go": "go", ".rs": "rust", ".rb": "ruby", ".php": "php", ".sh": "bash",
            ".html": "html", ".css": "css", ".scss": "scss", ".json": "json", ".yaml": "yaml", ".yml": "yaml",
            ".xml": "xml", ".sql": "sql", ".dockerfile": "dockerfile", "dockerfile": "dockerfile",
            ".md": "markdown", ".rst": "rst", ".gitignore":"gitignore",
        },
        "base_gen_agent_settings": {
            "max_file_size_kb_for_inclusion": 1024,
            "default_output_filename_stem": "codebase_snapshot",
            "output_subdir_relative_to_project": "mindX/memory/generated_docs/codebase_snapshots"
        }
    }

    def __init__(self, memory_agent: MemoryAgent, config_file_path_override_str: Optional[str] = None, agent_id: str = "base_gen_agent_v1.1", belief_system: Optional[BeliefSystem] = None):
        self.agent_id = agent_id
        self.belief_system = belief_system
        self.memory_agent = memory_agent
        self.log_prefix = f"[{self.agent_id}]"

        # Ensure the agent's data directory exists upon initialization
        self.data_dir = self.memory_agent.get_agent_data_directory(self.agent_id)

        global_cfg = Config()

        if config_file_path_override_str:
            self.agent_config_file_path = Path(config_file_path_override_str).resolve()
            logger.info(f"{self.log_prefix} Using specified config file: '{self.agent_config_file_path}'")
        else:
            default_path_from_global_cfg = global_cfg.get("base_gen_agent.config_file_path")
            if default_path_from_global_cfg:
                self.agent_config_file_path = (PROJECT_ROOT / default_path_from_global_cfg).resolve()
            else:
                self.agent_config_file_path = (PROJECT_ROOT / self.DEFAULT_AGENT_CONFIG_FILE_PATH_RELATIVE).resolve()
            logger.info(f"{self.log_prefix} Using resolved config file path: '{self.agent_config_file_path}'")

        self.config_data = self._load_and_merge_config_from_file()
        max_file_kb = self.get_agent_setting('max_file_size_kb_for_inclusion', 1024)
        logger.info(f"{self.log_prefix} Initialized. Config source: '{self.agent_config_file_path}'. Max file size: {max_file_kb}KB.")

    def get_agent_setting(self, key: str, default_value: Any = None) -> Any:
        return self.config_data.get("base_gen_agent_settings", {}).get(key, default_value)

    def _load_and_merge_config_from_file(self) -> Dict[str, Any]:
        current_config = copy.deepcopy(self.INTERNAL_FALLBACK_CONFIG_DATA)
        if self.agent_config_file_path.exists() and self.agent_config_file_path.is_file():
            try:
                with self.agent_config_file_path.open("r", encoding="utf-8") as f:
                    loaded_config_from_file = json.load(f)
                self._deep_update_dict(current_config, loaded_config_from_file)
                logger.info(f"{self.log_prefix} Loaded and merged agent config from '{self.agent_config_file_path}'")
            except Exception as e: # pragma: no cover
                logger.error(f"{self.log_prefix} Error reading/parsing config file '{self.agent_config_file_path}': {e}. Using internal fallback defaults only.")
                current_config = copy.deepcopy(self.INTERNAL_FALLBACK_CONFIG_DATA)
        else:
             logger.warning(f"{self.log_prefix} Agent config file '{self.agent_config_file_path}' not found. Using internal fallback defaults. Consider creating the file with desired settings.")
        return current_config

    def _save_agent_config_to_file(self) -> bool: # pragma: no cover
        try:
            self.memory_agent.save_memory(
                memory_type="config",
                category="bdi_agent",
                data=self.config_data,
                metadata={"agent_id": self.agent_id}
            )
            logger.info(f"{self.log_prefix} Agent configuration saved to '{self.agent_config_file_path}'")
            return True
        except Exception as e:
            logger.error(f"{self.log_prefix} Error saving agent configuration to '{self.agent_config_file_path}': {e}", exc_info=True)
            return False

    def _deep_update_dict(self, target: Dict, source: Dict): # pragma: no cover
        for key, value in source.items():
            if isinstance(value, dict) and key in target and isinstance(target[key], dict):
                self._deep_update_dict(target[key], value)
            elif isinstance(value, list) and key in target and isinstance(target[key], list) and key == "HARD_CODED_EXCLUDES":
                existing_set = set(target[key])
                for item in value:
                    if item not in existing_set: target[key].append(item)
                target[key] = sorted(list(set(target[key])))
            else:
                target[key] = value

    def update_config_setting(self, key_path: str, new_value: Any, save_after: bool = True) -> bool: # pragma: no cover
        logger.info(f"{self.log_prefix} Attempting to update config: '{key_path}' with value (type: {type(new_value).__name__})")
        try:
            keys = key_path.split('.')
            d = self.config_data
            for key_part in keys[:-1]:
                d = d.setdefault(key_part, {})
                if not isinstance(d, dict):
                    logger.error(f"{self.log_prefix} Config update failed: Path part '{key_part}' in '{key_path}' is not a dictionary."); return False
            final_key = keys[-1]
            if final_key == "HARD_CODED_EXCLUDES" and isinstance(new_value, list) and \
               new_value and isinstance(new_value[0], dict) and "_LIST_OP_" in new_value[0]:
                op_dict = new_value.pop(0)
                operation = op_dict["_LIST_OP_"]
                items_to_operate = new_value
                current_list = d.get(final_key, [])
                if not isinstance(current_list, list): current_list = []
                if operation == "APPEND_UNIQUE":
                    for item in items_to_operate:
                        if item not in current_list: current_list.append(item)
                    d[final_key] = sorted(list(set(current_list)))
                elif operation == "REMOVE":
                    d[final_key] = [item for item in current_list if item not in items_to_operate]
                else:
                    logger.warning(f"{self.log_prefix} Unknown list op '{operation}' for '{key_path}'. Replacing list.")
                    d[final_key] = items_to_operate
            elif isinstance(new_value, dict) and final_key in d and isinstance(d[final_key], dict) and new_value.get("_MERGE_DEEP_", False):
                new_value_copy = new_value.copy(); new_value_copy.pop("_MERGE_DEEP_")
                self._deep_update_dict(d[final_key], new_value_copy)
            else:
                d[final_key] = new_value
            logger.info(f"{self.log_prefix} Config setting '{key_path}' updated in memory.")
            if save_after:
                return self._save_agent_config_to_file()
            return True
        except Exception as e:
            logger.error(f"{self.log_prefix} Failed to update config setting '{key_path}': {e}", exc_info=True)
            return False

    def _guess_language(self, file_extension: str) -> str: # pragma: no cover
        ext = file_extension.lower()
        if not ext.startswith('.'): ext = '.' + ext
        mapping = self.config_data.get("LANGUAGE_MAPPING", self.INTERNAL_FALLBACK_CONFIG_DATA["LANGUAGE_MAPPING"])
        return mapping.get(ext, '')

    def _load_gitignore_specs(self, root_path: Path):
        if pathspec is None:
            logger.error(f"{self.log_prefix} 'pathspec' library not available. Cannot process .gitignore files.")
            return None
        all_patterns: List[str] = []
        try:
            for gitignore_file_path in root_path.rglob(".gitignore"):
                try: lines = gitignore_file_path.read_text(encoding="utf-8").splitlines()
                except Exception as e_read: logger.warning(f"{self.log_prefix} Could not read {gitignore_file_path}: {e_read}"); continue
                try: gitignore_dir_relative_to_root = gitignore_file_path.parent.relative_to(root_path)
                except ValueError: gitignore_dir_relative_to_root = Path(".")

                for line in lines:
                    line = line.strip()
                    if not line or line.startswith("#"): continue
                    if gitignore_dir_relative_to_root != Path("."):
                        if line.startswith('/'):
                            all_patterns.append((gitignore_dir_relative_to_root / line.lstrip('/')).as_posix())
                        else:
                            all_patterns.append((gitignore_dir_relative_to_root / line).as_posix())
                    else:
                         all_patterns.append(line)

            if (root_path / ".git").is_dir(): all_patterns.append("/.git/")
            if all_patterns:
                logger.debug(f"{self.log_prefix} Loaded {len(all_patterns)} patterns from .gitignore files under {root_path}.")
                return pathspec.PathSpec.from_lines(pathspec.patterns.GitWildMatchPattern, all_patterns)
            else: logger.debug(f"{self.log_prefix} No .gitignore patterns found or loaded for {root_path}."); return None
        except Exception as e: logger.error(f"{self.log_prefix} Error loading .gitignore for {root_path}: {e}", exc_info=True); return None

    def _should_include_file( self, file_abs_path: Path, root_path: Path,
        include_glob_patterns: Optional[List[str]], user_exclude_glob_patterns: Optional[List[str]],
        gitignore_spec: Optional[Any], use_gitignore_rules: bool = True ) -> bool: # pragma: no cover
        try: relative_file_path_for_match = file_abs_path.relative_to(root_path)
        except ValueError: logger.warning(f"{self.log_prefix} File {file_abs_path} not under root {root_path}. Excluding."); return False

        path_for_gitignore_match = relative_file_path_for_match.as_posix()

        if use_gitignore_rules and gitignore_spec and gitignore_spec.match_file(path_for_gitignore_match):
            logger.debug(f"{self.log_prefix} Excluding '{path_for_gitignore_match}' by .gitignore.")
            return False

        hardcoded_excludes = self.config_data.get("HARD_CODED_EXCLUDES", self.INTERNAL_FALLBACK_CONFIG_DATA["HARD_CODED_EXCLUDES"])
        all_exclude_glob_patterns = list(set((user_exclude_glob_patterns or []) + hardcoded_excludes))

        if any(fnmatch.fnmatch(file_abs_path.name, pattern) or \
               fnmatch.fnmatch(path_for_gitignore_match, pattern) or \
               any(fnmatch.fnmatch(part, pattern.strip('/')) for part in relative_file_path_for_match.parts if pattern.endswith('/') or pattern.startswith('/'))
               for pattern in all_exclude_glob_patterns):
            logger.debug(f"{self.log_prefix} Excluding '{path_for_gitignore_match}' by custom/hardcoded exclude pattern.")
            return False

        if include_glob_patterns is not None:
            if not any(fnmatch.fnmatch(path_for_gitignore_match, pattern) or fnmatch.fnmatch(file_abs_path.name, pattern) for pattern in include_glob_patterns):
                logger.debug(f"{self.log_prefix} Excluding '{path_for_gitignore_match}' as it does not match any include pattern.")
                return False
        return True

    def _build_tree_dict(self, root_scan_path: Path, relative_file_paths_to_include: List[Path]) -> Dict[str, Any]: # pragma: no cover
        tree: Dict[str, Any] = {}
        for rel_path in sorted(relative_file_paths_to_include):
            parts = rel_path.parts; current_level = tree
            for part in parts[:-1]: current_level = current_level.setdefault(part, {})
            current_level[parts[-1]] = {}
        return tree

    def _format_tree_lines(self, tree_dict: Dict[str, Any], indent_str: str = "", is_root_level: bool = True) -> List[str]: # pragma: no cover
        lines = []
        sorted_keys = sorted(tree_dict.keys(), key=lambda k: (not isinstance(tree_dict[k], dict) or not tree_dict[k], k.lower()))
        for i, key in enumerate(sorted_keys):
            is_last_item_in_level = (i == len(sorted_keys) - 1)
            connector = "" if is_root_level else (" " if is_last_item_in_level else " ")
            new_indent_for_children = indent_str + ("    " if (is_root_level or is_last_item_in_level) else "   ")
            is_directory_node = bool(tree_dict[key])
            lines.append(f"{indent_str}{connector}{key}{'/' if is_directory_node else ''}")
            if is_directory_node:
                lines.extend(self._format_tree_lines(tree_dict[key], new_indent_for_children, is_root_level=False))
        return lines

    def execute(
        self, root_path_str: str, output_file_str: Optional[str] = None,
        include_patterns: Optional[List[str]] = None, user_exclude_patterns: Optional[List[str]] = None,
        use_gitignore: bool = True ) -> Tuple[bool, Dict[str, Any]]: # pragma: no cover
        return self.generate_markdown_summary(
            root_path_str=root_path_str,
            output_file_str=output_file_str,
            include_patterns=include_patterns,
            user_exclude_patterns=user_exclude_patterns,
            use_gitignore=use_gitignore
        )

    def generate_markdown_summary(
        self, root_path_str: str, output_file_str: Optional[str] = None,
        include_patterns: Optional[List[str]] = None, user_exclude_patterns: Optional[List[str]] = None,
        use_gitignore: bool = True ) -> Tuple[bool, Dict[str, Any]]: # pragma: no cover

        root_path = Path(root_path_str)
        if not root_path.is_absolute():
            if root_path_str.startswith('mindx/'):
                root_path = (PROJECT_ROOT / root_path_str).resolve()
            else:
                root_path = (PROJECT_ROOT / root_path_str).resolve()
        else:
            root_path = root_path.resolve()
        effective_output_file: Path
        if output_file_str:
            effective_output_file = Path(output_file_str)
            if not effective_output_file.is_absolute():
                 effective_output_file = (PROJECT_ROOT / effective_output_file).resolve()
        else:
            # Use the agent's data_dir which was ensured at init
            output_subdir = self.data_dir / "generated_docs"
            input_dir_name_slug = root_path.name.replace(" ", "_").replace("/", "_")
            default_stem = self.get_agent_setting("default_output_filename_stem", "codebase_snapshot")
            effective_output_file = output_subdir / f"{input_dir_name_slug}_{default_stem}.md"

        logger.info(f"{self.log_prefix} Documentation generation: Input='{root_path}', Output='{effective_output_file}'")
        if not root_path.is_dir(): err_msg = f"Input path '{root_path}' is not a valid directory."; logger.error(f"{self.log_prefix} {err_msg}"); return False, {"status": "ERROR", "message": err_msg, "output_file": None, "files_included": 0}

        gitignore_spec = self._load_gitignore_specs(root_path) if use_gitignore else None
        included_files_rel: List[Path] = []
        try:
            for item_abs in sorted(root_path.rglob("*")):
                if item_abs.is_file() and self._should_include_file(item_abs, root_path, include_patterns, user_exclude_patterns, gitignore_spec, use_gitignore):
                    included_files_rel.append(item_abs.relative_to(root_path))
        except Exception as e_scan: err_msg = f"Error scanning directory '{root_path}': {e_scan}"; logger.error(f"{self.log_prefix} {err_msg}", exc_info=True); return False, {"status": "ERROR", "message": err_msg, "output_file": None, "files_included": 0}

        if not included_files_rel: logger.warning(f"{self.log_prefix} No files matched criteria in '{root_path}'. Output will be minimal.")

        tree_str = "[No files included to generate tree]"
        if included_files_rel:
            try:
                tree_dict = self._build_tree_dict(root_path, included_files_rel)
                tree_lines = self._format_tree_lines(tree_dict, indent_str="  ", is_root_level=True)
                tree_str = "\n".join([root_path.name + "/"] + tree_lines) if tree_lines else root_path.name + "/"
            except Exception as e_tree: err_msg = f"Error building directory tree: {e_tree}"; logger.error(f"{self.log_prefix} {err_msg}", exc_info=True); return False, {"status": "ERROR", "message": err_msg, "output_file": None, "files_included": 0}

        md_lines = [f"# Codebase Snapshot: {root_path.name}", f"Generated by: {self.agent_id} on {datetime.now().strftime('%Y-%m-%d %H:%M:%S %Z')}", f"Source Directory (resolved): `{root_path}`", "", "## Directory Structure", "", "```text", tree_str, "```", "", "## File Contents", ""]
        max_fsize_bytes = self.get_agent_setting("max_file_size_kb_for_inclusion", 1024) * 1024
        num_processed = 0
        for rel_p in included_files_rel:
            file_abs = root_path / rel_p; num_processed +=1
            lang_guess = self._guess_language(file_abs.suffix)
            md_lines.append(f"### `{rel_p.as_posix()}`\n\n```{lang_guess if lang_guess else ''}")
            try:
                file_size = file_abs.stat().st_size
                if file_size > max_fsize_bytes:
                    content = f"[File content omitted: Size ({file_size // 1024:,}KB) exceeds limit ({max_fsize_bytes // 1024:,}KB)]"
                    logger.warning(f"{self.log_prefix} Omitting content of '{rel_p.as_posix()}' due to size ({file_size} bytes).")
                else: content = file_abs.read_text(encoding="utf-8", errors="replace")
            except Exception as e_rc: content = f"[Error reading file '{rel_p.as_posix()}': {e_rc}]"; logger.warning(f"{self.log_prefix} {content}")
            md_lines.append(content.strip()); md_lines.append("```\n")

        try:
            effective_output_file.parent.mkdir(parents=True, exist_ok=True)
            with effective_output_file.open("w", encoding="utf-8") as f: f.write("\n".join(md_lines))
            msg = f"Markdown documentation generated successfully: {effective_output_file}"
            logger.info(f"{self.log_prefix} {msg}")
            
            if self.belief_system:
                belief_key = f"basegen.snapshot.{root_path.name}.{datetime.now().strftime('%Y%m%d%H%M%S')}"
                belief_value = {
                    "output_file": str(effective_output_file),
                    "files_included": num_processed,
                    "timestamp": time.time()
                }
                asyncio.create_task(self.belief_system.add_belief(belief_key, belief_value, 0.9, BeliefSource.DERIVED))

            return True, {"status": "SUCCESS", "message": msg, "output_file": str(effective_output_file), "files_included": num_processed}
        except Exception as e_w:
            err_msg = f"Error writing output Markdown to '{effective_output_file}': {e_w}"
            logger.error(f"{self.log_prefix} {err_msg}", exc_info=True)
            return False, {"status": "ERROR", "message": err_msg, "output_file": str(effective_output_file), "files_included": num_processed}

def main_cli(): # pragma: no cover
    parser = argparse.ArgumentParser(
        description="Generate Markdown documentation for a codebase directory.",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter )
    parser.add_argument("input_dir", help="Path to the codebase root directory to document.")
    parser.add_argument("-o", "--output", default=None, help="Output Markdown file path. If None, a default name is generated.")
    parser.add_argument("--include", nargs="+", default=None, help="Glob pattern(s) for files to explicitly include.")
    parser.add_argument("--exclude", nargs="+", default=None, help="Glob pattern(s) for files/directories to explicitly exclude.")
    parser.add_argument("--no-gitignore", action="store_true", help="Disable applying .gitignore file exclusions.")
    parser.add_argument("--config-file", default=None, help=f"Path to a custom agent JSON configuration file. Overrides default config path resolution.")
    parser.add_argument("--update-config", default=None, help="JSON string of settings to update in the agent's used config file. Example: '{\"base_gen_agent_settings.max_file_size_kb_for_inclusion\": 512}'")

    args = parser.parse_args()
    Config()

    try:
        # Create a MemoryAgent instance for standalone CLI usage
        memory_agent = MemoryAgent()
        agent = BaseGenAgent(memory_agent=memory_agent, config_file_path_override_str=args.config_file)
        if args.update_config:
            try:
                updates_dict = json.loads(args.update_config)
                if not isinstance(updates_dict, dict): raise ValueError("Update data must be a JSON object string.")
                all_ok = True
                for key_path, new_val in updates_dict.items():
                    if not agent.update_config_setting(key_path, new_val, save_after=False):
                        all_ok = False; logger.error(f"{agent.log_prefix} CLI: Failed to stage config update for key: {key_path}")
                if all_ok:
                    if agent._save_agent_config_to_file(): print(json.dumps({"status": "SUCCESS", "message": f"Agent configuration '{agent.agent_config_file_path}' updated successfully."}))
                    else: print(json.dumps({"status": "FAILURE", "message": f"Agent configuration updated in memory, but FAILED to save to '{agent.agent_config_file_path}'."})); sys.exit(1)
                else: print(json.dumps({"status": "FAILURE", "message": "One or more configuration updates failed in memory. Config file not saved."})); sys.exit(1)
                sys.exit(0)
            except Exception as e_cfg_update: print(json.dumps({"status": "ERROR", "message": f"Error processing --update-config: {e_cfg_update}"}), file=sys.stderr); sys.exit(2)

        output_file_path_str_for_gen: Optional[str] = args.output

        result = agent.generate_markdown_summary(
            root_path_str=args.input_dir, output_file_str=output_file_path_str_for_gen,
            include_patterns=args.include, user_exclude_patterns=args.exclude,
            use_gitignore=not args.no_gitignore,
        )
        print(json.dumps(result, indent=2)); sys.exit(0 if result["status"] == "SUCCESS" else 1)
    except SystemExit: raise
    except Exception as e:
        print(json.dumps({"status": "FATAL_ERROR", "message": str(e), "error_type": type(e).__name__}), file=sys.stderr)
        logger.critical(f"Fatal error in BaseGenAgent CLI: {e}", exc_info=True); sys.exit(2)

if __name__ == "__main__": # pragma: no cover
    Config()
    main_cli()
```

### `cli_command_tool.py`

```python
# mindx/tools/cli_command_tool.py
"""
A meta-tool that allows a BDI agent to execute the system's top-level CLI commands.
"""
from typing import Dict, Any, Optional

from core.bdi_agent import BaseTool
from orchestration.mastermind_agent import MastermindAgent
from orchestration.coordinator_agent import CoordinatorAgent

class CLICommandTool(BaseTool):
    """
    A tool that exposes the main CLI commands to an agent's planning process.
    """

    def __init__(self, mastermind: MastermindAgent, coordinator: CoordinatorAgent, **kwargs: Any):
        super().__init__(**kwargs)
        self.mastermind = mastermind
        self.coordinator = coordinator
        self.command_map = {
            "evolve": self.mastermind.manage_mindx_evolution,
            "deploy": self.mastermind.manage_agent_deployment,
            "agent_create": self.coordinator.create_and_register_agent,
            "agent_delete": self.coordinator.deregister_and_shutdown_agent,
            "agent_evolve": self.coordinator.handle_user_input, # This needs adaptation
        }

    async def execute(self, command_name: str, args: Dict[str, Any]) -> Dict[str, Any]:
        """
        Executes a CLI command by calling the appropriate agent method.
        """
        if command_name not in self.command_map:
            return {"status": "ERROR", "message": f"Unknown CLI command: {command_name}"}

        handler = self.command_map[command_name]
        
        # Special handling for agent_evolve which expects an Interaction object
        if command_name == "agent_evolve":
            # This is a simplification; a real implementation would need to construct
            # a proper Interaction object.
            return await handler(
                content=f"Evolve agent '{args.get('id')}' with directive: {args.get('directive')}",
                user_id=self.bdi_agent_ref.agent_id if self.bdi_agent_ref else "unknown",
                interaction_type="component_improvement",
                metadata={"target_component": args.get('id'), "analysis_context": args.get('directive')}
            )

        try:
            # Call the handler with the provided arguments
            result = await handler(**args)
            return {"status": "SUCCESS", "result": result}
        except Exception as e:
            self.logger.error(f"Error executing CLI command '{command_name}': {e}", exc_info=True)
            return {"status": "ERROR", "message": str(e)}
```

### `identity_sync_tool.py`

```python
#!/usr/bin/env python3
"""
Identity Sync Tool for mindX
Comprehensive identity management and synchronization for agents and tools
"""

import json
import time
import asyncio
from pathlib import Path
from typing import Dict, Any, List, Tuple, Optional

from core.bdi_agent import BaseTool
from core.id_manager_agent import IDManagerAgent
from core.belief_system import BeliefSystem
from agents.memory_agent import MemoryAgent
from utils.config import Config, PROJECT_ROOT
from utils.logging_config import get_logger

logger = get_logger(__name__)

class IdentitySyncTool(BaseTool):
    """
    Comprehensive identity synchronization tool for agents and tools.
    Manages cryptographic identities, registry updates, and validation.
    """
    
    def __init__(self, 
                 memory_agent: Optional[MemoryAgent] = None,
                 config: Optional[Config] = None,
                 **kwargs):
        super().__init__(config=config, **kwargs)
        self.memory_agent = memory_agent or MemoryAgent(config=self.config)
        self.config = config or Config()
        
        # Registry file paths
        self.agents_registry_path = PROJECT_ROOT / "data" / "config" / "official_agents_registry.json"
        self.tools_registry_path = PROJECT_ROOT / "data" / "config" / "official_tools_registry.json"
        
        self.log_prefix = "IdentitySyncTool:"
        logger.info(f"{self.log_prefix} Initialized with registry paths.")

    async def execute(self, action: str = "sync_all", **kwargs) -> Tuple[bool, Any]:
        """
        Execute identity synchronization operations.
        
        Args:
            action: Operation to perform
                - "sync_all": Sync both agents and tools
                - "sync_agents": Sync agent identities only
                - "sync_tools": Sync tool identities only
                - "validate": Validate all identities
                - "status": Get identity status report
        """
        logger.info(f"{self.log_prefix} Executing action: {action}")
        
        try:
            if action == "sync_all":
                return await self._sync_all_identities()
            elif action == "sync_agents":
                return await self._sync_agent_identities()
            elif action == "sync_tools":
                return await self._sync_tool_identities()
            elif action == "validate":
                return await self._validate_all_identities()
            elif action == "status":
                return await self._get_identity_status()
            else:
                return False, f"Unknown action: {action}"
                
        except Exception as e:
            logger.error(f"{self.log_prefix} Error executing {action}: {e}", exc_info=True)
            return False, f"Error: {e}"

    async def _sync_all_identities(self) -> Tuple[bool, Any]:
        """Sync both agent and tool identities."""
        logger.info(f"{self.log_prefix} Starting comprehensive identity sync...")
        
        results = {
            "agents": {"updated": 0, "errors": []},
            "tools": {"updated": 0, "errors": []},
            "total_duration": 0
        }
        
        start_time = time.time()
        
        # Sync agents
        agent_success, agent_result = await self._sync_agent_identities()
        if agent_success:
            results["agents"] = agent_result
        else:
            results["agents"]["errors"].append(str(agent_result))
        
        # Sync tools
        tool_success, tool_result = await self._sync_tool_identities()
        if tool_success:
            results["tools"] = tool_result
        else:
            results["tools"]["errors"].append(str(tool_result))
        
        results["total_duration"] = time.time() - start_time
        
        # Log comprehensive sync
        await self.memory_agent.log_process(
            process_name="identity_sync_comprehensive",
            data=results,
            metadata={"tool": "identity_sync_tool"}
        )
        
        success = agent_success and tool_success
        logger.info(f"{self.log_prefix} Comprehensive sync complete: {results}")
        return success, results

    async def _sync_agent_identities(self) -> Tuple[bool, Any]:
        """Sync agent identities with registry."""
        logger.info(f"{self.log_prefix} Syncing agent identities...")
        
        # Load agents registry
        if not self.agents_registry_path.exists():
            return False, f"Agents registry not found: {self.agents_registry_path}"
            
        with open(self.agents_registry_path, 'r') as f:
            registry = json.load(f)
        
        # Initialize ID Manager
        belief_system = BeliefSystem()
        id_manager = await IDManagerAgent.get_instance(
            agent_id="identity_sync_tool_service",
            belief_system=belief_system
        )
        
        results = {
            "updated": 0,
            "skipped": 0,
            "errors": [],
            "agents_processed": []
        }
        
        for agent_id, agent_info in registry["registered_agents"].items():
            try:
                identity = agent_info.get("identity", {})
                
                # Skip if already has valid identity
                if (identity.get("public_key") and 
                    identity.get("public_key") not in ["PENDING_SYNC", "0x1234567890123456789012345678901234567890"]):
                    results["skipped"] += 1
                    results["agents_processed"].append({
                        "agent_id": agent_id,
                        "status": "skipped",
                        "reason": "already_has_identity"
                    })
                    continue
                
                # Get or create public key
                public_key = await id_manager.get_public_address(agent_id)
                if not public_key:
                    public_key, env_var = await id_manager.create_new_wallet(entity_id=agent_id)
                
                # Generate signature
                signature_message = f"agent_registration:{agent_id}"
                signature = await id_manager.sign_message(agent_id, signature_message)
                
                if signature:
                    # Update registry
                    agent_info["identity"]["public_key"] = public_key
                    agent_info["identity"]["signature"] = signature
                    agent_info["last_updated"] = time.time()
                    
                    # Remove pending flags
                    agent_info.pop("registration_priority", None)
                    agent_info.pop("registration_notes", None)
                    
                    results["updated"] += 1
                    results["agents_processed"].append({
                        "agent_id": agent_id,
                        "status": "updated",
                        "public_key": public_key
                    })
                else:
                    results["errors"].append(f"Failed to generate signature for {agent_id}")
                    
            except Exception as e:
                error_msg = f"Error syncing {agent_id}: {e}"
                results["errors"].append(error_msg)
                logger.error(f"{self.log_prefix} {error_msg}")
        
        # Update registry metadata
        registry["last_updated_at"] = time.time()
        registry["last_updated_by"] = "identity_sync_tool"
        
        # Save updated registry
        with open(self.agents_registry_path, 'w') as f:
            json.dump(registry, f, indent=2)
        
        logger.info(f"{self.log_prefix} Agent sync complete: {results}")
        return True, results

    async def _sync_tool_identities(self) -> Tuple[bool, Any]:
        """Sync tool identities with registry."""
        logger.info(f"{self.log_prefix} Syncing tool identities...")
        
        # Load tools registry
        if not self.tools_registry_path.exists():
            return False, f"Tools registry not found: {self.tools_registry_path}"
            
        with open(self.tools_registry_path, 'r') as f:
            registry = json.load(f)
        
        # Initialize ID Manager
        belief_system = BeliefSystem()
        id_manager = await IDManagerAgent.get_instance(
            agent_id="identity_sync_tool_service",
            belief_system=belief_system
        )
        
        results = {
            "updated": 0,
            "skipped": 0,
            "errors": [],
            "tools_processed": []
        }
        
        for tool_id, tool_info in registry["registered_tools"].items():
            try:
                identity = tool_info.get("identity", {})
                
                # Skip if already has valid identity
                if (identity.get("public_key") and 
                    identity.get("public_key") not in [None, "PENDING_SYNC"]):
                    results["skipped"] += 1
                    results["tools_processed"].append({
                        "tool_id": tool_id,
                        "status": "skipped",
                        "reason": "already_has_identity"
                    })
                    continue
                
                # Create tool identity with tool_ prefix
                tool_entity_id = f"tool_{tool_id}"
                
                # Get or create public key
                public_key = await id_manager.get_public_address(tool_entity_id)
                if not public_key:
                    public_key, env_var = await id_manager.create_new_wallet(entity_id=tool_entity_id)
                
                # Generate signature for tool registration
                signature_message = f"tool_registration:{tool_id}:{tool_info.get('version', '1.0.0')}"
                signature = await id_manager.sign_message(tool_entity_id, signature_message)
                
                if signature:
                    # Update tool identity
                    if "identity" not in tool_info:
                        tool_info["identity"] = {}
                    
                    tool_info["identity"]["public_key"] = public_key
                    tool_info["identity"]["signature"] = signature
                    tool_info["identity"]["entity_id"] = tool_entity_id
                    tool_info["identity"]["signature_message"] = signature_message
                    
                    # Add identity metadata
                    tool_info["identity_enabled"] = True
                    tool_info["last_identity_update"] = time.time()
                    
                    results["updated"] += 1
                    results["tools_processed"].append({
                        "tool_id": tool_id,
                        "status": "updated",
                        "public_key": public_key
                    })
                else:
                    results["errors"].append(f"Failed to generate signature for {tool_id}")
                    
            except Exception as e:
                error_msg = f"Error syncing {tool_id}: {e}"
                results["errors"].append(error_msg)
                logger.error(f"{self.log_prefix} {error_msg}")
        
        # Update registry metadata
        registry["last_updated_at"] = time.time()
        registry["last_updated_by"] = "identity_sync_tool"
        registry["identity_sync_version"] = "1.0.0"
        
        # Save updated registry
        with open(self.tools_registry_path, 'w') as f:
            json.dump(registry, f, indent=2)
        
        logger.info(f"{self.log_prefix} Tool sync complete: {results}")
        return True, results

    async def _validate_all_identities(self) -> Tuple[bool, Any]:
        """Validate all agent and tool identities."""
        logger.info(f"{self.log_prefix} Validating all identities...")
        
        validation_results = {
            "agents": {"valid": 0, "invalid": 0, "issues": []},
            "tools": {"valid": 0, "invalid": 0, "issues": []},
            "validation_timestamp": time.time()
        }
        
        # Initialize ID Manager
        belief_system = BeliefSystem()
        id_manager = await IDManagerAgent.get_instance(
            agent_id="identity_sync_tool_service",
            belief_system=belief_system
        )
        
        # Validate agents
        if self.agents_registry_path.exists():
            with open(self.agents_registry_path, 'r') as f:
                agents_registry = json.load(f)
            
            for agent_id, agent_info in agents_registry["registered_agents"].items():
                identity = agent_info.get("identity", {})
                public_key = identity.get("public_key")
                signature = identity.get("signature")
                
                if public_key and signature:
                    # Verify identity exists in ID manager
                    stored_key = await id_manager.get_public_address(agent_id)
                    if stored_key == public_key:
                        validation_results["agents"]["valid"] += 1
                    else:
                        validation_results["agents"]["invalid"] += 1
                        validation_results["agents"]["issues"].append({
                            "agent_id": agent_id,
                            "issue": "public_key_mismatch",
                            "stored": stored_key,
                            "registry": public_key
                        })
                else:
                    validation_results["agents"]["invalid"] += 1
                    validation_results["agents"]["issues"].append({
                        "agent_id": agent_id,
                        "issue": "missing_identity_data"
                    })
        
        # Validate tools
        if self.tools_registry_path.exists():
            with open(self.tools_registry_path, 'r') as f:
                tools_registry = json.load(f)
            
            for tool_id, tool_info in tools_registry["registered_tools"].items():
                identity = tool_info.get("identity", {})
                public_key = identity.get("public_key")
                signature = identity.get("signature")
                entity_id = identity.get("entity_id", f"tool_{tool_id}")
                
                if public_key and signature:
                    # Verify identity exists in ID manager
                    stored_key = await id_manager.get_public_address(entity_id)
                    if stored_key == public_key:
                        validation_results["tools"]["valid"] += 1
                    else:
                        validation_results["tools"]["invalid"] += 1
                        validation_results["tools"]["issues"].append({
                            "tool_id": tool_id,
                            "issue": "public_key_mismatch",
                            "stored": stored_key,
                            "registry": public_key
                        })
                else:
                    validation_results["tools"]["invalid"] += 1
                    validation_results["tools"]["issues"].append({
                        "tool_id": tool_id,
                        "issue": "missing_identity_data"
                    })
        
        # Log validation results
        await self.memory_agent.log_process(
            process_name="identity_validation_complete",
            data=validation_results,
            metadata={"tool": "identity_sync_tool"}
        )
        
        total_issues = len(validation_results["agents"]["issues"]) + len(validation_results["tools"]["issues"])
        success = total_issues == 0
        
        logger.info(f"{self.log_prefix} Validation complete: {validation_results}")
        return success, validation_results

    async def _get_identity_status(self) -> Tuple[bool, Any]:
        """Get comprehensive identity status report."""
        logger.info(f"{self.log_prefix} Generating identity status report...")
        
        status = {
            "agents": {"total": 0, "with_identity": 0, "percentage": 0},
            "tools": {"total": 0, "with_identity": 0, "percentage": 0},
            "wallet_keys": 0,
            "report_timestamp": time.time()
        }
        
        # Check agents
        if self.agents_registry_path.exists():
            with open(self.agents_registry_path, 'r') as f:
                agents_registry = json.load(f)
            
            status["agents"]["total"] = len(agents_registry["registered_agents"])
            status["agents"]["with_identity"] = sum(
                1 for a in agents_registry["registered_agents"].values()
                if a.get("identity", {}).get("public_key") not in [None, "PENDING_SYNC"]
            )
            if status["agents"]["total"] > 0:
                status["agents"]["percentage"] = int(
                    status["agents"]["with_identity"] / status["agents"]["total"] * 100
                )
        
        # Check tools
        if self.tools_registry_path.exists():
            with open(self.tools_registry_path, 'r') as f:
                tools_registry = json.load(f)
            
            status["tools"]["total"] = len(tools_registry["registered_tools"])
            status["tools"]["with_identity"] = sum(
                1 for t in tools_registry["registered_tools"].values()
                if t.get("identity", {}).get("public_key") not in [None, "PENDING_SYNC"]
            )
            if status["tools"]["total"] > 0:
                status["tools"]["percentage"] = int(
                    status["tools"]["with_identity"] / status["tools"]["total"] * 100
                )
        
        # Check wallet keys
        wallet_path = PROJECT_ROOT / "data" / "identity" / ".wallet_keys.env"
        if wallet_path.exists():
            with open(wallet_path, 'r') as f:
                lines = [l.strip() for l in f if l.strip() and not l.startswith('#')]
            status["wallet_keys"] = len(lines)
        
        logger.info(f"{self.log_prefix} Status report: {status}")
        return True, status
```

### `llm_tool_manager.py`

```python
# mindx/tools/llm_tool_manager.py

import json
from pathlib import Path
from typing import Dict, Any, Tuple, Optional

from core.bdi_agent import BaseTool
from core.id_manager_agent import IDManagerAgent
from agents.memory_agent import MemoryAgent
from utils.logging_config import get_logger

logger = get_logger(__name__)

class LLMToolManager(BaseTool):
    """
    A tool for managing the LLM tools in the official tools registry.
    """
    def __init__(self, memory_agent: MemoryAgent, **kwargs: Any):
        super().__init__(memory_agent=memory_agent, **kwargs)
        self.tool_registry_path = Path(self.config.get("mastermind_agent.tools_registry_path", "data/config/official_tools_registry.json"))
        self.model_cards_path = self.memory_agent.get_agent_data_directory("a2a_model_cards")

    def _load_registry(self) -> Dict[str, Any]:
        """Loads the tool registry from a JSON file."""
        if self.tool_registry_path.exists():
            try:
                with self.tool_registry_path.open("r", encoding="utf-8") as f:
                    return json.load(f)
            except (json.JSONDecodeError, IOError) as e:
                logger.error(f"Error loading tool registry from {self.tool_registry_path}: {e}")
        return {"registered_tools": {}}

    def _save_registry(self, registry: Dict[str, Any]):
        """Saves the tool registry to a JSON file."""
        try:
            with self.tool_registry_path.open("w", encoding="utf-8") as f:
                json.dump(registry, f, indent=2)
        except IOError as e:
            logger.error(f"Error saving tool registry to {self.tool_registry_path}: {e}")

    async def _create_model_card(self, item_id: str, item_config: Dict[str, Any]) -> Dict[str, Any]:
        """Creates an A2A model card for a tool."""
        id_manager = await IDManagerAgent.get_instance()
        identity = await id_manager.get_identity(item_id)
        model_card = {
            "id": item_id,
            "name": item_config.get("name", item_id),
            "description": item_config.get("description", ""),
            "type": "tool",
            "version": item_config.get("version", "1.0.0"),
            "enabled": item_config.get("enabled", True),
            "commands": item_config.get("commands", []),
            "access_control": item_config.get("access_control", {}),
            "identity": {
                "public_address": identity.get("public_address") if identity else None,
                "signature": await id_manager.sign_message(item_id, json.dumps(item_config)) if identity else None,
            },
            "a2a_endpoint": f"https://mindx.internal/{item_id}/a2a",
        }
        return model_card

    async def execute(self, action: str, tool_id: str, tool_config: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Tuple[bool, Any]:
        """
        Executes an action on the LLM tools in the registry.

        Args:
            action: The action to perform. Can be 'add', 'remove', or 'update'.
            tool_id: The ID of the tool to act on.
            tool_config: The configuration of the tool. Required for 'add' and 'update' actions.

        Returns:
            A tuple containing a boolean indicating success and a result.
        """
        registry = self._load_registry()
        if action == "add":
            if not tool_config:
                return False, "Missing 'tool_config' parameter for 'add' action."
            if tool_id in registry["registered_tools"]:
                return False, f"Tool '{tool_id}' already exists."
            
            model_card = await self._create_model_card(tool_id, tool_config)
            tool_config["model_card"] = f"{tool_id}.json"
            self.model_cards_path.mkdir(parents=True, exist_ok=True)
            with (self.model_cards_path / f"{tool_id}.json").open("w", encoding="utf-8") as f:
                json.dump(model_card, f, indent=2)
            
            registry["registered_tools"][tool_id] = tool_config
            self._save_registry(registry)
            return True, f"Tool '{tool_id}' added successfully."
        elif action == "remove":
            if tool_id not in registry["registered_tools"]:
                return False, f"Tool '{tool_id}' not found."
            
            model_card_path = self.model_cards_path / registry["registered_tools"][tool_id]["model_card"]
            if model_card_path.exists():
                model_card_path.unlink()
            
            del registry["registered_tools"][tool_id]
            self._save_registry(registry)
            return True, f"Tool '{tool_id}' removed successfully."
        elif action == "update":
            if not tool_config:
                return False, "Missing 'tool_config' parameter for 'update' action."
            if tool_id not in registry["registered_tools"]:
                return False, f"Tool '{tool_id}' not found."

            model_card = await self._create_model_card(tool_id, tool_config)
            tool_config["model_card"] = f"{tool_id}.json"
            self.model_cards_path.mkdir(parents=True, exist_ok=True)
            with (self.model_cards_path / f"{tool_id}.json").open("w", encoding="utf-8") as f:
                json.dump(model_card, f, indent=2)

            registry["registered_tools"][tool_id] = tool_config
            self._save_registry(registry)
            return True, f"Tool '{tool_id}' updated successfully."
        else:
            return False, f"Unknown action: {action}"
```

### `memory_analysis_tool.py`

```python
# tools/memory_analysis_tool.py
"""
Memory Analysis Tool for MindX Self-Improvement

This tool provides comprehensive analysis of agent memory logs to identify
patterns, performance metrics, and improvement opportunities for the BDI agent.
"""
import asyncio
import json
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from collections import defaultdict, Counter
import re

from core.bdi_agent import BaseTool
from agents.memory_agent import MemoryAgent
from utils.config import Config, PROJECT_ROOT
from utils.logging_config import get_logger

logger = get_logger(__name__)

class MemoryAnalysisTool(BaseTool):
    """Comprehensive memory analysis tool for agent self-improvement."""

    def __init__(self, memory_agent: MemoryAgent, config: Optional[Config] = None, **kwargs):
        super().__init__(**kwargs)
        self.memory_agent = memory_agent
        self.config = config or Config()
        self.agent_id = "memory_analysis_tool"
        self.log_prefix = "MemoryAnalysisTool:"
        
        # Analysis categories
        self.analysis_categories = {
            "performance": ["success_rate", "execution_time", "error_patterns"],
            "behavior": ["decision_patterns", "goal_completion", "tool_usage"],
            "collaboration": ["agent_interactions", "coordination_patterns", "communication_efficiency"],
            "evolution": ["improvement_trends", "capability_growth", "adaptation_patterns"],
            "system_health": ["resource_usage", "error_frequency", "recovery_patterns"]
        }
        
        logger.info(f"{self.log_prefix} Memory analysis tool initialized")

    async def execute(self, action: str, **kwargs) -> Tuple[bool, Any]:
        """Execute memory analysis actions."""
        start_time = time.time()
        
        try:
            if action == "analyze_agent_performance":
                return await self._analyze_agent_performance(**kwargs)
            elif action == "analyze_system_patterns":
                return await self._analyze_system_patterns(**kwargs)
            elif action == "identify_improvement_opportunities":
                return await self._identify_improvement_opportunities(**kwargs)
            elif action == "generate_self_improvement_report":
                return await self._generate_self_improvement_report(**kwargs)
            elif action == "analyze_agent_collaboration":
                return await self._analyze_agent_collaboration(**kwargs)
            elif action == "track_evolution_progress":
                return await self._track_evolution_progress(**kwargs)
            elif action == "analyze_memory_patterns":
                return await self._analyze_memory_patterns(**kwargs)
            else:
                return False, f"Unknown action: {action}"
        except Exception as e:
            logger.error(f"{self.log_prefix} Action execution error: {e}")
            return False, f"Action execution failed: {e}"
        finally:
            # Log performance
            duration = time.time() - start_time
            await self._log_performance(action, duration, kwargs.get("agent_id") or "system")

    async def _analyze_agent_performance(self, agent_id: Optional[str] = None, days_back: int = 7) -> Tuple[bool, Any]:
        """Analyze performance metrics for specific agent or all agents."""
        try:
            analysis = {
                "timestamp": datetime.now().isoformat(),
                "analysis_type": "agent_performance",
                "days_back": days_back,
                "agents_analyzed": []
            }
            
            # Get agent list
            if agent_id:
                agents_to_analyze = [agent_id]
            else:
                agents_to_analyze = await self._get_active_agents(days_back)
            
            for target_agent in agents_to_analyze:
                agent_analysis = await self._analyze_single_agent_performance(target_agent, days_back)
                analysis["agents_analyzed"].append(agent_analysis)
            
            # Generate aggregate insights
            analysis["aggregate_insights"] = await self._generate_aggregate_insights(analysis["agents_analyzed"])
            
            # Log analysis completion
            await self.memory_agent.log_process(
                process_name="memory_analysis_agent_performance",
                data=analysis,
                metadata={"agent_id": self.agent_id}
            )
            
            return True, analysis
            
        except Exception as e:
            return False, f"Agent performance analysis failed: {e}"

    async def _analyze_single_agent_performance(self, agent_id: str, days_back: int) -> Dict[str, Any]:
        """Analyze performance for a single agent."""
        agent_analysis = {
            "agent_id": agent_id,
            "success_metrics": {},
            "error_patterns": {},
            "execution_patterns": {},
            "improvement_trends": {}
        }
        
        # Get memory records for the agent
        memories = await self._get_agent_memories(agent_id, days_back)
        
        # Analyze success rates
        agent_analysis["success_metrics"] = await self._analyze_success_rates(memories)
        
        # Analyze error patterns
        agent_analysis["error_patterns"] = await self._analyze_error_patterns(memories)
        
        # Analyze execution patterns
        agent_analysis["execution_patterns"] = await self._analyze_execution_patterns(memories)
        
        # Analyze improvement trends
        agent_analysis["improvement_trends"] = await self._analyze_improvement_trends(memories)
        
        return agent_analysis

    async def _analyze_system_patterns(self, days_back: int = 7) -> Tuple[bool, Any]:
        """Analyze system-wide patterns and interactions."""
        try:
            analysis = {
                "timestamp": datetime.now().isoformat(),
                "analysis_type": "system_patterns",
                "days_back": days_back,
                "interaction_patterns": {},
                "coordination_patterns": {},
                "resource_patterns": {},
                "evolution_patterns": {}
            }
            
            # Analyze interaction patterns
            analysis["interaction_patterns"] = await self._analyze_interaction_patterns(days_back)
            
            # Analyze coordination patterns
            analysis["coordination_patterns"] = await self._analyze_coordination_patterns(days_back)
            
            # Analyze resource patterns
            analysis["resource_patterns"] = await self._analyze_resource_patterns(days_back)
            
            # Analyze evolution patterns
            analysis["evolution_patterns"] = await self._analyze_evolution_patterns(days_back)
            
            # Log analysis completion
            await self.memory_agent.log_process(
                process_name="memory_analysis_system_patterns",
                data=analysis,
                metadata={"agent_id": self.agent_id}
            )
            
            return True, analysis
            
        except Exception as e:
            return False, f"System pattern analysis failed: {e}"

    async def _identify_improvement_opportunities(self, focus_area: str = "all") -> Tuple[bool, Any]:
        """Identify specific improvement opportunities based on memory analysis."""
        try:
            opportunities = {
                "timestamp": datetime.now().isoformat(),
                "focus_area": focus_area,
                "opportunities": [],
                "priority_matrix": {},
                "implementation_suggestions": []
            }
            
            # Get recent system performance data
            performance_data = await self._get_recent_performance_data()
            
            # Identify performance bottlenecks
            bottlenecks = await self._identify_performance_bottlenecks(performance_data)
            
            # Identify collaboration inefficiencies
            collaboration_issues = await self._identify_collaboration_inefficiencies(performance_data)
            
            # Identify capability gaps
            capability_gaps = await self._identify_capability_gaps(performance_data)
            
            # Identify resource optimization opportunities
            resource_optimizations = await self._identify_resource_optimizations(performance_data)
            
            # Consolidate opportunities
            all_opportunities = bottlenecks + collaboration_issues + capability_gaps + resource_optimizations
            
            # Prioritize opportunities
            opportunities["opportunities"] = await self._prioritize_opportunities(all_opportunities)
            opportunities["priority_matrix"] = await self._create_priority_matrix(opportunities["opportunities"])
            opportunities["implementation_suggestions"] = await self._generate_implementation_suggestions(opportunities["opportunities"])
            
            # Log analysis completion
            await self.memory_agent.log_process(
                process_name="memory_analysis_improvement_opportunities",
                data=opportunities,
                metadata={"agent_id": self.agent_id}
            )
            
            return True, opportunities
            
        except Exception as e:
            return False, f"Improvement opportunity analysis failed: {e}"

    async def _generate_self_improvement_report(self, target_agent: str = "bdi_agent") -> Tuple[bool, Any]:
        """Generate comprehensive self-improvement report for BDI agent."""
        try:
            report = {
                "timestamp": datetime.now().isoformat(),
                "target_agent": target_agent,
                "report_type": "self_improvement",
                "executive_summary": {},
                "detailed_analysis": {},
                "recommendations": {},
                "action_plan": {}
            }
            
            # Executive summary
            report["executive_summary"] = await self._generate_executive_summary(target_agent)
            
            # Detailed analysis sections
            report["detailed_analysis"] = {
                "performance_analysis": await self._analyze_single_agent_performance(target_agent, 30),
                "decision_quality": await self._analyze_decision_quality(target_agent),
                "tool_effectiveness": await self._analyze_tool_effectiveness(target_agent),
                "learning_progress": await self._analyze_learning_progress(target_agent),
                "collaboration_effectiveness": await self._analyze_collaboration_effectiveness(target_agent)
            }
            
            # Generate recommendations
            report["recommendations"] = await self._generate_recommendations(report["detailed_analysis"])
            
            # Create action plan
            report["action_plan"] = await self._create_action_plan(report["recommendations"])
            
            # Log report generation
            await self.memory_agent.log_process(
                process_name="memory_analysis_self_improvement_report",
                data=report,
                metadata={"agent_id": self.agent_id}
            )
            
            return True, report
            
        except Exception as e:
            return False, f"Self-improvement report generation failed: {e}"

    async def _get_agent_memories(self, agent_id: str, days_back: int) -> List[Dict[str, Any]]:
        """Retrieve memory records for an agent within the specified timeframe."""
        memories = []
        
        # Get STM memories
        stm_path = self.memory_agent.stm_path / agent_id
        if stm_path.exists():
            cutoff_date = datetime.now() - timedelta(days=days_back)
            
            for day_dir in stm_path.iterdir():
                if day_dir.is_dir():
                    try:
                        day_date = datetime.strptime(day_dir.name, "%Y%m%d")
                        if day_date >= cutoff_date:
                            for memory_file in day_dir.glob("*.memory.json"):
                                try:
                                    with memory_file.open('r') as f:
                                        memory_data = json.load(f)
                                        memories.append(memory_data)
                                except Exception as e:
                                    logger.warning(f"Failed to load memory file {memory_file}: {e}")
                    except ValueError:
                        # Skip directories that don't match date format
                        continue
        
        return memories

    async def _analyze_success_rates(self, memories: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Analyze success rates from memory records."""
        success_metrics = {
            "total_operations": len(memories),
            "successful_operations": 0,
            "failed_operations": 0,
            "success_rate": 0.0,
            "success_by_process": {},
            "failure_reasons": Counter()
        }
        
        process_stats = defaultdict(lambda: {"total": 0, "success": 0})
        
        for memory in memories:
            content = memory.get("content", {})
            process_name = content.get("process_name", "unknown")
            
            # Determine success based on content
            is_success = self._determine_operation_success(content)
            
            process_stats[process_name]["total"] += 1
            if is_success:
                success_metrics["successful_operations"] += 1
                process_stats[process_name]["success"] += 1
            else:
                success_metrics["failed_operations"] += 1
                # Extract failure reason
                failure_reason = self._extract_failure_reason(content)
                success_metrics["failure_reasons"][failure_reason] += 1
        
        # Calculate success rate
        if success_metrics["total_operations"] > 0:
            success_metrics["success_rate"] = success_metrics["successful_operations"] / success_metrics["total_operations"]
        
        # Calculate success rates by process
        for process, stats in process_stats.items():
            if stats["total"] > 0:
                success_metrics["success_by_process"][process] = {
                    "success_rate": stats["success"] / stats["total"],
                    "total_operations": stats["total"],
                    "successful_operations": stats["success"]
                }
        
        return success_metrics

    async def _analyze_error_patterns(self, memories: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Analyze error patterns from memory records."""
        error_patterns = {
            "error_frequency": {},
            "error_categories": Counter(),
            "error_trends": {},
            "common_error_sequences": [],
            "recovery_patterns": {}
        }
        
        errors_by_time = []
        error_sequences = []
        current_sequence = []
        
        for memory in memories:
            content = memory.get("content", {})
            timestamp = memory.get("timestamp")
            
            # Check if this is an error-related memory
            if self._is_error_memory(content):
                error_info = {
                    "timestamp": timestamp,
                    "process": content.get("process_name", "unknown"),
                    "error": self._extract_error_info(content)
                }
                errors_by_time.append(error_info)
                current_sequence.append(error_info)
            else:
                # End of error sequence
                if current_sequence:
                    error_sequences.append(current_sequence)
                    current_sequence = []
        
        # Analyze error frequency
        error_patterns["error_frequency"] = self._calculate_error_frequency(errors_by_time)
        
        # Categorize errors
        for error in errors_by_time:
            category = self._categorize_error(error["error"])
            error_patterns["error_categories"][category] += 1
        
        # Analyze error trends
        error_patterns["error_trends"] = self._analyze_error_trends(errors_by_time)
        
        # Identify common error sequences
        error_patterns["common_error_sequences"] = self._identify_common_sequences(error_sequences)
        
        return error_patterns

    async def _log_performance(self, action: str, duration: float, context: str):
        """Log performance metrics for the analysis tool."""
        await self.memory_agent.log_process(
            process_name="memory_analysis_tool_performance",
            data={
                "action": action,
                "duration_seconds": duration,
                "context": context,
                "timestamp": datetime.now().isoformat()
            },
            metadata={"agent_id": self.agent_id}
        )

    # Helper methods for analysis
    def _determine_operation_success(self, content: Dict[str, Any]) -> bool:
        """Determine if an operation was successful based on content."""
        # Check for explicit success indicators
        if "success" in content:
            return content["success"]
        
        # Check for failure indicators in process name
        process_name = content.get("process_name", "").lower()
        if any(word in process_name for word in ["failed", "error", "exception"]):
            return False
        
        # Check for success indicators in process name
        if any(word in process_name for word in ["completed", "success", "finished"]):
            return True
        
        # Check for error in data
        data = content.get("data", {})
        if isinstance(data, dict):
            if "error" in data or "exception" in data:
                return False
            if data.get("status") == "SUCCESS":
                return True
            if data.get("status") == "FAILURE":
                return False
        
        # Default to success if no clear indicators
        return True

    def _extract_failure_reason(self, content: Dict[str, Any]) -> str:
        """Extract failure reason from content."""
        data = content.get("data", {})
        
        if isinstance(data, dict):
            if "reason" in data:
                return data["reason"]
            if "error" in data:
                return str(data["error"])
            if "exception" in data:
                return str(data["exception"])
        
        process_name = content.get("process_name", "")
        if "failed" in process_name:
            return process_name
        
        return "unknown"

    def _is_error_memory(self, content: Dict[str, Any]) -> bool:
        """Check if a memory record represents an error."""
        process_name = content.get("process_name", "").lower()
        return any(word in process_name for word in ["failed", "error", "exception"])

    def _extract_error_info(self, content: Dict[str, Any]) -> str:
        """Extract error information from content."""
        data = content.get("data", {})
        if isinstance(data, dict) and "error" in data:
            return str(data["error"])
        return content.get("process_name", "unknown_error")

    def _categorize_error(self, error_info: str) -> str:
        """Categorize error based on error information."""
        error_lower = error_info.lower()
        
        if any(word in error_lower for word in ["llm", "model", "generation"]):
            return "llm_error"
        elif any(word in error_lower for word in ["network", "connection", "timeout"]):
            return "network_error"
        elif any(word in error_lower for word in ["memory", "storage", "file"]):
            return "storage_error"
        elif any(word in error_lower for word in ["validation", "guardian", "security"]):
            return "security_error"
        elif any(word in error_lower for word in ["agent", "creation", "registration"]):
            return "agent_lifecycle_error"
        else:
            return "general_error"

    async def _get_active_agents(self, days_back: int) -> List[str]:
        """Get list of agents that have been active in the specified timeframe."""
        active_agents = set()
        
        stm_base = self.memory_agent.stm_path
        if stm_base.exists():
            for agent_dir in stm_base.iterdir():
                if agent_dir.is_dir():
                    # Check if agent has recent activity
                    cutoff_date = datetime.now() - timedelta(days=days_back)
                    has_recent_activity = False
                    
                    for day_dir in agent_dir.iterdir():
                        if day_dir.is_dir():
                            try:
                                day_date = datetime.strptime(day_dir.name, "%Y%m%d")
                                if day_date >= cutoff_date:
                                    has_recent_activity = True
                                    break
                            except ValueError:
                                continue
                    
                    if has_recent_activity:
                        active_agents.add(agent_dir.name)
        
        return list(active_agents)

    # Placeholder methods for additional analysis capabilities
    async def _generate_aggregate_insights(self, agent_analyses: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Generate aggregate insights from multiple agent analyses."""
        insights = {
            "system_wide_success_rate": 0.0,
            "most_active_agents": [],
            "common_failure_patterns": [],
            "performance_trends": {},
            "collaboration_health": {}
        }
        
        if not agent_analyses:
            return insights
        
        # Calculate system-wide success rate
        total_ops = sum(analysis.get("success_metrics", {}).get("total_operations", 0) for analysis in agent_analyses)
        total_success = sum(analysis.get("success_metrics", {}).get("successful_operations", 0) for analysis in agent_analyses)
        
        if total_ops > 0:
            insights["system_wide_success_rate"] = total_success / total_ops
        
        # Identify most active agents
        activity_scores = [(analysis["agent_id"], analysis.get("success_metrics", {}).get("total_operations", 0)) 
                          for analysis in agent_analyses]
        insights["most_active_agents"] = sorted(activity_scores, key=lambda x: x[1], reverse=True)[:5]
        
        return insights

    async def _analyze_execution_patterns(self, memories: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Analyze execution patterns from memories."""
        patterns = {
            "operation_frequency": Counter(),
            "time_distribution": {},
            "process_sequences": [],
            "execution_duration_trends": {}
        }
        
        # Count operation frequency
        for memory in memories:
            process_name = memory.get("content", {}).get("process_name", "unknown")
            patterns["operation_frequency"][process_name] += 1
        
        return patterns

    async def _analyze_improvement_trends(self, memories: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Analyze improvement trends from memories."""
        trends = {
            "success_rate_over_time": {},
            "error_reduction_trends": {},
            "capability_improvements": {},
            "learning_indicators": {}
        }
        
        # Group memories by time periods
        time_groups = defaultdict(list)
        for memory in memories:
            timestamp = memory.get("timestamp", "")
            if timestamp:
                try:
                    date = datetime.fromisoformat(timestamp.replace('Z', '+00:00')).date()
                    time_groups[str(date)].append(memory)
                except:
                    continue
        
        # Analyze trends over time
        for date, day_memories in sorted(time_groups.items()):
            day_success_metrics = await self._analyze_success_rates(day_memories)
            trends["success_rate_over_time"][date] = day_success_metrics["success_rate"]
        
        return trends

    async def _analyze_interaction_patterns(self, days_back: int) -> Dict[str, Any]:
        """Analyze interaction patterns across the system."""
        return {"pattern": "Interaction pattern analysis not yet implemented"}

    async def _analyze_coordination_patterns(self, days_back: int) -> Dict[str, Any]:
        """Analyze coordination patterns across agents."""
        return {"pattern": "Coordination pattern analysis not yet implemented"}

    async def _analyze_resource_patterns(self, days_back: int) -> Dict[str, Any]:
        """Analyze resource usage patterns."""
        return {"pattern": "Resource pattern analysis not yet implemented"}

    async def _analyze_evolution_patterns(self, days_back: int) -> Dict[str, Any]:
        """Analyze evolution patterns in the system."""
        return {"pattern": "Evolution pattern analysis not yet implemented"}

    async def _get_recent_performance_data(self) -> Dict[str, Any]:
        """Get recent performance data for analysis."""
        return {"data": "Performance data collection not yet implemented"}

    async def _identify_performance_bottlenecks(self, performance_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Identify performance bottlenecks."""
        return []

    async def _identify_collaboration_inefficiencies(self, performance_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Identify collaboration inefficiencies."""
        return []

    async def _identify_capability_gaps(self, performance_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Identify capability gaps."""
        return []

    async def _identify_resource_optimizations(self, performance_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Identify resource optimization opportunities."""
        return []

    async def _prioritize_opportunities(self, opportunities: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Prioritize improvement opportunities."""
        return opportunities

    async def _create_priority_matrix(self, opportunities: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Create priority matrix for opportunities."""
        return {"matrix": "Priority matrix not yet implemented"}

    async def _generate_implementation_suggestions(self, opportunities: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Generate implementation suggestions."""
        return []

    async def _generate_executive_summary(self, target_agent: str) -> Dict[str, Any]:
        """Generate executive summary for agent."""
        return {"summary": "Executive summary not yet implemented"}

    async def _analyze_decision_quality(self, agent_id: str) -> Dict[str, Any]:
        """Analyze decision quality for agent."""
        return {"quality": "Decision quality analysis not yet implemented"}

    async def _analyze_tool_effectiveness(self, agent_id: str) -> Dict[str, Any]:
        """Analyze tool effectiveness for agent."""
        return {"effectiveness": "Tool effectiveness analysis not yet implemented"}

    async def _analyze_learning_progress(self, agent_id: str) -> Dict[str, Any]:
        """Analyze learning progress for agent."""
        return {"progress": "Learning progress analysis not yet implemented"}

    async def _analyze_collaboration_effectiveness(self, agent_id: str) -> Dict[str, Any]:
        """Analyze collaboration effectiveness for agent."""
        return {"effectiveness": "Collaboration effectiveness analysis not yet implemented"}

    async def _generate_recommendations(self, detailed_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """Generate recommendations based on analysis."""
        return {"recommendations": "Recommendation generation not yet implemented"}

    async def _create_action_plan(self, recommendations: Dict[str, Any]) -> Dict[str, Any]:
        """Create action plan based on recommendations."""
        return {"plan": "Action plan creation not yet implemented"}

    def _calculate_error_frequency(self, errors_by_time: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Calculate error frequency metrics."""
        return {"frequency": "Error frequency calculation not yet implemented"}

    def _analyze_error_trends(self, errors_by_time: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Analyze error trends over time."""
        return {"trends": "Error trend analysis not yet implemented"}

    def _identify_common_sequences(self, error_sequences: List[List[Dict[str, Any]]]) -> List[Dict[str, Any]]:
        """Identify common error sequences."""
        return []
```

### `note_taking_tool.py`

```python
# mindx/tools/note_taking_tool.py
"""
NoteTakingTool for MindX agents.
Allows agents to create, read, update, and delete textual notes.
"""
import asyncio
import re
import uuid
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional

import aiofiles

from core.bdi_agent import BaseTool
from utils.config import Config, PROJECT_ROOT
from utils.logging_config import get_logger
from agents.memory_agent import MemoryAgent

logger = get_logger(__name__)

class NoteTakingTool(BaseTool):
    """Tool for taking and managing textual notes, stored as files."""
    
    def __init__(self, 
                 memory_agent: MemoryAgent,
                 config: Optional[Config] = None,
                 **kwargs: Any):
        """
        Initializes the NoteTakingTool.
        
        Args:
            memory_agent: The memory agent for getting data directories.
            config: Optional Config instance.
            **kwargs: Catches any other arguments from the BDI agent.
        """
        super().__init__(config=config, **kwargs)
        self.memory_agent = memory_agent
        
        # The notes directory is now determined by the calling agent's workspace
        if self.bdi_agent_ref and hasattr(self.bdi_agent_ref, 'agent_id'):
            calling_agent_id = self.bdi_agent_ref.agent_id
            self.notes_dir = self.memory_agent.get_agent_data_directory(calling_agent_id) / "notes"
        else:
            # Fallback to a general notes directory if the tool is somehow used without a BDI agent context
            self.notes_dir = self.memory_agent.get_agent_data_directory("general_note_taking_tool") / "notes"

        try:
            self.notes_dir.mkdir(parents=True, exist_ok=True)
            logger.info(f"NoteTakingTool initialized. Notes directory: {self.notes_dir}")
        except Exception as e:
            logger.error(f"NoteTakingTool: Failed to create notes directory {self.notes_dir}: {e}", exc_info=True)
            raise

    def _sanitize_filename(self, name: str) -> str:
        """Sanitizes a string into a safe filename."""
        if not name or not isinstance(name, str):
            raise ValueError("Filename base must be a non-empty string.")
        
        sanitized = re.sub(r'[^\w\-\.]', '_', name)
        sanitized = re.sub(r'_+', '_', sanitized)
        sanitized = sanitized.strip('_.')
        
        if not sanitized:
            return f"note_{str(uuid.uuid4())[:8]}"
        
        return sanitized[:100] # Limit length

    def _get_note_path(self, topic: Optional[str] = None, file_name: Optional[str] = None) -> Path:
        """
        Constructs the full path for a note file, creating subdirectories from topic.
        """
        target_dir = self.notes_dir
        note_name = ""

        if topic:
            # Treat topic as a potential path
            path_parts = [self._sanitize_filename(part) for part in re.split(r'[\\/]', topic)]
            
            # Limit directory depth
            if len(path_parts) > 10:
                logger.warning(f"Topic path depth exceeds 10, truncating: {topic}")
                path_parts = path_parts[:10]

            if len(path_parts) > 1:
                target_dir = self.notes_dir.joinpath(*path_parts[:-1])
            
            note_name = path_parts[-1]

        if file_name:
            # file_name overrides the note name part of the topic
            note_name = self._sanitize_filename(Path(file_name).stem)
        
        if not note_name:
            # Fallback if topic and file_name are empty or just slashes
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            note_name = f"note_{timestamp}"

        # Create the directory structure if it doesn't exist
        target_dir.mkdir(parents=True, exist_ok=True)

        return target_dir / f"{note_name}.md"

    async def execute(self, **kwargs) -> Dict[str, Any]:
        """
        Executes a note-taking action based on provided parameters.

        Args (from kwargs):
            action (str): The action to perform. Supported: 'add', 'update', 'read', 'delete', 'list'.
            content (str): The content of the note (required for 'add', 'update').
            topic (Optional[str]): A topic to derive the filename from if 'file_name' is not provided.
            file_name (Optional[str]): The specific filename for the note.
        """
        action = kwargs.get("action")
        content = kwargs.get("content")
        topic = kwargs.get("topic")
        file_name = kwargs.get("file_name")

        if not action:
            return {"status": "error", "message": "Missing required parameter: 'action'."}
        
        action = action.lower()
        
        try:
            if action in ["add", "update", "read", "delete"]:
                if not topic and not file_name:
                    return {"status": "error", "message": "Either 'topic' or 'file_name' is required for this action."}
            
            file_path = self._get_note_path(topic=topic, file_name=file_name)

            if action == "add" or action == "update":
                if content is None:
                    return {"status": "error", "message": f"Missing 'content' parameter for '{action}' action."}
                
                async with aiofiles.open(file_path, "w", encoding="utf-8") as f:
                    await f.write(content)
                
                message = f"Note '{file_path.name}' created." if action == "add" else f"Note '{file_path.name}' updated."
                return {"status": "success", "message": message, "file_path": str(file_path)}

            elif action == "read":
                if not file_path.exists():
                    return {"status": "error", "message": f"Note '{file_path.name}' not found."}
                async with aiofiles.open(file_path, "r", encoding="utf-8") as f:
                    read_content = await f.read()
                return {"status": "success", "file_path": str(file_path), "content": read_content}

            elif action == "delete":
                if not file_path.exists():
                    return {"status": "error", "message": f"Note '{file_path.name}' not found for deletion."}
                file_path.unlink()
                return {"status": "success", "message": f"Note '{file_path.name}' deleted."}

            elif action == "list":
                # Recursively list all markdown files in the notes directory
                notes_files = [str(p.relative_to(self.notes_dir)) for p in self.notes_dir.rglob('*.md')]
                if not notes_files:
                    return {"status": "success", "notes": [], "message": "No notes found."}
                return {"status": "success", "notes": sorted(notes_files)}
            
            else:
                return {"status": "error", "message": f"Unknown action: '{action}'. Supported: add, update, read, delete, list."}

        except Exception as e:
            logger.error(f"NoteTakingTool: Error during action '{action}': {e}", exc_info=True)
            return {"status": "error", "message": f"An unexpected error occurred: {e}"}
```

### `optimized_audit_gen_agent.py`

```python
# tools/optimized_audit_gen_agent.py
"""
OptimizedAuditGenAgent: A specialized version of BaseGenAgent optimized for code auditing.
Addresses the giant file problem through smart filtering, chunking, and audit-focused analysis.
"""
import json
import fnmatch
from pathlib import Path
from typing import List, Optional, Dict, Tuple, Any, Set
from datetime import datetime
import copy
import hashlib
import subprocess
import re

try:
    import pathspec
except ImportError:
    pathspec = None

try:
    from utils.config import Config, PROJECT_ROOT
    from utils.logging_config import get_logger
    from core.belief_system import BeliefSystem, BeliefSource
    from agents.memory_agent import MemoryAgent
    logger = get_logger(__name__)
except ImportError as e:
    import logging
    logging.basicConfig(level=logging.INFO, format='[%(levelname)s] %(name)s: %(message)s')
    logger = logging.getLogger(__name__)
    logger.warning(f"Could not import from 'utils' package ({e}). Using fallback.")
    PROJECT_ROOT = Path(__file__).resolve().parent.parent
    class Config:
        def get(self, key, default=None):
            return default


class AuditMetrics:
    """Container for code audit metrics and analysis."""
    
    def __init__(self):
        self.complexity_score = 0
        self.maintainability_score = 0
        self.test_coverage_estimate = 0
        self.code_smells: List[Dict[str, Any]] = []
        self.security_issues: List[Dict[str, Any]] = []
        self.performance_issues: List[Dict[str, Any]] = []
        self.documentation_coverage = 0
        self.dependencies: Set[str] = set()
        self.file_metrics: Dict[str, Dict[str, Any]] = {}

    def to_dict(self) -> Dict[str, Any]:
        return {
            "complexity_score": self.complexity_score,
            "maintainability_score": self.maintainability_score,
            "test_coverage_estimate": self.test_coverage_estimate,
            "code_smells": self.code_smells,
            "security_issues": self.security_issues,
            "performance_issues": self.performance_issues,
            "documentation_coverage": self.documentation_coverage,
            "dependencies": list(self.dependencies),
            "file_metrics": self.file_metrics
        }


class OptimizedAuditGenAgent:
    """
    Optimized code auditing agent that generates manageable documentation chunks
    with focus on code quality, maintainability, and audit insights.
    """
    
    # Enhanced exclude patterns specifically for audit focus
    AUDIT_OPTIMIZED_EXCLUDES = [
        # Memory and log files (major source of bloat)
        "data/memory/*", "data/logs/*", "logs/*", "*.log", "*.log.*",
        
        # Binary and media files
        "*.png", "*.jpg", "*.jpeg", "*.gif", "*.bmp", "*.tiff", "*.svg", "*.ico", "*.webp",
        "*.mp3", "*.wav", "*.ogg", "*.flac", "*.aac", "*.mp4", "*.mov", "*.avi", "*.mkv",
        "*.zip", "*.tar", "*.tar.gz", "*.tar.bz2", "*.rar", "*.7z", "*.gz", "*.bz2",
        "*.exe", "*.dll", "*.so", "*.dylib", "*.class", "*.jar", "*.war", "*.ear",
        "*.pyc", "*.pyo", "*.pyd", "__pycache__/", "*.o", "*.a",
        
        # Documentation that's not code (reduce noise)
        "*.md", "*.txt", "*.pdf", "*.doc", "*.docx", "*.rst",
        
        # Package management and build artifacts
        "node_modules/", "package-lock.json", "yarn.lock", "poetry.lock", "Pipfile.lock",
        "vendor/", "venv/", ".venv/", "env/", "build/", "dist/", "target/", "bin/", "obj/",
        
        # VCS and IDE
        ".git/", ".hg/", ".svn/", ".bzr/", ".idea/", ".vscode/", ".DS_Store", "Thumbs.db",
        
        # Test and coverage artifacts
        "coverage.xml", ".coverage", "nosetests.xml", "pytestdebug.log", ".pytest_cache/",
        
        # Temporary and backup files
        "*.tmp", "*.temp", "*.swp", "*.swo", "*.bak", "*.old", "*.orig"
    ]
    
    # Code patterns that indicate potential issues
    CODE_SMELL_PATTERNS = {
        "long_functions": r"def\s+\w+\([^)]*\):[^}]*(?:\n(?:\s{4,}|\t)[^\n]*){50,}",
        "deep_nesting": r"(\s{16,}|\t{4,})(if|for|while|try|with)",
        "magic_numbers": r"\b(?<![\.\w])[0-9]{2,}\b(?![\.\w])",
        "hardcoded_strings": r'["\'][^"\']{20,}["\']',
        "todo_fixme": r"(TODO|FIXME|HACK|XXX)[:|\s]",
        "long_lines": r".{120,}",
        "missing_docstrings": r"^(class|def)\s+[^#\n]*:\s*\n\s*(?!\"\"\"|\'\'\')(?!\s*#)",
    }
    
    SECURITY_PATTERNS = {
        "sql_injection": r"(execute|query|cursor).*%.*['\"]",
        "command_injection": r"(os\.system|subprocess|shell=True)",
        "hardcoded_secrets": r"(password|secret|key|token)\s*=\s*['\"][^'\"]+['\"]",
        "eval_usage": r"\beval\s*\(",
        "pickle_usage": r"\bpickle\.(loads?|dumps?)\s*\(",
    }
    
    def __init__(self, 
                 memory_agent: MemoryAgent, 
                 agent_id: str = "optimized_audit_gen_agent",
                 max_file_size_kb: int = 500,
                 max_files_per_chunk: int = 50,
                 belief_system: Optional[BeliefSystem] = None):
        self.agent_id = agent_id
        self.belief_system = belief_system
        self.memory_agent = memory_agent
        self.max_file_size_kb = max_file_size_kb
        self.max_files_per_chunk = max_files_per_chunk
        self.log_prefix = f"[{self.agent_id}]"
        
        # Ensure agent data directory exists
        self.data_dir = self.memory_agent.get_agent_data_directory(self.agent_id)
        self.output_dir = self.data_dir / "audit_reports"
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        logger.info(f"{self.log_prefix} Initialized with max_file_size={max_file_size_kb}KB, max_files_per_chunk={max_files_per_chunk}")

    def _should_include_file_for_audit(self, file_path: Path, root_path: Path) -> bool:
        """Enhanced file filtering specifically for code auditing."""
        try:
            relative_path = file_path.relative_to(root_path)
        except ValueError:
            return False
            
        relative_str = relative_path.as_posix()
        
        # Apply optimized exclude patterns
        for pattern in self.AUDIT_OPTIMIZED_EXCLUDES:
            if fnmatch.fnmatch(relative_str, pattern) or fnmatch.fnmatch(file_path.name, pattern):
                logger.debug(f"{self.log_prefix} Excluding {relative_str} by audit pattern: {pattern}")
                return False
        
        # Only include code files and configuration files for auditing
        code_extensions = {'.py', '.js', '.jsx', '.ts', '.tsx', '.java', '.cpp', '.c', '.h', '.hpp',
                          '.cs', '.go', '.rs', '.rb', '.php', '.scala', '.kt', '.swift',
                          '.json', '.yaml', '.yml', '.toml', '.xml', '.ini', '.cfg', '.conf'}
        
        if file_path.suffix.lower() not in code_extensions and file_path.name.lower() not in ['dockerfile', 'makefile', 'requirements.txt']:
            logger.debug(f"{self.log_prefix} Excluding {relative_str} - not a code file")
            return False
        
        # Check file size
        try:
            if file_path.stat().st_size > (self.max_file_size_kb * 1024):
                logger.warning(f"{self.log_prefix} Excluding {relative_str} - file too large ({file_path.stat().st_size} bytes)")
                return False
        except OSError:
            return False
            
        return True

    def generate_audit_documentation(self,
                                   root_path_str: str,
                                   focus_areas: Optional[List[str]] = None,
                                   include_patterns: Optional[List[str]] = None,
                                   additional_exclude_patterns: Optional[List[str]] = None) -> Tuple[bool, Dict[str, Any]]:
        """
        Generate optimized audit documentation with chunking and quality metrics.
        """
        root_path = Path(root_path_str).resolve()
        
        if not root_path.is_dir():
            error_msg = f"Input path '{root_path}' is not a valid directory"
            logger.error(f"{self.log_prefix} {error_msg}")
            return False, {"status": "ERROR", "message": error_msg}
        
        logger.info(f"{self.log_prefix} Starting audit documentation for: {root_path}")
        
        # Collect files for analysis
        included_files = []
        
        try:
            for item in sorted(root_path.rglob("*")):
                if item.is_file() and self._should_include_file_for_audit(item, root_path):
                    included_files.append(item)
        except Exception as e:
            error_msg = f"Error scanning directory: {e}"
            logger.error(f"{self.log_prefix} {error_msg}", exc_info=True)
            return False, {"status": "ERROR", "message": error_msg}
        
        if not included_files:
            logger.warning(f"{self.log_prefix} No files found for analysis")
            return False, {"status": "WARNING", "message": "No files found for analysis"}
        
        logger.info(f"{self.log_prefix} Found {len(included_files)} files for analysis")
        
        # Chunk files to prevent giant output
        file_chunks = self._chunk_files(included_files)
        output_files = []
        
        # Generate timestamp for this audit session
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        try:
            # Generate main audit report
            main_report_path = self.output_dir / f"audit_report_{root_path.name}_{timestamp}.md"
            
            # Generate main report
            with main_report_path.open("w", encoding="utf-8") as f:
                f.write(f"# Code Audit Report: {root_path.name}\n")
                f.write(f"Generated by: {self.agent_id} on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"Source Directory: `{root_path}`\n\n")
                
                f.write(f"## Summary\n")
                f.write(f"- **Total Files Analyzed:** {len(included_files)}\n")
                f.write(f"- **Files per Chunk:** {self.max_files_per_chunk}\n")
                f.write(f"- **Total Chunks:** {len(file_chunks)}\n\n")
                
                # Write file index
                f.write("## File Analysis Chunks\n\n")
                for i, chunk in enumerate(file_chunks):
                    chunk_file = f"audit_chunk_{i+1:03d}_{root_path.name}_{timestamp}.md"
                    f.write(f"- [Chunk {i+1}](./{chunk_file}) - {len(chunk)} files\n")
                
                f.write(f"\n## File List\n\n")
                for file_path in included_files:
                    rel_path = file_path.relative_to(root_path)
                    f.write(f"- `{rel_path.as_posix()}`\n")
            
            # Generate chunk files
            for i, chunk in enumerate(file_chunks):
                chunk_path = self.output_dir / f"audit_chunk_{i+1:03d}_{root_path.name}_{timestamp}.md"
                
                with chunk_path.open("w", encoding="utf-8") as f:
                    f.write(f"# Audit Chunk {i+1} - {root_path.name}\n")
                    f.write(f"Files {i*self.max_files_per_chunk + 1} to {min((i+1)*self.max_files_per_chunk, len(included_files))}\n\n")
                    
                    for file_path in chunk:
                        try:
                            content = file_path.read_text(encoding="utf-8", errors="replace")
                            rel_path = file_path.relative_to(root_path)
                            
                            f.write(f"## `{rel_path.as_posix()}`\n\n")
                            
                            # Write file content with appropriate language tag
                            lang = self._guess_language(file_path.suffix)
                            f.write(f"```{lang}\n{content.strip()}\n```\n\n")
                            
                        except Exception as e:
                            f.write(f"Error reading file: {e}\n\n")
                
                output_files.append(str(chunk_path))
            
            output_files.append(str(main_report_path))
            
            result = {
                "status": "SUCCESS",
                "message": f"Audit documentation generated successfully",
                "main_report": str(main_report_path),
                "chunk_files": output_files[:-1],  # Exclude main report
                "files_analyzed": len(included_files),
                "chunks_created": len(file_chunks),
            }
            
            logger.info(f"{self.log_prefix} Audit complete. Main report: {main_report_path}")
            return True, result
            
        except Exception as e:
            error_msg = f"Error generating audit documentation: {e}"
            logger.error(f"{self.log_prefix} {error_msg}", exc_info=True)
            return False, {"status": "ERROR", "message": error_msg}

    def _chunk_files(self, files: List[Path]) -> List[List[Path]]:
        """Split files into manageable chunks to prevent giant output files."""
        chunks = []
        current_chunk = []
        
        for file_path in files:
            current_chunk.append(file_path)
            
            if len(current_chunk) >= self.max_files_per_chunk:
                chunks.append(current_chunk)
                current_chunk = []
        
        if current_chunk:
            chunks.append(current_chunk)
        
        return chunks

    def _guess_language(self, extension: str) -> str:
        """Guess programming language from file extension."""
        lang_map = {
            ".py": "python", ".js": "javascript", ".jsx": "javascript",
            ".ts": "typescript", ".tsx": "typescript", ".java": "java",
            ".cpp": "cpp", ".c": "c", ".h": "c", ".hpp": "cpp",
            ".cs": "csharp", ".go": "go", ".rs": "rust", ".rb": "ruby",
            ".php": "php", ".scala": "scala", ".kt": "kotlin", ".swift": "swift",
            ".json": "json", ".yaml": "yaml", ".yml": "yaml", ".xml": "xml",
            ".toml": "toml", ".ini": "ini", ".cfg": "ini", ".conf": "apache"
        }
        return lang_map.get(extension.lower(), "")


def main():
    """CLI entry point for testing."""
    import argparse
    
    parser = argparse.ArgumentParser(description="Optimized Audit Code Generator")
    parser.add_argument("input_dir", help="Directory to analyze")
    parser.add_argument("--max-file-size", type=int, default=500, 
                       help="Maximum file size in KB to include")
    parser.add_argument("--max-files-per-chunk", type=int, default=50,
                       help="Maximum files per output chunk")
    
    args = parser.parse_args()
    
    # Create a minimal memory agent for testing
    from agents.memory_agent import MemoryAgent
    memory_agent = MemoryAgent()
    
    # Create the audit agent
    audit_agent = OptimizedAuditGenAgent(
        memory_agent=memory_agent,
        max_file_size_kb=args.max_file_size,
        max_files_per_chunk=args.max_files_per_chunk
    )
    
    # Run the audit
    success, result = audit_agent.generate_audit_documentation(args.input_dir)
    
    if success:
        print(f" Audit completed successfully!")
        print(f" Files analyzed: {result['files_analyzed']}")
        print(f" Chunks created: {result['chunks_created']}")
        print(f" Main report: {result['main_report']}")
    else:
        print(f" Audit failed: {result['message']}")


if __name__ == "__main__":
    main()
```

### `registry_manager_tool.py`

```python
# mindx/tools/registry_manager_tool.py

import json
from pathlib import Path
from typing import Dict, Any, Tuple, Optional

from core.bdi_agent import BaseTool
from core.id_manager_agent import IDManagerAgent
from agents.memory_agent import MemoryAgent
from utils.logging_config import get_logger

logger = get_logger(__name__)

class RegistryManagerTool(BaseTool):
    """
    A tool for managing the official tool and agent registries.
    """
    def __init__(self, memory_agent: MemoryAgent, **kwargs: Any):
        super().__init__(**kwargs)
        self.memory_agent = memory_agent
        self.tool_registry_path = Path(self.config.get("mastermind_agent.tools_registry_path", "data/config/official_tools_registry.json"))
        self.agent_registry_path = Path(self.config.get("mastermind_agent.agents_registry_path", "data/config/official_agents_registry.json"))
        self.model_cards_path = self.memory_agent.get_agent_data_directory("a2a_model_cards")

    def _load_registry(self, registry_path: Path) -> Dict[str, Any]:
        """Loads a registry from a JSON file."""
        if registry_path.exists():
            try:
                with registry_path.open("r", encoding="utf-8") as f:
                    return json.load(f)
            except (json.JSONDecodeError, IOError) as e:
                logger.error(f"Error loading registry from {registry_path}: {e}")
        return {"registered_tools": {}, "registered_agents": {}}

    def _save_registry(self, registry: Dict[str, Any], registry_path: Path):
        """Saves a registry to a JSON file."""
        try:
            with registry_path.open("w", encoding="utf-8") as f:
                json.dump(registry, f, indent=2)
        except IOError as e:
            logger.error(f"Error saving registry to {registry_path}: {e}")

    async def _create_model_card(self, item_id: str, item_config: Dict[str, Any], item_type: str) -> Dict[str, Any]:
        """Creates an A2A model card for an agent or tool."""
        id_manager = await IDManagerAgent.get_instance()
        public_key, _ = await id_manager.create_new_wallet(item_id)
        model_card = {
            "id": item_id,
            "name": item_config.get("name", item_id),
            "description": item_config.get("description", ""),
            "type": item_type,
            "version": item_config.get("version", "1.0.0"),
            "enabled": item_config.get("enabled", True),
            "commands": item_config.get("commands", []),
            "access_control": item_config.get("access_control", {}),
            "identity": {
                "public_key": public_key,
                "signature": await id_manager.sign_message(item_id, json.dumps(item_config)) if public_key else None,
            },
            "a2a_endpoint": f"https://mindx.internal/{item_id}/a2a",
        }
        return model_card

    async def execute(self, registry_type: str, action: str, item_id: str, item_config: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Tuple[bool, Any]:
        """
        Executes an action on a registry.

        Args:
            registry_type: The type of registry to act on. Can be 'tool' or 'agent'.
            action: The action to perform. Can be 'add', 'remove', or 'update'.
            item_id: The ID of the item to act on.
            item_config: The configuration of the item. Required for 'add' and 'update' actions.

        Returns:
            A tuple containing a boolean indicating success and a result.
        """
        if registry_type == "tool":
            registry_path = self.tool_registry_path
            registry_key = "registered_tools"
        elif registry_type == "agent":
            registry_path = self.agent_registry_path
            registry_key = "registered_agents"
        else:
            return False, f"Unknown registry type: {registry_type}"

        registry = self._load_registry(registry_path)

        if action == "add":
            if not item_config:
                return False, f"Missing 'item_config' parameter for 'add' action."
            if item_id in registry[registry_key]:
                return False, f"{registry_type.capitalize()} '{item_id}' already exists."
            
            model_card = await self._create_model_card(item_id, item_config, registry_type)
            item_config["model_card"] = f"{item_id}.json"
            self.model_cards_path.mkdir(parents=True, exist_ok=True)
            with (self.model_cards_path / f"{item_id}.json").open("w", encoding="utf-8") as f:
                json.dump(model_card, f, indent=2)
            
            registry[registry_key][item_id] = item_config
            self._save_registry(registry, registry_path)
            return True, f"{registry_type.capitalize()} '{item_id}' added successfully."
        elif action == "remove":
            if item_id not in registry[registry_key]:
                return False, f"{registry_type.capitalize()} '{item_id}' not found."
            
            model_card_path = self.model_cards_path / registry[registry_key][item_id]["model_card"]
            if model_card_path.exists():
                model_card_path.unlink()
            
            del registry[registry_key][item_id]
            self._save_registry(registry, registry_path)
            return True, f"{registry_type.capitalize()} '{item_id}' removed successfully."
        elif action == "update":
            if not item_config:
                return False, f"Missing 'item_config' parameter for 'update' action."
            if item_id not in registry[registry_key]:
                return False, f"{registry_type.capitalize()} '{item_id}' not found."

            model_card = await self._create_model_card(item_id, item_config, registry_type)
            item_config["model_card"] = f"{item_id}.json"
            self.model_cards_path.mkdir(parents=True, exist_ok=True)
            with (self.model_cards_path / f"{item_id}.json").open("w", encoding="utf-8") as f:
                json.dump(model_card, f, indent=2)

            registry[registry_key][item_id] = item_config
            self._save_registry(registry, registry_path)
            return True, f"{registry_type.capitalize()} '{item_id}' updated successfully."
        else:
            return False, f"Unknown action: {action}"
```

### `registry_sync_tool.py`

```python
# mindx/tools/registry_sync_tool.py
"""
Registry Synchronization Tool for MindX.

This tool handles synchronization between runtime agent registry and persistent 
agent registry files, ensuring all agents have proper cryptographic identities 
and signatures.
"""

import json
import time
from pathlib import Path
from typing import Dict, Any, List, Tuple, Optional

from core.bdi_agent import BaseTool
from core.id_manager_agent import IDManagerAgent
from agents.memory_agent import MemoryAgent
from utils.config import Config, PROJECT_ROOT
from utils.logging_config import get_logger

logger = get_logger(__name__)

class RegistrySyncTool(BaseTool):
    """
    Tool for synchronizing and validating agent registries with cryptographic identities.
    """
    
    def __init__(self, 
                 memory_agent: MemoryAgent,
                 coordinator_ref: Optional[Any] = None,
                 config: Optional[Config] = None,
                 **kwargs):
        super().__init__(config=config, **kwargs)
        self.memory_agent = memory_agent
        self.coordinator_ref = coordinator_ref
        self.config = config or Config()
        
        # Registry file paths
        self.agents_registry_path = PROJECT_ROOT / "data" / "config" / "official_agents_registry.json"
        self.tools_registry_path = PROJECT_ROOT / "data" / "config" / "official_tools_registry.json"
        
        self.log_prefix = "RegistrySyncTool:"
        logger.info(f"{self.log_prefix} Initialized with registry paths.")

    async def execute(self, 
                     action: str = "sync_all",
                     validate_signatures: bool = True,
                     update_missing_keys: bool = True,
                     **kwargs) -> Tuple[bool, Any]:
        """
        Execute registry synchronization operations.
        """
        try:
            if action == "sync_all":
                return await self._sync_all_registries(validate_signatures, update_missing_keys)
            elif action == "update_keys":
                return await self._update_missing_keys()
            else:
                return False, f"Unknown action: {action}"
                
        except Exception as e:
            logger.error(f"{self.log_prefix} Error during {action}: {e}", exc_info=True)
            return False, f"Registry sync failed: {e}"

    async def _sync_all_registries(self, validate_signatures: bool, update_missing_keys: bool) -> Tuple[bool, Any]:
        """Perform comprehensive registry synchronization."""
        logger.info(f"{self.log_prefix} Starting comprehensive registry synchronization...")
        
        results = {
            "agents_synced": 0,
            "keys_updated": 0,
            "signatures_validated": 0,
            "errors": []
        }
        
        try:
            # 1. Load current registries
            runtime_registry = self._get_runtime_registry()
            persistent_registry = self._load_persistent_agents_registry()
            
            # 2. Get ID manager instance
            id_manager = await IDManagerAgent.get_instance()
            
            # 3. Sync each agent
            for agent_id, runtime_info in runtime_registry.items():
                try:
                    # Get or create public key
                    public_key = await id_manager.get_public_address(agent_id)
                    if not public_key and update_missing_keys:
                        public_key, _ = await id_manager.create_new_wallet(entity_id=agent_id)
                        results["keys_updated"] += 1
                        logger.info(f"{self.log_prefix} Created new identity for {agent_id}")
                    
                    # Update existing entry
                    if agent_id in persistent_registry.get("registered_agents", {}):
                        await self._update_persistent_entry(
                            persistent_registry["registered_agents"][agent_id],
                            runtime_info, public_key, id_manager
                        )
                        results["agents_synced"] += 1
                            
                except Exception as e:
                    error_msg = f"Failed to sync agent {agent_id}: {e}"
                    results["errors"].append(error_msg)
                    logger.error(f"{self.log_prefix} {error_msg}")
            
            # 4. Update registry metadata
            persistent_registry["last_updated_at"] = time.time()
            persistent_registry["last_updated_by"] = "registry_sync_tool"
            
            # 5. Save updated registry
            await self._save_persistent_agents_registry(persistent_registry)
            
            logger.info(f"{self.log_prefix} Registry sync complete: {results}")
            return True, results
            
        except Exception as e:
            logger.error(f"{self.log_prefix} Registry sync failed: {e}", exc_info=True)
            return False, f"Sync failed: {e}"

    async def _update_persistent_entry(self,
                                     persistent_entry: Dict[str, Any],
                                     runtime_info: Dict[str, Any],
                                     public_key: Optional[str],
                                     id_manager: IDManagerAgent):
        """Update an existing persistent registry entry."""
        
        # Update public key if missing
        if not persistent_entry.get("identity", {}).get("public_key") and public_key:
            persistent_entry.setdefault("identity", {})["public_key"] = public_key
            
            # Generate new signature
            signature = await id_manager.sign_message(
                persistent_entry["id"], 
                f"agent_registration:{persistent_entry['id']}"
            )
            persistent_entry["identity"]["signature"] = signature
            
        # Update other fields
        persistent_entry["type"] = runtime_info.get("agent_type", persistent_entry.get("type", "unknown"))
        persistent_entry["description"] = runtime_info.get("description", persistent_entry.get("description"))
        persistent_entry["last_updated"] = time.time()
        
        logger.debug(f"{self.log_prefix} Updated persistent entry for {persistent_entry['id']}")

    def _get_runtime_registry(self) -> Dict[str, Any]:
        """Get the current runtime agent registry from coordinator."""
        if self.coordinator_ref:
            return self.coordinator_ref.agent_registry
        return {}

    def _load_persistent_agents_registry(self) -> Dict[str, Any]:
        """Load the persistent agents registry from file."""
        if self.agents_registry_path.exists():
            try:
                with self.agents_registry_path.open("r", encoding="utf-8") as f:
                    return json.load(f)
            except Exception as e:
                logger.error(f"{self.log_prefix} Failed to load agents registry: {e}")
        
        # Return default structure
        return {
            "last_updated_at": time.time(),
            "last_updated_by": "registry_sync_tool",
            "registered_agents": {},
            "agents_schema_version": "2.0"
        }

    async def _save_persistent_agents_registry(self, registry: Dict[str, Any]):
        """Save the persistent agents registry to file."""
        try:
            with self.agents_registry_path.open("w", encoding="utf-8") as f:
                json.dump(registry, f, indent=2)
            logger.info(f"{self.log_prefix} Saved persistent agents registry")
        except Exception as e:
            logger.error(f"{self.log_prefix} Failed to save agents registry: {e}")
            raise

    async def _update_missing_keys(self) -> Tuple[bool, Any]:
        """Update missing public keys for all agents."""
        logger.info(f"{self.log_prefix} Updating missing public keys...")
        
        results = {
            "keys_created": 0,
            "keys_updated": 0,
            "errors": []
        }
        
        try:
            registry = self._load_persistent_agents_registry()
            id_manager = await IDManagerAgent.get_instance()
            
            for agent_id, agent_info in registry.get("registered_agents", {}).items():
                identity = agent_info.setdefault("identity", {})
                
                if not identity.get("public_key"):
                    # Create new identity
                    public_key, _ = await id_manager.create_new_wallet(entity_id=agent_id)
                    signature = await id_manager.sign_message(agent_id, f"agent_registration:{agent_id}")
                    
                    identity["public_key"] = public_key
                    identity["signature"] = signature
                    
                    results["keys_created"] += 1
                    logger.info(f"{self.log_prefix} Created identity for {agent_id}")
            
            # Save updated registry
            await self._save_persistent_agents_registry(registry)
            
            logger.info(f"{self.log_prefix} Key update complete: {results}")
            return True, results
            
        except Exception as e:
            logger.error(f"{self.log_prefix} Key update failed: {e}", exc_info=True)
            return False, f"Key update failed: {e}"
```

### `shell_command_tool.py`

```python
# mindx/tools/shell_command_tool.py

import asyncio
from typing import Dict, Any, Tuple

from core.bdi_agent import BaseTool
from utils.logging_config import get_logger

logger = get_logger(__name__)

class ShellCommandTool(BaseTool):
    """
    A tool for executing shell commands.
    """
    async def execute(self, command: str, **kwargs: Any) -> Tuple[bool, str]:
        """
        Executes a shell command.

        Args:
            command: The shell command to execute.

        Returns:
            A tuple containing a boolean indicating success and a string with the command's output or an error message.
        """
        self.logger.info(f"Executing shell command: {command}")
        try:
            process = await asyncio.create_subprocess_shell(
                command,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            stdout, stderr = await process.communicate()

            if process.returncode == 0:
                output = stdout.decode().strip()
                self.logger.info(f"Command executed successfully. Output:\n{output}")
                return True, output
            else:
                error_message = stderr.decode().strip()
                self.logger.error(f"Command failed with return code {process.returncode}. Error:\n{error_message}")
                return False, error_message
        except Exception as e:
            self.logger.error(f"An exception occurred while executing the command: {e}", exc_info=True)
            return False, f"An exception occurred: {e}"
```

### `summarization_tool.py`

```python
# mindx/tools/summarization_tool.py
"""
SummarizationTool for mindX agents.
Utilizes an LLM to summarize provided text based on context and length constraints.
This version is integrated into the BaseTool architecture.
"""
from typing import Dict, Any, Optional, TYPE_CHECKING

from utils.config import Config
from utils.logging_config import get_logger
from llm.llm_interface import LLMHandlerInterface
from core.bdi_agent import BaseTool

# Use TYPE_CHECKING to avoid circular import at runtime
if TYPE_CHECKING:
    from core.bdi_agent import BDIAgent

logger = get_logger(__name__)

class SummarizationTool(BaseTool):
    """
    Tool for summarizing text using a Large Language Model.
    It inherits from BaseTool and integrates with the BDIAgent's tool system.
    It can take into account topic context, desired summary length, and output format.
    """
    
    def __init__(self, 
                 config: Optional[Config] = None, 
                 llm_handler: Optional[LLMHandlerInterface] = None,
                 bdi_agent_ref: Optional['BDIAgent'] = None):
        """
        Initializes the summarization tool.
        
        Args:
            config: Optional Config instance.
            llm_handler: LLMHandler instance provided by the agent.
            bdi_agent_ref: Optional reference to the owning BDI agent.
        """
        super().__init__(config, llm_handler, bdi_agent_ref=bdi_agent_ref)
        
        if not self.llm_handler:
            raise ValueError("SummarizationTool requires a valid LLMHandlerInterface instance passed during initialization.")
        
        logger.info(f"SummarizationTool initialized. Using LLM: {self.llm_handler.provider_name}/{self.llm_handler.model_name_for_api or 'default'}")
    
    async def execute(self, **kwargs) -> str:
        """
        Summarizes the provided text using an LLM, driven by parameters from the agent's plan.
        
        Args:
            **kwargs: A dictionary of parameters. Expected keys include:
                - text_to_summarize (str): The text content to be summarized.
                - topic_context (Optional[str]): Context about the topic of the text.
                - max_summary_words (Optional[int]): Approx. max words for the summary. Defaults to 150.
                - output_format (Optional[str]): "paragraph" or "bullet_points". Defaults to "paragraph".
                - temperature (Optional[float]): LLM generation temperature.
                - custom_instructions (Optional[str]): Additional instructions for the LLM.
            
        Returns:
            The generated summary as a string, or an error message if summarization fails.
        """
        text_to_summarize = kwargs.get("text_to_summarize")
        topic_context = kwargs.get("topic_context")
        max_summary_words = kwargs.get("max_summary_words", 150)
        output_format = kwargs.get("output_format", "paragraph")
        temperature = kwargs.get("temperature")
        custom_instructions = kwargs.get("custom_instructions")
        
        self.logger.info(f"Executing summarization. Topic: '{topic_context or 'N/A'}', MaxWords: {max_summary_words}, Format: {output_format}")
        
        if not text_to_summarize or not isinstance(text_to_summarize, str) or not text_to_summarize.strip():
            self.logger.warning("No valid 'text_to_summarize' provided in kwargs.")
            return "Error: No text provided for summarization."
        
        # Truncate very long input text to avoid exceeding LLM context limits.
        # A more advanced implementation might use map-reduce for very long texts.
        max_input_chars = self.config.get("tools.summarization.max_input_chars", 30000)
        if len(text_to_summarize) > max_input_chars:
            self.logger.warning(f"Input text length ({len(text_to_summarize)} chars) exceeds max ({max_input_chars}). Truncating.")
            text_to_summarize = (text_to_summarize[:max_input_chars//2] + 
                                 f"\n... (TEXT TRUNCATED DUE TO LENGTH) ...\n" + 
                                 text_to_summarize[-(max_input_chars//2):])
        
        prompt = self._build_summarization_prompt(
            text_to_summarize, topic_context, max_summary_words, output_format, custom_instructions
        )
        
        eff_temperature = temperature if temperature is not None else self.config.get("tools.summarization.llm.temperature", 0.2)
        # Rough estimate: words to tokens (generous buffer)
        max_tokens_for_summary = int(max_summary_words * 2.5)
                         
        try:
            if not self.llm_handler:
                return "Error: LLM handler not available"
            
            self.logger.debug(f"Sending prompt to LLM (first 200 chars): {prompt[:200]}...")
            model_name = self.llm_handler.model_name_for_api or "gemini-1.5-flash-latest"
            summary_result = await self.llm_handler.generate_text(
                prompt=prompt,
                model=model_name,
                max_tokens=max_tokens_for_summary,
                temperature=eff_temperature
            )
            
            if summary_result and not summary_result.lower().startswith("error:"):
                self.logger.info(f"Summary generated successfully for topic '{topic_context or 'N/A'}'.")
                return summary_result.strip()
            else:
                self.logger.error(f"LLM generation for summary failed or returned error: {summary_result}")
                return f"Error: LLM failed to generate summary - {summary_result}"

        except Exception as e:
            self.logger.error(f"Exception during summarization LLM call: {e}", exc_info=True)
            return f"Error: Exception during summarization - {type(e).__name__}: {e}"

    def _build_summarization_prompt(self, text: str, topic: Optional[str], 
                                   max_words: int, format_type: str,
                                   custom_instr: Optional[str]) -> str:
        """Constructs the prompt for the summarization LLM."""
        
        prompt_lines = [
            "You are an expert summarization AI. Please summarize the following text accurately and concisely."
        ]
        if topic:
            prompt_lines.append(f"The text is about: {topic}.")
        
        prompt_lines.append(f"The summary should be approximately {max_words} words or less.")
        
        if format_type and format_type.lower() == "bullet_points":
            prompt_lines.append("Present the summary as a series of key bullet points, each starting with a hyphen '-'.")
        else:
            prompt_lines.append("Present the summary as a coherent paragraph.")
            
        prompt_lines.extend([
            "Focus on extracting the most critical information and main ideas.",
            "Maintain a neutral and objective tone.",
            "Ensure factual accuracy with respect to the original text."
        ])

        if custom_instr:
            prompt_lines.append(f"\nAdditional specific instructions for this summary: {custom_instr}")
            
        prompt_lines.append("\nText to Summarize:\n---BEGIN TEXT---")
        prompt_lines.append(text)
        prompt_lines.append("---END TEXT---\n\nConcise Summary:")
        
        return "\n".join(prompt_lines)
```

### `system_analyzer_tool.py`

```python
# mindx/tools/system_analyzer_tool.py
"""
SystemAnalyzerTool for the MindX Strategic Evolution Agent.

This tool performs holistic analysis of the MindX system's state, including
codebase structure, performance metrics, resource usage, and improvement backlogs,
to generate actionable insights and improvement suggestions.
"""

import json
from typing import Dict, Any, Optional

from utils.config import Config
from utils.logging_config import get_logger
from core.belief_system import BeliefSystem
from llm.llm_interface import LLMHandlerInterface
from llm.model_selector import ModelSelector
from orchestration.coordinator_agent import CoordinatorAgent

logger = get_logger(__name__)

class SystemAnalyzerTool:
    """
    A specialized tool for analyzing the overall state of the MindX system.
    """
    def __init__(self,
                 belief_system: BeliefSystem,
                 llm_handler: LLMHandlerInterface,
                 coordinator_ref: CoordinatorAgent, # FIXED: Now takes coordinator_ref
                 model_selector: Optional[ModelSelector] = None,
                 config: Optional[Config] = None):
        """
        Initializes the SystemAnalyzerTool.

        Args:
            belief_system: The shared BeliefSystem.
            llm_handler: The primary LLM handler for analysis.
            coordinator_ref: A reference to the live CoordinatorAgent to access monitors and backlogs.
            model_selector: (Optional) For selecting specialized models for sub-tasks.
            config: The system configuration object.
        """
        self.belief_system = belief_system
        self.llm_handler = llm_handler
        self.coordinator_ref = coordinator_ref
        self.model_selector = model_selector
        self.config = config or Config()
        self.log_prefix = "SystemAnalyzerTool:"
        
        # Monitors are now accessed via the coordinator reference
        self.performance_monitor = self.coordinator_ref.performance_monitor
        self.resource_monitor = self.coordinator_ref.resource_monitor
        
        logger.info(f"{self.log_prefix} Initialized with integrated monitoring capabilities via Coordinator.")

    async def execute(self, analysis_focus_hint: Optional[str] = None) -> Dict[str, Any]:
        return await self.analyze_system_for_improvements(analysis_focus_hint)

    async def analyze_system_for_improvements(self, analysis_focus_hint: Optional[str] = None) -> Dict[str, Any]:
        """
        Performs a comprehensive system analysis and generates improvement suggestions.
        """
        logger.info(f"{self.log_prefix} Starting comprehensive system analysis. Focus: {analysis_focus_hint or 'General'}")
        
        # 1. Gather data from all relevant sources
        system_state = {
            "performance_metrics": self.performance_monitor.get_all_metrics() if self.performance_monitor else {},
            "resource_usage": self.resource_monitor.get_resource_usage() if self.resource_monitor else {},
            "improvement_backlog": self.coordinator_ref.improvement_backlog[:10], # Get top 10 backlog items
            "recent_campaign_history": self.coordinator_ref.improvement_campaign_history[-5:] # Get last 5 campaigns
        }

        # 2. Formulate a prompt for the LLM to analyze the state
        prompt = (
            "You are a Senior Systems Architect AI analyzing the MindX self-improving system.\n"
            "Your goal is to identify the most impactful areas for improvement based on the following system snapshot.\n\n"
            f"**System State Snapshot:**\n```json\n{json.dumps(system_state, indent=2, default=str)}\n```\n\n"
        )
        if analysis_focus_hint:
            prompt += f"**Specific Analysis Focus:** {analysis_focus_hint}\n\n"
        
        prompt += (
            "**Analysis Task:**\n"
            "1. Synthesize the provided data to identify key patterns, bottlenecks, or recurring failures.\n"
            "2. Propose 2-4 concrete, high-priority 'improvement_suggestions'.\n"
            "3. For each suggestion, provide a 'target_component_path', a 'suggestion' (clear description of the change), a 'justification' (why it's important), and a 'priority' (integer 1-10).\n\n"
            "Respond ONLY with a single JSON object containing the key 'improvement_suggestions', which holds a list of your suggestion objects."
        )

        # 3. Use the LLM to generate insights
        try:
            response_str = await self.llm_handler.generate_text(
                prompt,
                model=self.llm_handler.model_name_for_api,
                max_tokens=2000,
                temperature=0.2,
                json_mode=True
            )
            if not response_str:
                 raise ValueError(f"Analysis LLM returned empty response")

            analysis_result = json.loads(response_str)
            
            # Check if the result has the expected structure
            if "improvement_suggestions" not in analysis_result:
                raise ValueError(f"Analysis LLM response missing 'improvement_suggestions': {response_str}")
            logger.info(f"{self.log_prefix} Successfully generated {len(analysis_result.get('improvement_suggestions', []))} improvement suggestions.")
            return analysis_result

        except Exception as e:
            logger.error(f"{self.log_prefix} Failed to perform system analysis: {e}", exc_info=True)
            return {"error": str(e), "improvement_suggestions": []}
```

### `system_health_tool.py`

```python
# mindx/tools/system_health_tool.py
"""
SystemHealthTool for mindX

This tool is a refactoring of a classic imperative system monitoring agent into a
callable, modular tool for the mindX Augmentic Intelligence ecosystem. It provides
discrete, callable functions for monitoring system resources (CPU, disk, network, temp)
and performing basic remediation actions.

Each function returns a structured dictionary, allowing the calling agent to reason
about the outcome and build dynamic plans. The tool is configured via the central
mindX Config object under the 'tools.system_health' key.
"""
import os
import psutil
import subprocess
import json
import time
from datetime import datetime
import smtplib
from email.mime.text import MIMEText
import asyncio
from typing import Dict, Any, Optional

from core.bdi_agent import BaseTool
from utils.config import Config
from utils.logging_config import get_logger

class SystemHealthTool(BaseTool):
    """A tool for monitoring system health and performing basic administrative tasks."""

    def __init__(self, config: Optional[Config] = None, **kwargs):
        """
        Initializes the SystemHealthTool.

        Args:
            config: The main mindX Config object.
        """
        super().__init__(config=config, **kwargs)
        # The BaseTool's __init__ already sets self.config and self.logger
        
        # Task dispatcher maps a command string to a class method
        self.tasks = {
            "monitor_cpu": self.monitor_cpu,
            "monitor_memory_disk": self.monitor_memory_and_disk,
            "monitor_network": self.monitor_network,
            "monitor_temperatures": self.monitor_temperatures,
            "get_top_cpu_processes": self.get_top_cpu_processes,
            "clean_log_directory": self.clean_log_directory,
            "update_man_db": self.update_man_db_if_permitted,
            "kill_stale_processes": self.self_healing
        }
        self.logger.info("SystemHealthTool initialized.")

    async def execute(self, **kwargs) -> Dict[str, Any]:
        """
        Executes a specific system health task.

        Args:
            **kwargs: Must contain a 'task' key specifying which action to perform.
                      e.g., {"task": "monitor_cpu"}

        Returns:
            A dictionary containing the status and result of the executed task.
        """
        task_name = kwargs.get("task")
        if not task_name:
            return {"status": "ERROR", "message": "No 'task' specified in arguments."}

        handler = self.tasks.get(task_name)
        if not handler:
            return {"status": "ERROR", "message": f"Unknown task: '{task_name}'"}

        self.logger.info(f"Executing system health task: '{task_name}'")
        try:
            # Pass through any additional kwargs to the handler
            result = await handler(**kwargs)
            return result
        except Exception as e:
            self.logger.error(f"Error executing task '{task_name}': {e}", exc_info=True)
            return {"status": "ERROR", "message": str(e)}

    async def _send_email_alert(self, subject: str, body: str) -> bool:
        """Helper method to send email alerts if configured."""
        if not self.config.get("tools.system_health.email_alerts", False):
            return False
        
        recipient = self.config.get("tools.system_health.email_recipient")
        msg = MIMEText(body)
        msg["Subject"] = subject
        msg["From"] = "system-agent@mindx.local"
        msg["To"] = recipient
        try:
            # Note: smtplib is synchronous. For a truly async system, aioesmtp would be better.
            with smtplib.SMTP("localhost") as server:
                server.sendmail(msg["From"], [msg["To"]], msg.as_string())
            self.logger.info(f"Email alert sent to {recipient} with subject: {subject}")
            return True
        except Exception as e:
            self.logger.error(f"Failed to send email alert: {e}")
            return False

    async def monitor_cpu(self, **kwargs) -> Dict[str, Any]:
        """Monitors CPU usage and returns status and data."""
        cpu_usage = psutil.cpu_percent(interval=1)
        threshold = self.config.get("tools.system_health.cpu_alert_threshold", 90)
        
        if cpu_usage > threshold:
            message = f"High CPU usage detected: {cpu_usage}%"
            self.logger.warning(message)
            await self._send_email_alert("High CPU Usage Alert", message)
            return {"status": "ALERT", "cpu_usage": cpu_usage, "threshold": threshold, "message": message}
        
        return {"status": "OK", "cpu_usage": cpu_usage, "threshold": threshold}

    async def monitor_memory_and_disk(self, **kwargs) -> Dict[str, Any]:
        """Monitors memory and root disk usage."""
        mem_info = psutil.virtual_memory()
        disk_info = psutil.disk_usage("/")
        mem_threshold = self.config.get("tools.system_health.mem_alert_threshold", 90)
        disk_threshold = self.config.get("tools.system_health.disk_alert_threshold", 80)
        
        alerts = []
        if mem_info.percent > mem_threshold:
            alerts.append(f"High Memory Usage: {mem_info.percent}%")
        if disk_info.percent > disk_threshold:
            alerts.append(f"High Disk Usage: {disk_info.percent}%")

        if alerts:
            message = ", ".join(alerts)
            self.logger.warning(message)
            await self._send_email_alert("System Resource Alert", message)
            return {"status": "ALERT", "memory_usage": mem_info.percent, "disk_usage": disk_info.percent, "message": message}

        return {"status": "OK", "memory_usage": mem_info.percent, "disk_usage": disk_info.percent}

    async def monitor_network(self, **kwargs) -> Dict[str, Any]:
        """Monitors network usage over a 1-second interval."""
        net_before = psutil.net_io_counters()
        await asyncio.sleep(1)
        net_after = psutil.net_io_counters()
        
        sent_kbs = (net_after.bytes_sent - net_before.bytes_sent) / 1024
        recv_kbs = (net_after.bytes_recv - net_before.bytes_recv) / 1024
        threshold_kbs = self.config.get("tools.system_health.network_alert_threshold", 1000)

        if max(sent_kbs, recv_kbs) > threshold_kbs:
            message = f"High network usage detected: Sent={sent_kbs:.2f} KB/s, Received={recv_kbs:.2f} KB/s"
            self.logger.warning(message)
            await self._send_email_alert("High Network Usage Alert", message)
            return {"status": "ALERT", "sent_kbs": sent_kbs, "recv_kbs": recv_kbs, "message": message}

        return {"status": "OK", "sent_kbs": sent_kbs, "recv_kbs": recv_kbs}
        
    async def get_top_cpu_processes(self, **kwargs) -> Dict[str, Any]:
        """Returns the top 10 CPU-consuming processes."""
        self.logger.info("Investigating top CPU processes.")
        try:
            # Using subprocess for portability and to avoid complex psutil logic
            output = subprocess.check_output(["ps", "aux", "--sort=-%cpu", "--no-headers"], text=True)
            top_lines = output.strip().split("\n")[:10]
            return {"status": "SUCCESS", "processes": top_lines}
        except Exception as e:
            self.logger.error(f"Failed to gather process list: {e}")
            return {"status": "ERROR", "message": f"Failed to run 'ps': {e}"}

    async def clean_log_directory(self, **kwargs) -> Dict[str, Any]:
        """Removes all files in the specified log directory."""
        log_dir_path = kwargs.get("directory", "/var/log/aion")
        self.logger.warning(f"Attempting disk cleanup in '{log_dir_path}'.")
        
        if not os.path.isdir(log_dir_path):
             return {"status": "ERROR", "message": f"Directory not found: {log_dir_path}"}
             
        removed_files = []
        errors = []
        try:
            for item in os.listdir(log_dir_path):
                item_path = os.path.join(log_dir_path, item)
                if os.path.isfile(item_path):
                    try:
                        os.remove(item_path)
                        removed_files.append(item)
                    except Exception as e_file:
                        errors.append(f"Failed to remove {item}: {e_file}")
            
            message = f"Cleanup complete. Removed {len(removed_files)} files."
            if errors:
                message += f" Encountered {len(errors)} errors."
            self.logger.info(message)
            return {"status": "SUCCESS", "removed_count": len(removed_files), "errors": errors, "message": message}
        except Exception as e:
            self.logger.error(f"Failed to clean up logs in {log_dir_path}: {e}")
            return {"status": "ERROR", "message": f"General error cleaning directory: {e}"}

    async def update_man_db_if_permitted(self, **kwargs) -> Dict[str, Any]:
        """Updates the manual page index database if CPU is below a threshold."""
        cpu_permit_threshold = self.config.get("tools.system_health.cpu_permit_man_update", 50)
        cpu_usage = psutil.cpu_percent(interval=1)

        if cpu_usage < cpu_permit_threshold:
            self.logger.info(f"CPU usage low ({cpu_usage}%), running `mandb`.")
            try:
                # Use asyncio's subprocess for non-blocking execution
                process = await asyncio.create_subprocess_exec("mandb", "-q", stdout=subprocess.PIPE, stderr=subprocess.PIPE)
                stdout, stderr = await process.communicate()
                if process.returncode == 0:
                    message = "Manual page indexes updated successfully."
                    self.logger.info(message)
                    return {"status": "SUCCESS", "executed": True, "message": message}
                else:
                    message = f"`mandb` update failed with code {process.returncode}: {stderr.decode()}"
                    self.logger.error(message)
                    return {"status": "ERROR", "executed": True, "message": message}
            except FileNotFoundError:
                return {"status": "ERROR", "executed": False, "message": "`mandb` command not found."}
            except Exception as e:
                return {"status": "ERROR", "executed": False, "message": f"`mandb` update failed: {e}"}
        else:
            message = f"CPU usage {cpu_usage}% too high for `mandb` update (threshold: {cpu_permit_threshold}%)."
            self.logger.info(message)
            return {"status": "SKIPPED", "executed": False, "message": message}

    async def self_healing(self, **kwargs) -> Dict[str, Any]:
        """Kills stale Python processes running longer than a configured duration."""
        max_runtime_hours = kwargs.get("max_runtime_hours", 1)
        process_name_filter = kwargs.get("process_name", "python")
        
        max_runtime_seconds = max_runtime_hours * 3600
        killed_processes = []
        
        for proc in psutil.process_iter(['pid', 'create_time', 'cmdline', 'name']):
            try:
                if process_name_filter in (proc.info.get("name", "") or "").lower():
                    running_time = time.time() - proc.info['create_time']
                    if running_time > max_runtime_seconds:
                        self.logger.warning(f"Killing stale '{process_name_filter}' process PID {proc.info['pid']} running for {running_time:.0f}s")
                        proc.kill()
                        killed_processes.append({"pid": proc.info['pid'], "runtime": running_time})
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                continue
                
        message = f"Self-healing complete. Killed {len(killed_processes)} stale processes."
        self.logger.info(message)
        return {"status": "SUCCESS", "killed_count": len(killed_processes), "details": killed_processes}
```

### `tool_factory_tool.py`

```python
# mindx/tools/tool_factory_tool.py
"""
Tool Factory Tool for MindX.
This tool enables the BDI agent to create new tools dynamically.
"""

import json
import time
from pathlib import Path
from typing import Dict, Any, Tuple, Optional

from core.bdi_agent import BaseTool
from agents.memory_agent import MemoryAgent
from utils.config import Config, PROJECT_ROOT
from utils.logging_config import get_logger

logger = get_logger(__name__)

class ToolFactoryTool(BaseTool):
    """Tool for creating new tools dynamically."""
    
    def __init__(self, memory_agent: MemoryAgent, config: Optional[Config] = None, **kwargs):
        super().__init__(config=config, **kwargs)
        self.memory_agent = memory_agent
        self.config = config or Config()
        self.tools_registry_path = PROJECT_ROOT / "data" / "config" / "official_tools_registry.json"
        self.log_prefix = "ToolFactoryTool:"
        logger.info(f"{self.log_prefix} Initialized with tool creation capabilities.")

    async def execute(self, action: str, tool_id: str = None, tool_config: Optional[Dict[str, Any]] = None, **kwargs) -> Tuple[bool, Any]:
        """Execute tool factory operations."""
        try:
            if action == "create_tool":
                return await self._create_tool(tool_id, tool_config or {})
            else:
                return False, f"Unknown action: {action}"
        except Exception as e:
            logger.error(f"{self.log_prefix} Error executing action '{action}': {e}", exc_info=True)
            return False, f"Tool factory error: {e}"

    async def _create_tool(self, tool_id: str, tool_config: Dict[str, Any]) -> Tuple[bool, Any]:
        """Create a new tool with basic template."""
        logger.info(f"{self.log_prefix} Creating new tool: {tool_id}")
        
        try:
            # Generate basic tool code
            tool_code_path = await self._generate_tool_code(tool_id, tool_config)
            if not tool_code_path:
                return False, "Failed to generate tool code"
            
            # Register in tools registry
            registration_result = await self._register_tool_in_registry(tool_id, tool_config)
            if not registration_result[0]:
                return False, f"Tool registration failed: {registration_result[1]}"
            
            tool_metadata = {
                "tool_id": tool_id,
                "name": tool_config.get("name", tool_id),
                "description": tool_config.get("description", "Dynamically created tool"),
                "code_path": str(tool_code_path),
                "created_at": time.time(),
                "created_by": "tool_factory_tool",
                "status": "active"
            }
            
            logger.info(f"{self.log_prefix} Successfully created tool {tool_id}")
            return True, tool_metadata
            
        except Exception as e:
            logger.error(f"{self.log_prefix} Failed to create tool {tool_id}: {e}", exc_info=True)
            return False, f"Tool creation failed: {e}"

    async def _generate_tool_code(self, tool_id: str, tool_config: Dict[str, Any]) -> Optional[Path]:
        """Generate tool code from basic template."""
        try:
            tool_class_name = f"{tool_id.replace('_', '').title()}Tool"
            tool_description = tool_config.get("description", "Dynamically created tool")
            
            tool_code = f'''# mindx/tools/{tool_id}.py
"""
{tool_class_name} - Dynamically created tool.
Description: {tool_description}
"""

import time
from typing import Dict, Any, Tuple, Optional

from core.bdi_agent import BaseTool
from agents.memory_agent import MemoryAgent
from utils.config import Config
from utils.logging_config import get_logger

logger = get_logger(__name__)

class {tool_class_name}(BaseTool):
    """Dynamically created tool: {tool_description}"""
    
    def __init__(self, memory_agent: MemoryAgent, config: Optional[Config] = None, **kwargs):
        super().__init__(config=config, **kwargs)
        self.memory_agent = memory_agent
        self.config = config or Config()
        self.tool_id = "{tool_id}"
        self.log_prefix = f"{tool_class_name}:"
        logger.info(f"{{self.log_prefix}} Initialized tool {{self.tool_id}}")
    
    async def execute(self, operation: str, parameters: Dict[str, Any] = None, **kwargs) -> Tuple[bool, Any]:
        """Execute the tool operation."""
        logger.info(f"{{self.log_prefix}} Executing operation: {{operation}}")
        
        try:
            parameters = parameters or {{}}
            
            if operation == "test":
                return await self._test_operation(parameters)
            elif operation == "status":
                return await self._status_operation()
            else:
                return await self._custom_operation(operation, parameters)
                
        except Exception as e:
            logger.error(f"{{self.log_prefix}} Operation '{{operation}}' failed: {{e}}", exc_info=True)
            return False, f"Tool operation error: {{e}}"
    
    async def _test_operation(self, parameters: Dict[str, Any]) -> Tuple[bool, Any]:
        """Test operation for validation."""
        result = {{
            "status": "SUCCESS",
            "tool_id": self.tool_id,
            "operation": "test",
            "message": "Tool test completed successfully",
            "timestamp": time.time()
        }}
        return True, result
    
    async def _status_operation(self) -> Tuple[bool, Any]:
        """Get tool status."""
        status = {{
            "tool_id": self.tool_id,
            "status": "active",
            "description": "{tool_description}",
            "timestamp": time.time()
        }}
        return True, status
    
    async def _custom_operation(self, operation: str, parameters: Dict[str, Any]) -> Tuple[bool, Any]:
        """Custom operation implementation."""
        result = {{
            "status": "SUCCESS",
            "tool_id": self.tool_id,
            "operation": operation,
            "parameters": parameters,
            "message": f"Custom operation '{{operation}}' executed",
            "timestamp": time.time()
        }}
        return True, result
'''
            
            # Save to tools directory
            tool_code_path = PROJECT_ROOT / "tools" / f"{tool_id}.py"
            with tool_code_path.open("w", encoding="utf-8") as f:
                f.write(tool_code)
            
            logger.info(f"{self.log_prefix} Generated tool code at {tool_code_path}")
            return tool_code_path
            
        except Exception as e:
            logger.error(f"{self.log_prefix} Failed to generate tool code: {e}")
            return None

    async def _register_tool_in_registry(self, tool_id: str, tool_config: Dict[str, Any]) -> Tuple[bool, Any]:
        """Register the tool in the official tools registry."""
        logger.info(f"{self.log_prefix} Registering tool {tool_id} in registry")
        
        try:
            registry = {}
            if self.tools_registry_path.exists():
                with self.tools_registry_path.open("r", encoding="utf-8") as f:
                    registry = json.load(f)
            
            if "registered_tools" not in registry:
                registry["registered_tools"] = {}
            
            tool_entry = {
                "id": tool_id,
                "name": tool_config.get("name", tool_id),
                "description": tool_config.get("description", "Dynamically created tool"),
                "module_path": f"tools.{tool_id}",
                "class_name": f"{tool_id.replace('_', '').title()}Tool",
                "version": tool_config.get("version", "1.0.0"),
                "enabled": tool_config.get("enabled", True),
                "commands": [{
                    "name": "execute",
                    "description": "Execute tool operation",
                    "parameters": [
                        {"name": "operation", "type": "str", "required": True},
                        {"name": "parameters", "type": "dict", "required": False}
                    ]
                }],
                "access_control": {"allowed_agents": ["*"]},
                "identity": {"public_key": None, "signature": None},
                "created_by": "tool_factory_tool",
                "created_at": time.time()
            }
            
            registry["registered_tools"][tool_id] = tool_entry
            registry["last_updated_at"] = time.time()
            registry["last_updated_by"] = "tool_factory_tool"
            
            with self.tools_registry_path.open("w", encoding="utf-8") as f:
                json.dump(registry, f, indent=2)
            
            logger.info(f"{self.log_prefix} Successfully registered tool {tool_id}")
            return True, tool_entry
            
        except Exception as e:
            logger.error(f"{self.log_prefix} Failed to register tool {tool_id}: {e}")
            return False, f"Tool registration error: {e}"
```

### `tool_registry_manager.py`

```python
# mindx/tools/tool_registry_manager.py

import json
from pathlib import Path
from typing import Dict, Any, Tuple

from core.bdi_agent import BaseTool
from utils.logging_config import get_logger

logger = get_logger(__name__)

class ToolRegistryManager(BaseTool):
    """
    A tool for managing the official tools registry.
    """
    def __init__(self, **kwargs: Any):
        super().__init__(**kwargs)
        self.registry_path = Path(self.config.get("mastermind_agent.tools_registry_path", "data/config/official_tools_registry.json"))

    def _load_registry(self) -> Dict[str, Any]:
        """Loads the tool registry from a JSON file."""
        if self.registry_path.exists():
            try:
                with self.registry_path.open("r", encoding="utf-8") as f:
                    return json.load(f)
            except (json.JSONDecodeError, IOError) as e:
                logger.error(f"Error loading tool registry from {self.registry_path}: {e}")
        return {"registered_tools": {}}

    def _save_registry(self, registry: Dict[str, Any]):
        """Saves the tool registry to a JSON file."""
        try:
            with self.registry_path.open("w", encoding="utf-8") as f:
                json.dump(registry, f, indent=2)
        except IOError as e:
            logger.error(f"Error saving tool registry to {self.registry_path}: {e}")

    async def execute(self, action: str, tool_id: str, tool_config: Optional[Dict[str, Any]] = None, **kwargs: Any) -> Tuple[bool, Any]:
        """
        Executes an action on the tool registry.

        Args:
            action: The action to perform. Can be 'add', 'remove', or 'update'.
            tool_id: The ID of the tool to act on.
            tool_config: The configuration of the tool. Required for 'add' and 'update' actions.

        Returns:
            A tuple containing a boolean indicating success and a result.
        """
        registry = self._load_registry()
        if action == "add":
            if not tool_config:
                return False, "Missing 'tool_config' parameter for 'add' action."
            if tool_id in registry["registered_tools"]:
                return False, f"Tool '{tool_id}' already exists."
            registry["registered_tools"][tool_id] = tool_config
            self._save_registry(registry)
            return True, f"Tool '{tool_id}' added successfully."
        elif action == "remove":
            if tool_id not in registry["registered_tools"]:
                return False, f"Tool '{tool_id}' not found."
            del registry["registered_tools"][tool_id]
            self._save_registry(registry)
            return True, f"Tool '{tool_id}' removed successfully."
        elif action == "update":
            if not tool_config:
                return False, "Missing 'tool_config' parameter for 'update' action."
            if tool_id not in registry["registered_tools"]:
                return False, f"Tool '{tool_id}' not found."
            registry["registered_tools"][tool_id] = tool_config
            self._save_registry(registry)
            return True, f"Tool '{tool_id}' updated successfully."
        else:
            return False, f"Unknown action: {action}"
```

### `tree_agent.py`

```python
import os
from pathlib import Path
from typing import Dict, Any, List, Optional
from tools.shell_command_tool import ShellCommandTool
from core.bdi_agent import BaseTool

class TreeAgent(BaseTool):
    def __init__(self, root_path: str, **kwargs: Any):
        super().__init__(**kwargs)
        self.root_path = Path(root_path).resolve()
        self.shell = ShellCommandTool()

    async def execute(self, command: str) -> Optional[str]:
        if not command.startswith("ls") and not command.startswith("find"):
            return "Error: Only 'ls' and 'find' commands are allowed."
        
        # Correctly construct the command to be sandboxed to the root path.
        # e.g., `find . -name file.txt` becomes `find /root/path . -name file.txt`
        parts = command.split(" ")
        cmd_base = parts[0]
        cmd_args = " ".join(parts[1:])
        full_command = f"{cmd_base} {self.root_path} {cmd_args}"
        
        success, result = self.shell.execute(command=full_command)
        
        if self.memory_agent and self.bdi_agent_ref:
            await self.memory_agent.log_process(
                process_name='tree_agent_execution',
                data={'command': full_command, 'success': success, 'result': result},
                metadata={'agent_id': self.bdi_agent_ref.agent_id, 'tool_id': 'tree_agent'}
            )
            
        return result if success else f"Error: {result}"
```

### `web_search_tool.py`

```python
# tools/web_search_tool.py
"""
WebSearchTool for mindX agents.
Utilizes Google Custom Search JSON API to perform web searches.
"""
import os
# import logging # Use get_logger
import json
import asyncio
from typing import Dict, Any, List, Optional, Coroutine

# httpx is an async-capable HTTP client
try:
    import httpx # Requires: pip install httpx
except ImportError: # pragma: no cover
    httpx = None
    print("CRITICAL: httpx library not found for WebSearchTool. Please 'pip install httpx'.", file=sys.stderr)


from utils.config import Config
from utils.logging_config import get_logger
from core.bdi_agent import BaseTool # Import BaseTool from the core package

logger = get_logger(__name__)

class WebSearchTool(BaseTool): # Inherit from BaseTool
    """
    Tool for searching the web using Google Custom Search JSON API.
    Requires GOOGLE_SEARCH_API_KEY and GOOGLE_SEARCH_ENGINE_ID to be configured.
    Gracefully falls back to mock results if keys are missing.
    """

    def __init__(self,
                 config: Optional[Config] = None,
                 api_key_override: Optional[str] = None,
                 search_engine_id_override: Optional[str] = None,
                 bdi_agent_ref: Optional[Any] = None, # From BaseTool
                 llm_handler: Optional[Any] = None): # From BaseTool, if needed for mocks
        """
        Initialize the web search tool.
        """
        super().__init__(config=config, llm_handler=llm_handler, bdi_agent_ref=bdi_agent_ref)
        # self.config is now set by BaseTool's __init__
        # self.logger is now set by BaseTool's __init__ to f"tool.WebSearchTool"

        self.api_key: Optional[str] = api_key_override or \
                                     self.config.get("tools.web_search.google_api_key",
                                                     os.environ.get("GOOGLE_SEARCH_API_KEY"))
        self.search_engine_id: Optional[str] = search_engine_id_override or \
                                               self.config.get("tools.web_search.google_search_engine_id",
                                                               os.environ.get("GOOGLE_SEARCH_ENGINE_ID"))

        self.http_client: Optional[httpx.AsyncClient] = None
        if httpx:
            self.http_client = httpx.AsyncClient(
                timeout=self.config.get("tools.web_search.timeout_seconds", 20.0),
                follow_redirects=True
            )
        else: # pragma: no cover
            self.logger.error("httpx library is not installed. Real web searches will fail. Only mock results available.")


        if not self.api_key or not self.search_engine_id: # pragma: no cover
            self.logger.warning(
                f"Google Search API key or Search Engine ID not configured. "
                "Web search will use mock results."
            )
        self.logger.info(f"WebSearchTool initialized. API Key Configured: {bool(self.api_key)}, SE ID Configured: {bool(self.search_engine_id)}, httpx available: {bool(httpx)}")

    async def execute(self, query: str, num_results: int = 5, **kwargs) -> str: # Added **kwargs for BaseTool compatibility
        """
        Executes a web search using Google Custom Search API.
        """
        tool_name = self.__class__.__name__ # Use class name for tool name
        self.logger.info(f"Executing web search. Query: '{query}', NumResults: {num_results}")

        if not query or not isinstance(query, str): # pragma: no cover
            self.logger.warning(f"Invalid query provided: {query}")
            return "Error: Invalid or empty query provided for web search."

        if not self.api_key or not self.search_engine_id or not self.http_client: # pragma: no cover
            self.logger.warning(f"API key, Search Engine ID, or HTTP client missing. Generating mock results.")
            return self._generate_mock_results(query, num_results)

        actual_num_results = min(max(1, num_results), 10)

        search_url = "https://www.googleapis.com/customsearch/v1"
        params = {
            "key": self.api_key,
            "cx": self.search_engine_id,
            "q": query,
            "num": actual_num_results
        }

        try:
            response = await self.http_client.get(search_url, params=params)
            response.raise_for_status()
            results_json = response.json()
            return self._format_google_search_results(results_json, query)

        except httpx.TimeoutException as e_timeout: # pragma: no cover
            self.logger.error(f"Web search request timed out for query '{query}': {e_timeout}")
            return f"Error: Web search request timed out. ({e_timeout})"
        except httpx.HTTPStatusError as e_http: # pragma: no cover
            error_detail = "Unknown API error."
            try: error_detail = e_http.response.json().get("error", {}).get("message", str(e_http))
            except: pass
            self.logger.error(f"HTTP error during web search for '{query}': {e_http.response.status_code} - {error_detail}", exc_info=True)
            return f"Error: Web search API request failed with status {e_http.response.status_code}. Detail: {error_detail}"
        except Exception as e_general: # pragma: no cover
            self.logger.error(f"Unexpected error during web search for '{query}': {e_general}", exc_info=True)
            return f"Error: Unexpected error during web search - {type(e_general).__name__}: {e_general}"

    def _format_google_search_results(self, results_json: Dict[str, Any], query: str) -> str: # pragma: no cover
        original_query = query
        search_info = results_json.get("searchInformation", {})
        formatted_time = search_info.get("formattedSearchTime", "N/A")
        total_results = search_info.get("formattedTotalResults", "N/A")
        output_parts = [f"Search Results for: \"{original_query}\" (Time: {formatted_time}s, Approx. Total: {total_results})\n"]
        items = results_json.get("items")
        if not items:
            output_parts.append("\nNo results found for this query.")
            return "".join(output_parts)
        for i, item in enumerate(items, 1):
            title = item.get("title", "No Title")
            link = item.get("link", "No Link")
            snippet = item.get("snippet", "No Snippet").replace("\n", " ").strip()
            output_parts.append(f"\nResult {i}:")
            output_parts.append(f"  Title: {title}")
            output_parts.append(f"  Link: {link}")
            output_parts.append(f"  Snippet: {snippet}")
        return "\n".join(output_parts)

    def _generate_mock_results(self, query: str, num_results: int) -> str: # pragma: no cover
        self.logger.info(f"Generating mock search results for query '{query}'.")
        output_parts = [f"Mock Search Results for: \"{query}\" (API Key/ID Not Configured or httpx missing)\n"]
        for i in range(1, num_results + 1):
            output_parts.append(f"\nResult {i}:")
            output_parts.append(f"  Title: Mock Result {i} - {query[:50]}")
            output_parts.append(f"  Link: https://example.com/mocksearch?q={query.replace(' ','+')}&result={i}")
            output_parts.append(f"  Snippet: This is mock search result number {i} for the query '{query}'. It demonstrates the expected format of real search results, which would contain relevant information from the web.")
        return "\n".join(output_parts)

    async def shutdown(self): # pragma: no cover
        if self.http_client and not self.http_client.is_closed:
            await self.http_client.aclose()
            self.logger.info(f"WebSearchTool's HTTP client closed.")

# Example usage section can be kept for direct testing of this file
async def _web_search_tool_example(): # pragma: no cover
    # Ensure .env is loaded if running this file directly for testing API keys
    # PROJECT_ROOT here would be tools/, so .env is ../.env
    env_path = Path(__file__).resolve().parent.parent / ".env"
    if env_path.exists():
        from dotenv import load_dotenv
        print(f"Loading .env from {env_path}")
        load_dotenv(dotenv_path=env_path, override=True)
    else:
        print(f"Example: .env not found at {env_path}", file=sys.stderr)

    # Need to init Config for the tool to use it
    config = Config()
    search_tool = WebSearchTool(config=config) # bdi_agent_ref is optional

    query1 = "latest advancements in Augmentic Intelligence"
    print(f"\n--- Searching for: '{query1}' ---")
    results1 = await search_tool.execute(query=query1, num_results=3)
    print(results1)
    await search_tool.shutdown()

if __name__ == "__main__": # pragma: no cover
    # Setup basic logging if run standalone
    logging.basicConfig(level=logging.INFO, format='[%(levelname)s] %(name)s - %(module)s.%(funcName)s:%(lineno)d - %(message)s')
    if httpx is None:
        logger.critical("httpx is not installed. WebSearchTool example cannot run effectively.")
    else:
        asyncio.run(_web_search_tool_example())
```
