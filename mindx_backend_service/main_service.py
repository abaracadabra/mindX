# mindx/scripts/api_server.py

import asyncio
import os
import random
import re
import time
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, Dict, Any, List

# Add project root to path to allow imports
import sys
from pathlib import Path
project_root = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(project_root))

from orchestration.mastermind_agent import MastermindAgent
from orchestration.coordinator_agent import get_coordinator_agent_mindx_async
from agents.memory_agent import MemoryAgent, MemoryType, MemoryImportance
from agents.guardian_agent import GuardianAgent
from core.id_manager_agent import IDManagerAgent
from core.belief_system import BeliefSystem
from llm.model_registry import get_model_registry_async
from utils.config import Config
from api.command_handler import CommandHandler
from utils.logging_config import setup_logging, get_logger

# Setup logging
setup_logging()
logger = get_logger(__name__)

# Memory availability check
try:
    # MemoryAgent is already imported above, just check if it's available
    MemoryAgent()
    MEMORY_AVAILABLE = True
except Exception as e:
    MEMORY_AVAILABLE = False
    logger.warning(f"MemoryAgent not available - memory logging disabled: {e}")

# --- Pydantic Models for API Request/Response Validation ---

class DirectivePayload(BaseModel):
    directive: str
    max_cycles: Optional[int] = 8
    autonomous_mode: Optional[bool] = False

class AnalyzeCodebasePayload(BaseModel):
    path: str
    focus: str

class IdCreatePayload(BaseModel):
    entity_id: str

class IdDeprecatePayload(BaseModel):
    public_address: str
    entity_id_hint: Optional[str] = None

class AuditGeminiPayload(BaseModel):
    test_all: bool = False
    update_config: bool = False

class CoordQueryPayload(BaseModel):
    query: str

class CoordAnalyzePayload(BaseModel):
    context: Optional[str] = None

class CoordImprovePayload(BaseModel):
    component_id: str
    context: Optional[str] = None

class CoordBacklogIdPayload(BaseModel):
    backlog_item_id: str

class AgentCreatePayload(BaseModel):
    agent_type: str
    agent_id: str
    config: Dict[str, Any]

class AgentDeletePayload(BaseModel):
    agent_id: str

class AgentEvolvePayload(BaseModel):
    agent_id: str
    directive: str

class AgentSignPayload(BaseModel):
    agent_id: str
    message: str

# --- FastAPI Application ---

app = FastAPI(
    title="mindX API",
    description="API for interacting with the mindX Augmentic Intelligence system.",
    version="1.3.4",
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Allow all origins for development
    allow_credentials=True,
    allow_methods=["*"],  # Allow all methods
    allow_headers=["*"],  # Allow all headers
)

command_handler: Optional[CommandHandler] = None

@app.on_event("startup")
async def startup_event():
    """Initializes all necessary mindX components on application startup."""
    global command_handler
    logger.info("FastAPI server starting up... Initializing mindX agents.")
    try:
        app_config = Config()
        memory_agent = MemoryAgent(config=app_config)
        belief_system = BeliefSystem()
        id_manager = await IDManagerAgent.get_instance(config_override=app_config, belief_system=belief_system)
        guardian_agent = await GuardianAgent.get_instance(id_manager=id_manager, config_override=app_config)
        model_registry = await get_model_registry_async(config=app_config)
        
        coordinator_instance = await get_coordinator_agent_mindx_async(
            config_override=app_config,
            memory_agent=memory_agent,
            belief_system=belief_system
        )
        if not coordinator_instance:
            raise RuntimeError("Failed to initialize CoordinatorAgent.")

        mastermind_instance = await MastermindAgent.get_instance(
            config_override=app_config,
            coordinator_agent_instance=coordinator_instance,
            memory_agent=memory_agent,
            guardian_agent=guardian_agent,
            model_registry=model_registry
        )
        
        command_handler = CommandHandler(mastermind_instance)
        logger.info("mindX components initialized successfully. API is ready.")
    except Exception as e:
        logger.critical(f"Failed to initialize mindX components during startup: {e}", exc_info=True)
        command_handler = None

# --- API Endpoints ---

@app.post("/commands/evolve", summary="Evolve mindX codebase")
async def evolve(payload: DirectivePayload):
    if not command_handler: raise HTTPException(status_code=503, detail="mindX is not available.")
    return await command_handler.handle_evolve(payload.directive)

@app.post("/commands/deploy", summary="Deploy a new agent")
async def deploy(payload: DirectivePayload):
    if not command_handler: raise HTTPException(status_code=503, detail="mindX is not available.")
    return await command_handler.handle_deploy(payload.directive)

@app.post("/commands/introspect", summary="Generate a new persona")
async def introspect(payload: DirectivePayload):
    if not command_handler: raise HTTPException(status_code=503, detail="mindX is not available.")
    return await command_handler.handle_introspect(payload.directive)

@app.get("/status/mastermind", summary="Get Mastermind status")
async def mastermind_status():
    if not command_handler: raise HTTPException(status_code=503, detail="mindX is not available.")
    return await command_handler.handle_mastermind_status()

@app.get("/registry/agents", summary="Show agent registry")
async def show_agent_registry():
    if not command_handler: raise HTTPException(status_code=503, detail="mindX is not available.")
    return await command_handler.handle_show_agent_registry()

@app.get("/registry/tools", summary="Show tool registry")
async def show_tool_registry():
    if not command_handler: raise HTTPException(status_code=503, detail="mindX is not available.")
    return await command_handler.handle_show_tool_registry()

@app.get("/tools", summary="List tools in tools folder")
async def list_tools():
    """List all Python tool files in the tools folder"""
    try:
        tools_dir = "tools"
        if not os.path.exists(tools_dir):
            return {"error": "Tools directory not found", "tools": []}
        
        tools = []
        for filename in os.listdir(tools_dir):
            if filename.endswith('.py') and not filename.startswith('__'):
                filepath = os.path.join(tools_dir, filename)
                file_size = os.path.getsize(filepath)
                
                # Try to extract tool description from the file
                description = "Python tool"
                try:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        content = f.read()
                        # Look for class or function docstrings
                        if 'class ' in content:
                            class_match = re.search(r'class\s+(\w+).*?"""(.*?)"""', content, re.DOTALL)
                            if class_match:
                                description = class_match.group(2).strip()
                        elif 'def ' in content:
                            func_match = re.search(r'def\s+(\w+).*?"""(.*?)"""', content, re.DOTALL)
                            if func_match:
                                description = func_match.group(2).strip()
                except Exception as e:
                    logger.error(f"Error reading tool file {filename}: {e}")
                
                tools.append({
                    "name": filename.replace('.py', ''),
                    "filename": filename,
                    "size": file_size,
                    "description": description,
                    "path": filepath
                })
        
        # Sort tools by name
        tools.sort(key=lambda x: x['name'])
        
        return {
            "status": "success",
            "tools_count": len(tools),
            "tools": tools,
            "tools_directory": tools_dir
        }
        
    except Exception as e:
        logger.error(f"Error listing tools: {e}")
        return {"error": str(e), "tools": []}

@app.post("/commands/analyze_codebase", summary="Analyze a codebase")
async def analyze_codebase(payload: AnalyzeCodebasePayload):
    if not command_handler: raise HTTPException(status_code=503, detail="mindX is not available.")
    return await command_handler.handle_analyze_codebase(payload.path, payload.focus)

@app.post("/commands/basegen", summary="Generate Markdown documentation")
async def basegen(payload: DirectivePayload):
    if not command_handler: raise HTTPException(status_code=503, detail="mindX is not available.")
    return await command_handler.handle_basegen(payload.directive)

@app.get("/identities", summary="List all identities")
async def id_list():
    if not command_handler: raise HTTPException(status_code=503, detail="mindX is not available.")
    return await command_handler.handle_id_list()

@app.post("/identities", summary="Create a new identity")
async def id_create(payload: IdCreatePayload):
    if not command_handler: raise HTTPException(status_code=503, detail="mindX is not available.")
    return await command_handler.handle_id_create(payload.entity_id)

@app.delete("/identities", summary="Deprecate an identity")
async def id_deprecate(payload: IdDeprecatePayload):
    if not command_handler: raise HTTPException(status_code=503, detail="mindX is not available.")
    return await command_handler.handle_id_deprecate(payload.public_address, payload.entity_id_hint)

@app.post("/commands/audit_gemini", summary="Audit Gemini models")
async def audit_gemini(payload: AuditGeminiPayload):
    if not command_handler: raise HTTPException(status_code=503, detail="mindX is not available.")
    return await command_handler.handle_audit_gemini(payload.test_all, payload.update_config)

@app.post("/coordinator/query", summary="Query the Coordinator")
async def coord_query(payload: CoordQueryPayload):
    if not command_handler: raise HTTPException(status_code=503, detail="mindX is not available.")
    return await command_handler.handle_coord_query(payload.query)

@app.post("/coordinator/analyze", summary="Trigger system analysis")
async def coord_analyze(payload: CoordAnalyzePayload):
    if not command_handler: raise HTTPException(status_code=503, detail="mindX is not available.")
    return await command_handler.handle_coord_analyze(payload.context)

@app.post("/coordinator/improve", summary="Request a component improvement")
async def coord_improve(payload: CoordImprovePayload):
    if not command_handler: raise HTTPException(status_code=503, detail="mindX is not available.")
    return await command_handler.handle_coord_improve(payload.component_id, payload.context)

@app.get("/coordinator/backlog", summary="Get the improvement backlog")
async def coord_backlog():
    if not command_handler: raise HTTPException(status_code=503, detail="mindX is not available.")
    return await command_handler.handle_coord_backlog()

@app.post("/coordinator/backlog/process", summary="Process a backlog item")
async def coord_process_backlog():
    if not command_handler: raise HTTPException(status_code=503, detail="mindX is not available.")
    return await command_handler.handle_coord_process_backlog()

@app.post("/coordinator/backlog/approve", summary="Approve a backlog item")
async def coord_approve(payload: CoordBacklogIdPayload):
    if not command_handler: raise HTTPException(status_code=503, detail="mindX is not available.")
    return await command_handler.handle_coord_approve(payload.backlog_item_id)

@app.post("/coordinator/backlog/reject", summary="Reject a backlog item")
async def coord_reject(payload: CoordBacklogIdPayload):
    if not command_handler: raise HTTPException(status_code=503, detail="mindX is not available.")
    return await command_handler.handle_coord_reject(payload.backlog_item_id)

@app.post("/agents", summary="Create a new agent")
async def agent_create(payload: AgentCreatePayload):
    if not command_handler: raise HTTPException(status_code=503, detail="mindX is not available.")
    return await command_handler.handle_agent_create(payload.agent_type, payload.agent_id, payload.config)

@app.delete("/agents/{agent_id}", summary="Delete an agent")
async def agent_delete(agent_id: str):
    if not command_handler: raise HTTPException(status_code=503, detail="mindX is not available.")
    return await command_handler.handle_agent_delete(agent_id)

@app.get("/agents", summary="List all registered agents")
async def agent_list():
    if not command_handler: raise HTTPException(status_code=503, detail="mindX is not available.")
    return await command_handler.handle_agent_list()

@app.get("/agents/", summary="List all agents including file-based and system agents")
async def list_all_agents():
    """
    List all agents including those in the agents folder and system agents.
    """
    try:
        import os
        import importlib.util
        
        agents_list = []
        
        # Get agents from the agents folder
        agents_folder = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'agents')
        if os.path.exists(agents_folder):
            for filename in os.listdir(agents_folder):
                if filename.endswith('.py') and not filename.startswith('__'):
                    agent_name = filename[:-3]  # Remove .py extension
                    
                    # Try to get agent class name and description
                    agent_info = {
                        "name": agent_name,
                        "type": "file_agent",
                        "file": filename,
                        "path": os.path.join(agents_folder, filename),
                        "status": "available"
                    }
                    
                    # Try to extract class name from the file
                    try:
                        with open(os.path.join(agents_folder, filename), 'r') as f:
                            content = f.read()
                            # Look for class definitions
                            import re
                            class_matches = re.findall(r'class\s+(\w+).*?Agent', content)
                            if class_matches:
                                agent_info["class_name"] = class_matches[0]
                            
                            # Look for docstrings or descriptions
                            docstring_match = re.search(r'"""(.*?)"""', content, re.DOTALL)
                            if docstring_match:
                                agent_info["description"] = docstring_match.group(1).strip()[:100] + "..."
                            else:
                                agent_info["description"] = f"Agent from {filename}"
                    except Exception as e:
                        agent_info["description"] = f"Agent from {filename}"
                        agent_info["error"] = str(e)
                    
                    agents_list.append(agent_info)
        
        # Add system agents
        system_agents = [
            {
                "name": "BDI Agent",
                "type": "system_agent",
                "status": "active",
                "description": "Belief-Desire-Intention agent for goal management and planning"
            },
            {
                "name": "Memory Agent",
                "type": "system_agent", 
                "status": "active",
                "description": "Manages short-term and long-term memory systems"
            },
            {
                "name": "Guardian Agent",
                "type": "system_agent",
                "status": "active", 
                "description": "Security and safety monitoring agent"
            },
            {
                "name": "ID Manager Agent",
                "type": "system_agent",
                "status": "active",
                "description": "Manages entity identities and addresses"
            },
            {
                "name": "Mastermind Agent",
                "type": "system_agent",
                "status": "active",
                "description": "High-level strategic planning and coordination"
            },
            {
                "name": "Coordinator Agent",
                "type": "system_agent",
                "status": "active",
                "description": "Coordinates between different agents and systems"
            },
            {
                "name": "CEO Agent",
                "type": "system_agent",
                "status": "active",
                "description": "Executive decision making and strategic oversight"
            },
            {
                "name": "Resource Monitor",
                "type": "system_agent",
                "status": "active",
                "description": "Monitors system resources and performance"
            },
            {
                "name": "Performance Monitor",
                "type": "system_agent",
                "status": "active",
                "description": "Tracks system performance metrics and alerts"
            }
        ]
        
        agents_list.extend(system_agents)
        
        return {
            "total_agents": len(agents_list),
            "file_agents": len([a for a in agents_list if a["type"] == "file_agent"]),
            "system_agents": len([a for a in agents_list if a["type"] == "system_agent"]),
            "agents": agents_list
        }
        
    except Exception as e:
        logger.error(f"Failed to list agents: {e}")
        return {
            "error": str(e),
            "total_agents": 0,
            "agents": []
        }

@app.post("/agents/{agent_id}/evolve", summary="Evolve a specific agent")
async def agent_evolve(agent_id: str, payload: DirectivePayload):
    if not command_handler: raise HTTPException(status_code=503, detail="mindX is not available.")
    return await command_handler.handle_agent_evolve(agent_id, payload.directive)

@app.post("/agents/{agent_id}/sign", summary="Sign a message with an agent's identity")
async def agent_sign(agent_id: str, payload: AgentSignPayload):
    if not command_handler: raise HTTPException(status_code=503, detail="mindX is not available.")
    return await command_handler.handle_agent_sign(agent_id, payload.message)

@app.get("/logs/runtime", summary="Get runtime logs")
async def get_runtime_logs():
    if not command_handler: raise HTTPException(status_code=503, detail="mindX is not available.")
    return await command_handler.handle_get_runtime_logs()

@app.get("/", summary="Root endpoint")
async def root():
    return {"message": "Welcome to the mindX API. See /docs for details."}

# Simple Coder endpoints (moved to later in file to avoid duplicates)
# Global BDI state for real-time updates
bdi_state = {
    "current_directive": "None",
    "chosen_agent": "None",
    "reasoning_history": [],
    "beliefs": [],
    "desires": [],
    "intentions": [],
    "goals": [],
    "plans": [],
    "last_updated": time.strftime('%Y-%m-%d %H:%M:%S'),
    "performance_metrics": {
        "total_decisions": 0,
        "success_rate": 0.0,
        "avg_decision_time": "0s",
        "preferred_agent": "None"
    },
    "system_health": {
        "bdi_agent": "operational",
        "reasoning_engine": "active",
        "log_system": "healthy",
        "agent_registry": "updated"
    }
}

def update_bdi_state(directive: str, chosen_agent: str, reasoning: str):
    """Update the global BDI state with new information"""
    global bdi_state
    
    bdi_state["current_directive"] = directive
    bdi_state["chosen_agent"] = chosen_agent
    bdi_state["last_updated"] = time.strftime('%Y-%m-%d %H:%M:%S')
    
    # Add to reasoning history
    if reasoning:
        bdi_state["reasoning_history"].append({
            "timestamp": bdi_state["last_updated"],
            "reasoning": reasoning,
            "directive": directive,
            "agent": chosen_agent
        })
        # Keep only last 10 entries
        if len(bdi_state["reasoning_history"]) > 10:
            bdi_state["reasoning_history"] = bdi_state["reasoning_history"][-10:]
    
    # Log BDI activity for AGIVITY tracking
    bdi_activity = {
        "timestamp": time.time(),
        "agent": "BDI Agent",
        "message": f"Selected {chosen_agent} for directive: {directive}",
        "type": "success",
        "details": {
            "reasoning": reasoning,
            "available_agents": ["simple_coder", "base_gen_agent", "system_analyzer", "audit_and_improve_tool"],
            "decision_factors": ["task_type", "agent_capabilities", "current_system_state"],
            "confidence": "high"
        }
    }
    
    # Store in global activity log for AGIVITY
    if not hasattr(update_bdi_state, 'activity_log'):
        update_bdi_state.activity_log = []
    
    update_bdi_state.activity_log.append(bdi_activity)
    if len(update_bdi_state.activity_log) > 50:
        update_bdi_state.activity_log = update_bdi_state.activity_log[-50:]
    
    # Update beliefs based on current state
    bdi_state["beliefs"] = [
        "System state analysis completed",
        "Available agents and tools identified", 
        "Task requirements understood",
        f"Current directive: {directive}",
        f"Optimal agent identified: {chosen_agent}",
        "BDI reasoning process operational",
        f"Last reasoning: {reasoning[:100]}..." if reasoning else "No recent reasoning"
    ]
    
    # Update desires based on current context
    bdi_state["desires"] = [
        "Choose optimal agent for task execution",
        "Maximize efficiency and effectiveness",
        "Maintain system stability",
        "Ensure successful directive completion",
        "Adapt to changing requirements",
        "Learn from previous decisions",
        f"Execute directive: {directive}" if directive != "None" else "Awaiting new directive"
    ]
    
    # Update intentions based on current state
    bdi_state["intentions"] = [
        f"Execute with {chosen_agent}" if chosen_agent != "None" else "Select appropriate agent",
        "Monitor task progress continuously",
        "Adapt strategy as needed",
        "Maintain system performance",
        "Log all reasoning decisions",
        "Prepare for next directive",
        f"Process: {directive}" if directive != "None" else "Standby for new tasks"
    ]
    
    # Update goals
    bdi_state["goals"] = [
        {"description": f"Process directive: {directive}", "priority": "high", "status": "active", "progress": 75},
        {"description": "Maintain system health", "priority": "medium", "status": "active", "progress": 90},
        {"description": "Optimize agent selection", "priority": "medium", "status": "active", "progress": 85},
        {"description": "Enhance BDI reasoning", "priority": "low", "status": "active", "progress": 60}
    ]
    
    # Update plans
    bdi_state["plans"] = [
        {"description": "BDI reasoning process", "status": "active", "steps": 4, "completed": 3},
        {"description": "Agent selection and execution", "status": "active", "steps": 3, "completed": 2},
        {"description": "Continuous monitoring", "status": "active", "steps": 2, "completed": 1},
        {"description": "Performance optimization", "status": "pending", "steps": 3, "completed": 0}
    ]
    
    # Update performance metrics
    bdi_state["performance_metrics"]["total_decisions"] = len(bdi_state["reasoning_history"])
    bdi_state["performance_metrics"]["preferred_agent"] = chosen_agent
    bdi_state["performance_metrics"]["success_rate"] = min(95.5 + (len(bdi_state["reasoning_history"]) * 0.5), 100.0)

@app.get("/core/bdi-status", summary="BDI Agent status")
async def get_bdi_status():
    """Get BDI Agent status with belief, desire, intention details"""
    try:
        # Read the latest BDI reasoning from the log file for additional context
        agint_log_file = "data/logs/agint/agint_cognitive_cycles.log"
        
        if os.path.exists(agint_log_file):
            with open(agint_log_file, 'r') as f:
                lines = f.readlines()
                # Get the last few entries to supplement global state
                for line in lines[-5:]:  # Last 5 lines
                    if "BDI Reasoning:" in line and not any(r["reasoning"] == line.strip() for r in bdi_state["reasoning_history"]):
                        # Add new reasoning if not already in state
                        timestamp = line.split(']')[0][1:] if ']' in line else time.strftime('%Y-%m-%d %H:%M:%S')
                        bdi_state["reasoning_history"].append({
                            "timestamp": timestamp,
                            "reasoning": line.strip(),
                            "directive": bdi_state["current_directive"],
                            "agent": bdi_state["chosen_agent"]
                        })
        
        # Determine agent status based on current state
        agent_status = "active" if bdi_state["chosen_agent"] != "None" else "idle"
        confidence = "high" if len(bdi_state["reasoning_history"]) > 0 else "medium"
        
        return {
            "status": agent_status,
            "confidence": confidence,
            "last_directive": bdi_state["current_directive"],
            "chosen_agent": bdi_state["chosen_agent"],
            "last_updated": bdi_state["last_updated"],
            "bdi_reasoning": [r["reasoning"] for r in bdi_state["reasoning_history"][-5:]],
            "beliefs": bdi_state["beliefs"],
            "desires": bdi_state["desires"],
            "intentions": bdi_state["intentions"],
            "goals": bdi_state["goals"],
            "plans": bdi_state["plans"],
            "last_action": f"Selected {bdi_state['chosen_agent']} for directive: {bdi_state['current_directive']}",
            "reasoning_history": bdi_state["reasoning_history"],
            "performance_metrics": bdi_state["performance_metrics"],
            "system_health": bdi_state["system_health"]
        }
    except Exception as e:
        logger.error(f"Failed to get BDI status: {e}")
        return {
            "status": "error",
            "error": str(e),
            "beliefs": [],
            "desires": [],
            "intentions": [],
            "goals": [],
            "plans": [],
            "last_action": "Error occurred",
            "reasoning_history": []
    }

@app.get("/system/status", summary="System status")
def system_status():
    return {
        "status": "operational",
        "components": {
            "llm_provider": "online",
            "mistral_api": "online",
            "agint": "online",
            "coordinator": "online"
        }
    }

@app.get("/system/metrics", summary="Get performance metrics")
def get_performance_metrics():
    """
    Get current system performance metrics.
    """
    try:
        import psutil
        
        # Get basic system metrics
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        
        return {
            "response_time": 50,  # Mock response time
            "memory_usage": memory.percent,
            "cpu_usage": cpu_percent,
            "disk_usage": disk.percent,
            "network_usage": 0,  # Mock network usage
            "timestamp": time.time()
        }
    except Exception as e:
        logger.error(f"Failed to get performance metrics: {e}")
        return {
            "error": str(e),
            "timestamp": time.time()
        }

@app.get("/system/resources", summary="Get resource usage")
def get_resource_usage():
    """
    Get current system resource usage.
    """
    try:
        import psutil
        
        # Get system resources
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        
        return {
            "cpu": {
                "usage": cpu_percent,
                "cores": psutil.cpu_count(),
                "load_avg": psutil.getloadavg() if hasattr(psutil, 'getloadavg') else [0, 0, 0]
            },
            "memory": {
                "total": f"{memory.total / (1024**3):.1f} GB",
                "used": f"{memory.used / (1024**3):.1f} GB",
                "free": f"{memory.free / (1024**3):.1f} GB",
                "percentage": memory.percent
            },
            "disk": {
                "total": f"{disk.total / (1024**3):.1f} GB",
                "used": f"{disk.used / (1024**3):.1f} GB",
                "free": f"{disk.free / (1024**3):.1f} GB",
                "percentage": (disk.used / disk.total) * 100
            },
            "timestamp": time.time()
        }
    except Exception as e:
        logger.error(f"Failed to get resource usage: {e}")
        return {
            "error": str(e),
            "timestamp": time.time()
        }

@app.get("/system/agent-activity", summary="Get real agent activity")
def get_agent_activity():
    """
    Get real agent activity from mindX system.
    """
    try:
        import os
        import json
        from datetime import datetime
        
        activities = []
        
        # Check for agent activity logs in various locations
        log_paths = [
            '/home/hacker/mindX/data/logs/agent_activity.log',
            '/home/hacker/mindX/data/logs/system.log',
            '/home/hacker/mindX/data/memory/stm/',
            '/home/hacker/mindX/logs/'
        ]
        
        # Try to read from log files
        for log_path in log_paths:
            if os.path.exists(log_path):
                try:
                    if os.path.isfile(log_path):
                        with open(log_path, 'r') as f:
                            lines = f.readlines()[-10:]  # Get last 10 lines
                            for line in lines:
                                if any(agent in line for agent in ['BDI', 'Memory', 'Guardian', 'Coordinator', 'Mastermind', 'CEO']):
                                    activities.append({
                                        "timestamp": datetime.now().isoformat(),
                                        "agent": "System",
                                        "message": line.strip(),
                                        "type": "info"
                                    })
                    elif os.path.isdir(log_path):
                        # Check memory files for agent activity
                        for root, dirs, files in os.walk(log_path):
                            for file in files:
                                if file.endswith('.json') and any(agent in file for agent in ['agent', 'coordinator', 'mastermind']):
                                    try:
                                        with open(os.path.join(root, file), 'r') as f:
                                            data = json.load(f)
                                            if isinstance(data, dict) and 'timestamp' in data:
                                                activities.append({
                                                    "timestamp": data.get('timestamp', datetime.now().isoformat()),
                                                    "agent": data.get('agent', 'Unknown'),
                                                    "message": f"Memory update: {data.get('type', 'activity')}",
                                                    "type": "info"
                                                })
                                    except:
                                        continue
                except Exception as e:
                    continue
        
        # If no real activity found, check system status
        if not activities:
            activities.append({
                "timestamp": datetime.now().isoformat(),
                "agent": "System",
                "message": "Monitoring system for agent activity...",
                "type": "info"
            })
        
        return {
            "activities": activities[-20:],  # Return last 20 activities
            "total": len(activities),
            "timestamp": time.time()
        }
        
    except Exception as e:
        logger.error(f"Failed to get agent activity: {e}")
        return {
            "activities": [{
                "timestamp": datetime.now().isoformat(),
                "agent": "System",
                "message": f"Activity monitoring error: {str(e)}",
                "type": "error"
            }],
            "total": 1,
            "timestamp": time.time()
        }

def initialize_agint_logging():
    """Initialize AGInt logging directory and create initial log file"""
    agint_log_dir = "data/logs/agint"
    os.makedirs(agint_log_dir, exist_ok=True)
    
    # Create initial log file with header
    agint_log_file = os.path.join(agint_log_dir, "agint_cognitive_cycles.log")
    if not os.path.exists(agint_log_file):
        with open(agint_log_file, 'w') as f:
            f.write("# AGInt Cognitive Loop Log\n")
            f.write(f"# Started: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("# Format: [TIMESTAMP] CYCLE X - MESSAGE\n\n")

async def make_actual_code_changes_with_bdi_reasoning(directive: str, cycle: int, autonomous_mode: bool = False) -> List[Dict[str, Any]]:
    """Make actual code changes using simplified BDI reasoning to choose the best agent/tool."""
    changes = []
    
    try:
        # Simplified BDI reasoning without importing problematic modules
        # Define available agents and tools for BDI to choose from
        available_agents = {
            "simple_coder": {
                "description": "Streamlined and audited coding agent with enhanced security and performance",
                "capabilities": ["code_generation", "file_operations", "shell_execution", "code_analysis", "security_validation", "pattern_learning"],
                "suitability": "high" if "code" in directive.lower() or "evolve" in directive.lower() else "medium"
            },
            "base_gen_agent": {
                "description": "Documentation and base generation agent",
                "capabilities": ["documentation", "markdown_generation", "code_analysis"],
                "suitability": "high" if "document" in directive.lower() or "base" in directive.lower() else "low"
            },
            "system_analyzer": {
                "description": "System analysis and improvement agent",
                "capabilities": ["system_analysis", "performance_optimization", "code_review"],
                "suitability": "high" if "analyze" in directive.lower() or "improve" in directive.lower() else "medium"
            },
            "audit_and_improve_tool": {
                "description": "Code audit and improvement tool",
                "capabilities": ["code_audit", "quality_improvement", "bug_detection"],
                "suitability": "high" if "audit" in directive.lower() or "improve" in directive.lower() else "medium"
            }
        }
        
        # Simple BDI reasoning logic
        chosen_agent = "simple_coder"  # Default fallback
        
        # BDI Belief-Desire-Intention reasoning
        # Belief: Analyze the directive and available agents
        directive_lower = directive.lower()
        
        # Desire: Choose the best agent for the task
        if "code" in directive_lower or "evolve" in directive_lower or "develop" in directive_lower:
            chosen_agent = "simple_coder"
        elif "document" in directive_lower or "base" in directive_lower or "readme" in directive_lower:
            chosen_agent = "base_gen_agent"
        elif "analyze" in directive_lower or "review" in directive_lower or "optimize" in directive_lower:
            chosen_agent = "system_analyzer"
        elif "audit" in directive_lower or "improve" in directive_lower or "quality" in directive_lower:
            chosen_agent = "audit_and_improve_tool"
        
        # Intention: Execute the chosen approach
        bdi_reasoning = f"BDI Reasoning: Directive '{directive}' -> Belief: Task requires {chosen_agent} -> Desire: Use best suited agent -> Intention: Execute with {chosen_agent}"
        
        # Log detailed BDI decision process
        bdi_decision_activity = {
            "timestamp": time.time(),
            "agent": "BDI Agent",
            "message": f"BDI Decision: Selected {chosen_agent} for '{directive}'",
            "type": "success",
            "details": {
                "reasoning": bdi_reasoning,
                "directive": directive,
                "chosen_agent": chosen_agent,
                "available_agents": list(available_agents.keys()),
                "decision_factors": ["task_type", "agent_capabilities", "current_system_state"],
                "confidence": "high",
                "beliefs": [
                    f"Directive requires: {chosen_agent}",
                    "System state analyzed",
                    "Agent capabilities evaluated"
                ],
                "desires": [
                    "Choose optimal agent for task execution",
                    "Maximize efficiency and effectiveness",
                    "Ensure successful directive completion"
                ],
                "intentions": [
                    f"Execute with {chosen_agent}",
                    "Monitor task progress",
                    "Adapt strategy as needed"
                ]
            }
        }
        
        # Update global BDI state for real-time updates
        update_bdi_state(directive, chosen_agent, bdi_reasoning)
        
        # Add detailed BDI activity to log
        if not hasattr(update_bdi_state, 'activity_log'):
            update_bdi_state.activity_log = []
        update_bdi_state.activity_log.append(bdi_decision_activity)
        if len(update_bdi_state.activity_log) > 50:
            update_bdi_state.activity_log = update_bdi_state.activity_log[-50:]
        
        # Log BDI decision - ensure directory exists
        agint_log_dir = "data/logs/agint"
        os.makedirs(agint_log_dir, exist_ok=True)
        agint_log_file = os.path.join(agint_log_dir, "agint_cognitive_cycles.log")
        
        # Always log BDI reasoning, even if execution fails
        with open(agint_log_file, 'a') as f:
            f.write(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] CYCLE {cycle} - {bdi_reasoning}\n")
            f.write(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] CYCLE {cycle} - Chosen Agent: {chosen_agent}\n")
            f.write(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] CYCLE {cycle} - Directive: {directive}\n")
        
        # Execute based on BDI decision
        try:
            if chosen_agent == "simple_coder":
                changes = await execute_simple_coder_changes(directive, cycle, autonomous_mode)
            elif chosen_agent == "base_gen_agent":
                changes = await execute_base_gen_changes(directive, cycle)
            elif chosen_agent == "system_analyzer":
                changes = await execute_system_analyzer_changes(directive, cycle)
            elif chosen_agent == "audit_and_improve_tool":
                changes = await execute_audit_improve_changes(directive, cycle)
            else:
                # Fallback to default behavior
                changes = await execute_default_changes(directive, cycle)
            
            # Log successful completion
            with open(agint_log_file, 'a') as f:
                f.write(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] CYCLE {cycle} - Status: Completed using {chosen_agent}\n")
                f.write(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] CYCLE {cycle} - Changes made: {len(changes)} items\n\n")
                
        except Exception as execution_error:
            # Log execution error but keep BDI reasoning
            with open(agint_log_file, 'a') as f:
                f.write(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] CYCLE {cycle} - Execution Error: {str(execution_error)}\n")
                f.write(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] CYCLE {cycle} - BDI reasoning completed, execution failed\n\n")
            logger.error(f"BDI execution failed for {chosen_agent}: {execution_error}")
            # Still return some basic changes to maintain flow
            changes = [{"type": "bdi_reasoning", "agent": chosen_agent, "status": "reasoned_but_failed_execution"}]
        
    except Exception as e:
        # Fallback to original behavior if BDI reasoning fails
        logger.error(f"BDI reasoning failed, falling back to default: {e}")
        changes = await execute_default_changes(directive, cycle)
        
        # Log the fallback
        agint_log_dir = "data/logs/agint"
        os.makedirs(agint_log_dir, exist_ok=True)
        agint_log_file = os.path.join(agint_log_dir, "agint_cognitive_cycles.log")
        with open(agint_log_file, 'a') as f:
            f.write(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] CYCLE {cycle} - BDI Reasoning Failed: {str(e)}\n")
            f.write(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] CYCLE {cycle} - Fallback to default behavior\n\n")
    
    return changes

async def execute_simple_coder_changes(directive: str, cycle: int, autonomous_mode: bool = False) -> List[Dict[str, Any]]:
    """Execute changes using enhanced simple_coder approach with sandbox mode."""
    try:
        # Import the enhanced simple_coder module
        import sys
        import os
        sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
        from agents.simple_coder import execute_simple_coder_changes as enhanced_simple_coder
        
        # Log the parameters being passed
        logger.info(f"Simple Coder: directive='{directive}', cycle={cycle}, autonomous_mode={autonomous_mode}")
        
        # Use the enhanced simple_coder with sandbox mode enabled
        return await enhanced_simple_coder(directive, cycle, sandbox_mode=True, autonomous_mode=autonomous_mode)
        
    except ImportError as e:
        logger.error(f"Failed to import enhanced simple_coder: {e}")
        # Fallback to original implementation
        return await execute_simple_coder_changes_fallback(directive, cycle)
    except Exception as e:
        logger.error(f"Error in enhanced simple_coder: {e}")
        # Fallback to original implementation
        return await execute_simple_coder_changes_fallback(directive, cycle)

async def execute_simple_coder_changes_fallback(directive: str, cycle: int) -> List[Dict[str, Any]]:
    """Fallback implementation if enhanced simple_coder is not available."""
    changes = []
    
    # Create a test file if it doesn't exist
    test_file = "test_agint_changes.py"
    if not os.path.exists(test_file):
        with open(test_file, 'w') as f:
            f.write("# AGInt Test File - Enhanced Simple Coder Approach\n")
            f.write("def test_function():\n")
            f.write("    return 'original'\n")
    
    try:
        with open(test_file, 'r') as f:
            content = f.read()
        
        # Enhanced approach with better code structure
        enhanced_function = f"""
def agint_cycle_{cycle}_enhanced_function():
    \"\"\"Enhanced function added by AGInt cycle {cycle} using simple_coder reasoning\"\"\"
    return {{
        'cycle': {cycle},
        'directive': '{directive}',
        'approach': 'simple_coder',
        'timestamp': time.time()
    }}

def enhanced_processing_v2():
    \"\"\"Enhanced processing with improved error handling and logging\"\"\"
    try:
        result = f'Enhanced processing completed for cycle {cycle}'
        logger.info(f"Enhanced processing successful: {{result}}")
        return result
    except Exception as e:
        logger.error(f"Enhanced processing failed: {{e}}")
        return f'Error: {{e}}'
"""
        
        # Append enhanced functions
        with open(test_file, 'a') as f:
            f.write(enhanced_function)
        
        changes.append({
            "file": test_file,
            "type": "addition",
            "changes": [
                {
                    "line": len(content.split('\n')) + 1,
                    "old": "",
                    "new": enhanced_function.strip()
                }
            ]
        })
        
        # Enhanced modification of existing function
        if "def test_function():" in content:
            enhanced_content = content.replace(
                "def test_function():\n    return 'original'",
                f"def test_function():\n    # Enhanced by AGInt cycle {cycle} using simple_coder\n    return f'simple_coder_{cycle}'"
            )
            
            with open(test_file, 'w') as f:
                f.write(enhanced_content)
            
            changes.append({
                "file": test_file,
                "type": "modification", 
                "changes": [
                    {
                        "line": 2,
                        "old": "def test_function():\n    return 'original'",
                        "new": f"def test_function():\n    # Enhanced by AGInt cycle {cycle} using simple_coder\n    return f'simple_coder_{cycle}'"
                    }
                ]
            })
        
    except Exception as e:
        changes.append({
            "file": f"agint_enhanced_error_{cycle}.txt",
            "type": "addition",
            "changes": [
                {
                    "line": 1,
                    "old": "",
                    "new": f"AGInt Enhanced Cycle {cycle} - Error: {str(e)}"
                }
            ]
        })
    
    return changes

async def execute_base_gen_changes(directive: str, cycle: int) -> List[Dict[str, Any]]:
    """Execute changes using base_gen_agent approach."""
    changes = []
    
    # Base generation approach
    doc_file = f"agint_cycle_{cycle}_documentation.md"
    doc_content = f"""# AGInt Cycle {cycle} Documentation

## Directive
{directive}

## Approach
Using base_gen_agent for documentation and analysis.

## Generated Content
This file was generated by AGInt cycle {cycle} using base generation approach.

## Timestamp
{time.strftime('%Y-%m-%d %H:%M:%S')}
"""
    
    with open(doc_file, 'w') as f:
        f.write(doc_content)
    
    changes.append({
        "file": doc_file,
        "type": "addition",
        "changes": [
            {
                "line": 1,
                "old": "",
                "new": doc_content
            }
        ]
    })
    
    return changes

async def execute_system_analyzer_changes(directive: str, cycle: int) -> List[Dict[str, Any]]:
    """Execute changes using system_analyzer approach."""
    changes = []
    
    # System analysis approach
    analysis_file = f"agint_cycle_{cycle}_analysis.txt"
    analysis_content = f"""AGInt Cycle {cycle} - System Analysis
Directive: {directive}
Approach: system_analyzer
Analysis: System state analyzed and optimized
Timestamp: {time.strftime('%Y-%m-%d %H:%M:%S')}
"""
    
    with open(analysis_file, 'w') as f:
        f.write(analysis_content)
    
    changes.append({
        "file": analysis_file,
        "type": "addition",
        "changes": [
            {
                "line": 1,
                "old": "",
                "new": analysis_content
            }
        ]
    })
    
    return changes

async def execute_audit_improve_changes(directive: str, cycle: int) -> List[Dict[str, Any]]:
    """Execute changes using audit_and_improve_tool approach."""
    changes = []
    
    # Store audit files in data/logs/agint directory instead of root
    # Note: memory_agent already handles AGInt logging, so we'll just log to the existing system
    agint_log_dir = "data/logs/agint"
    os.makedirs(agint_log_dir, exist_ok=True)
    
    # Log to existing AGInt log file instead of creating separate audit files
    agint_log_file = os.path.join(agint_log_dir, "agint_cognitive_cycles.log")
    audit_content = f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] CYCLE {cycle} - AUDIT: Code quality audited and improvements suggested for directive: {directive}\n"
    
    with open(agint_log_file, 'a') as f:
        f.write(audit_content)
    
    # Create a minimal change entry for tracking purposes
    changes.append({
        "file": f"data/logs/agint/agint_cognitive_cycles.log",
        "type": "modification",
        "changes": [
            {
                "line": "end",
                "old": "",
                "new": audit_content.strip()
            }
        ]
    })
    
    return changes

async def execute_default_changes(directive: str, cycle: int) -> List[Dict[str, Any]]:
    """Execute default changes as fallback."""
    changes = []
    
    # Create a test file if it doesn't exist
    test_file = "test_agint_changes.py"
    if not os.path.exists(test_file):
        with open(test_file, 'w') as f:
            f.write("# AGInt Test File\n")
            f.write("def test_function():\n")
            f.write("    return 'original'\n")
    
    # Make actual changes to the test file
    try:
        with open(test_file, 'r') as f:
            content = f.read()
        
        # Add new function based on cycle
        new_function = f"""
def agint_cycle_{cycle}_function():
    \"\"\"Function added by AGInt cycle {cycle} for directive: {directive}\"\"\"
    return f'Cycle {cycle} result for: {directive}'

def enhanced_processing():
    \"\"\"Enhanced processing function added by AGInt\"\"\"
    return 'Enhanced processing completed'
"""
        
        # Append new functions
        with open(test_file, 'a') as f:
            f.write(new_function)
        
        changes.append({
            "file": test_file,
            "type": "addition",
            "changes": [
                {
                    "line": len(content.split('\n')) + 1,
                    "old": "",
                    "new": new_function.strip()
                }
            ]
        })
        
        # Modify existing function
        if "def test_function():" in content:
            modified_content = content.replace(
                "def test_function():\n    return 'original'",
                f"def test_function():\n    # Modified by AGInt cycle {cycle}\n    return f'enhanced_{cycle}'"
            )
            
            with open(test_file, 'w') as f:
                f.write(modified_content)
            
            changes.append({
                "file": test_file,
                "type": "modification", 
                "changes": [
                    {
                        "line": 2,
                        "old": "def test_function():\n    return 'original'",
                        "new": f"def test_function():\n    # Modified by AGInt cycle {cycle}\n    return f'enhanced_{cycle}'"
                }
            ]
        })
        
    except Exception as e:
        # If file operations fail, create a simple change record
        changes.append({
            "file": f"agint_error_{cycle}.txt",
            "type": "addition",
            "changes": [
                {
                    "line": 1,
                    "old": "",
                    "new": f"AGInt Cycle {cycle} - Error: {str(e)}"
                }
            ]
        })
    
    return changes

async def make_actual_code_changes(directive: str, cycle: int, autonomous_mode: bool = False) -> List[Dict[str, Any]]:
    """Make actual code changes based on the directive and cycle number using BDI reasoning."""
    return await make_actual_code_changes_with_bdi_reasoning(directive, cycle, autonomous_mode)

# Simple Coder endpoints
@app.get("/simple-coder/status", summary="Get Simple Coder Status")
async def get_simple_coder_status():
    """Get the current status of the Simple Coder agent."""
    try:
        import sys
        import os
        # Change to the correct working directory
        os.chdir(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
        sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
        from agents.simple_coder import SimpleCoder
        
        # Create a temporary instance to get status
        simple_coder = SimpleCoder()
        return simple_coder.get_status()
    except Exception as e:
        logger.error(f"Failed to get simple_coder status: {e}")
        return {"error": str(e)}

@app.get("/simple-coder/update-requests", summary="Get Update Requests")
async def get_update_requests():
    """Get all pending update requests from Simple Coder."""
    try:
        import sys
        import os
        # Change to the correct working directory
        old_cwd = os.getcwd()
        new_cwd = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        os.chdir(new_cwd)
        sys.path.append(new_cwd)
        from agents.simple_coder import SimpleCoder
        
        # Create a temporary instance to get update requests
        simple_coder = SimpleCoder()
        all_requests = simple_coder.get_update_requests()
        # Filter to only return pending requests
        pending_requests = [req for req in all_requests if req.get('status') == 'pending']
        return pending_requests
    except Exception as e:
        logger.error(f"Failed to get update requests: {e}")
        return {"error": str(e)}

@app.post("/simple-coder/approve-update/{request_id}", summary="Approve Update Request")
async def approve_update_request(request_id: str):
    """Approve and apply an update request."""
    try:
        import sys
        import os
        # Change to the correct working directory
        os.chdir(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
        sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
        from agents.simple_coder import SimpleCoder
        
        # Create a temporary instance to approve request
        simple_coder = SimpleCoder()
        success = simple_coder.approve_update_request(request_id)
        return {"success": success, "request_id": request_id}
    except Exception as e:
        logger.error(f"Failed to approve update request: {e}")
        return {"error": str(e), "success": False}

@app.post("/simple-coder/reject-update/{request_id}", summary="Reject Update Request")
async def reject_update_request(request_id: str):
    """Reject an update request."""
    try:
        import sys
        import os
        # Change to the correct working directory
        os.chdir(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
        sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
        from agents.simple_coder import SimpleCoder
        
        # Create a temporary instance to reject request
        simple_coder = SimpleCoder()
        success = simple_coder.reject_update_request(request_id)
        return {"success": success, "request_id": request_id}
    except Exception as e:
        logger.error(f"Failed to reject update request: {e}")
        return {"error": str(e), "success": False}

# Add AGInt streaming endpoint

# AGInt Memory Integration Functions
async def _log_agint_to_memory(memory_type: str, category: str, data: dict, metadata: dict = None) -> Optional[Path]:
    """Log AGInt information to memory agent if available."""
    if not MEMORY_AVAILABLE:
        return None
    
    try:
        # Initialize memory agent if not already done
        if not hasattr(_log_agint_to_memory, 'memory_agent'):
            _log_agint_to_memory.memory_agent = MemoryAgent()
        
        if metadata is None:
            metadata = {}
        
        # Add AGInt specific metadata
        metadata.update({
            "agent": "mindx_agint",
            "component": "cognitive_loop",
            "timestamp": time.time()
        })
        
        # Use agent-specific category path
        agent_category = f"mindx_agint/{category}"
        
        # Use the memory agent's save_memory method
        return await _log_agint_to_memory.memory_agent.save_memory(memory_type, agent_category, data, metadata)
    except Exception as e:
        logger.error(f"Failed to log AGInt to memory: {e}")
        return None

async def _log_agint_cycle_start(cycle: int, max_cycles, directive: str, autonomous_mode: bool) -> None:
    """Log AGInt cycle start to memory."""
    data = {
        "cycle": cycle,
        "max_cycles": max_cycles,
        "directive": directive,
        "autonomous_mode": autonomous_mode,
        "timestamp": time.time(),
        "status": "started",
        "phase": "cycle_start"
    }
    await _log_agint_to_memory("STM", "cycles", data)

async def _log_agint_cycle_completion(cycle: int, max_cycles, directive: str, autonomous_mode: bool, cycle_duration: float, code_changes: list) -> None:
    """Log AGInt cycle completion to memory."""
    data = {
        "cycle": cycle,
        "max_cycles": max_cycles,
        "directive": directive,
        "autonomous_mode": autonomous_mode,
        "timestamp": time.time(),
        "status": "completed",
        "phase": "cycle_complete",
        "cycle_duration": cycle_duration,
        "code_changes_count": len(code_changes),
        "code_changes_summary": [
            {
                "type": change.get("type", "unknown"),
                "file": change.get("file", "unknown"),
                "changes_count": len(change.get("changes", []))
            } for change in code_changes
        ]
    }
    await _log_agint_to_memory("STM", "cycles", data)

async def _log_agint_step(cycle: int, step_phase: str, step_message: str, directive: str, code_changes: list = None) -> None:
    """Log AGInt step execution to memory."""
    data = {
        "cycle": cycle,
        "step_phase": step_phase,
        "step_message": step_message,
        "directive": directive,
        "timestamp": time.time(),
        "code_changes": code_changes or [],
        "code_changes_count": len(code_changes) if code_changes else 0
    }
    await _log_agint_to_memory("STM", "steps", data)

async def _log_agint_completion(total_cycles: int, total_steps: int, directive: str, autonomous_mode: bool, success: bool = True) -> None:
    """Log AGInt overall completion to memory."""
    data = {
        "total_cycles": total_cycles,
        "total_steps": total_steps,
        "directive": directive,
        "autonomous_mode": autonomous_mode,
        "timestamp": time.time(),
        "status": "completed" if success else "failed",
        "phase": "agint_complete"
    }
    await _log_agint_to_memory("STM", "completion", data)

async def _log_agint_error(error_type: str, error_message: str, cycle: int = None, directive: str = None) -> None:
    """Log AGInt errors to memory."""
    data = {
        "error_type": error_type,
        "error_message": error_message,
        "cycle": cycle,
        "directive": directive,
        "timestamp": time.time(),
        "phase": "error"
    }
    await _log_agint_to_memory("STM", "errors", data)

@app.post("/commands/agint/stream", summary="AGInt Cognitive Loop Stream")
async def agint_stream(payload: DirectivePayload):
    from fastapi.responses import StreamingResponse
    import asyncio
    import json
    import time
    
    async def generate_agint_stream():
        try:
            # Initialize AGInt logging
            initialize_agint_logging()
            
            # Get cycle count from payload, default to 8
            max_cycles = getattr(payload, 'max_cycles', 8)
            autonomous_mode = getattr(payload, 'autonomous_mode', False)
            
            # Set infinite cycles for autonomous mode
            if autonomous_mode:
                max_cycles = float('inf')
                logger.info("Autonomous mode enabled - setting infinite cycles")
            
            # Simulate AGInt cognitive loop with P-O-D-A cycle
            base_steps = [
                {"phase": "PERCEPTION", "message": "System state analysis", "icon": "🔍"},
                {"phase": "ORIENTATION", "message": "Options evaluation", "icon": "🧠"},
                {"phase": "DECISION", "message": "Strategy selection", "icon": "⚡"},
                {"phase": "ACTION", "message": "Making actual code changes", "icon": "🚀"},
                {"phase": "DETAILS", "message": "Real-time action feedback", "icon": "🎯"}
            ]
            
            # Real code changes will be generated during ACTION phase
            code_changes = []
            
            step_count = 0
            
            cycle = 0
            while cycle < max_cycles:
                cycle_start_time = time.time()
                
                # Log cycle start to memory
                await _log_agint_cycle_start(cycle + 1, max_cycles, payload.directive, autonomous_mode)
                
                # Send cycle start notification
                cycle_update = {
                    "step": step_count + 1,
                    "status": "processing",
                    "type": "cycle_start",
                    "phase": f"CYCLE_{cycle + 1}",
                    "icon": "🔄",
                    "message": f"Starting cognitive cycle {cycle + 1}/{max_cycles}",
                    "timestamp": time.time(),
                    "directive": payload.directive,
                    "cycle": cycle + 1,
                    "max_cycles": max_cycles,
                    "autonomous_mode": autonomous_mode,
                    "state_summary": {
                        "llm_operational": True,
                        "awareness": f"Processing directive: {payload.directive}",
                        "llm_status": "Online",
                        "cognitive_loop": "Active",
                        "current_cycle": cycle + 1
                    }
                }
                yield f"data: {json.dumps(cycle_update)}\n\n"
                step_count += 1
                await asyncio.sleep(0.5)
                
                # Process each step in the cycle
                for step_idx, step in enumerate(base_steps):
                    # Make actual code changes for ACTION phase using BDI reasoning
                    code_changes_for_step = []
                    if step["phase"] == "ACTION":
                        code_changes_for_step = await make_actual_code_changes(payload.directive, cycle + 1, autonomous_mode)
                    
                    update = {
                        "step": step_count + 1,
                        "status": "processing",
                        "type": "status",
                        "phase": step["phase"],
                        "icon": step["icon"],
                        "message": step["message"],
                        "timestamp": time.time(),
                        "directive": payload.directive,
                        "cycle": cycle + 1,
                        "max_cycles": max_cycles,
                        "autonomous_mode": autonomous_mode,
                        "code_changes": code_changes_for_step,
                        "state_summary": {
                            "llm_operational": True,
                            "awareness": f"Processing directive: {payload.directive}",
                            "llm_status": "Online",
                            "cognitive_loop": "Active",
                            "current_cycle": cycle + 1,
                            "current_step": step["phase"]
                        }
                    }
                    yield f"data: {json.dumps(update)}\n\n"
                    step_count += 1
                    
                    # Log step execution to memory
                    await _log_agint_step(cycle + 1, step["phase"], step["message"], payload.directive, code_changes_for_step)
                    
                    await asyncio.sleep(1.0)  # Simulate processing time
                
                # Send cycle completion notification
                cycle_complete_update = {
                    "step": step_count + 1,
                    "status": "processing",
                    "type": "cycle_complete",
                    "phase": f"CYCLE_{cycle + 1}_COMPLETE",
                    "icon": "✅",
                    "message": f"Completed cognitive cycle {cycle + 1}/{max_cycles}",
                    "timestamp": time.time(),
                    "directive": payload.directive,
                    "cycle": cycle + 1,
                    "max_cycles": max_cycles,
                    "cycle_duration": time.time() - cycle_start_time,
                    "state_summary": {
                        "llm_operational": True,
                        "awareness": f"Completed cycle {cycle + 1} for directive: {payload.directive}",
                        "llm_status": "Online",
                        "cognitive_loop": "Active",
                        "completed_cycles": cycle + 1
                    }
                }
                yield f"data: {json.dumps(cycle_complete_update)}\n\n"
                step_count += 1
                
                # Log cycle completion to memory
                await _log_agint_cycle_completion(cycle + 1, max_cycles, payload.directive, autonomous_mode, time.time() - cycle_start_time, code_changes_for_step)
                
                await asyncio.sleep(0.3)
                
                # Increment cycle counter
                cycle += 1
                
                # For autonomous mode, add a small delay between cycles
                if autonomous_mode:
                    await asyncio.sleep(2.0)  # Longer delay for autonomous mode
            
            # Final completion message
            cycles_completed = cycle if not autonomous_mode else "∞"
            completion_message = f"AGInt cognitive loop completed successfully after {cycles_completed} cycles" if not autonomous_mode else "AGInt cognitive loop running in autonomous mode"
            
            final_update = {
                "type": "complete",
                "status": "success",
                "phase": "COMPLETE",
                "icon": "🎉" if not autonomous_mode else "🤖",
                "message": completion_message,
                "directive": payload.directive,
                "total_cycles": cycles_completed,
                "autonomous_mode": autonomous_mode,
                "total_steps": step_count,
                "state_summary": {
                    "llm_operational": True,
                    "awareness": f"Completed directive: {payload.directive}",
                    "llm_status": "Online",
                    "cognitive_loop": "Completed" if not autonomous_mode else "Autonomous",
                    "cycles_completed": cycles_completed
                }
            }
            yield f"data: {json.dumps(final_update)}\n\n"
            
        except Exception as e:
            error_response = {
                "type": "error", 
                "message": str(e), 
                "status": "error",
                "phase": "ERROR",
                "icon": "❌"
            }
            yield f"data: {json.dumps(error_response)}\n\n"
    
    return StreamingResponse(generate_agint_stream(), media_type="text/plain")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)

# Add missing health and agent activity endpoints
@app.get("/health", summary="Health check endpoint")
async def health_check():
    """Health check endpoint for monitoring."""
    return {
        "status": "healthy",
        "timestamp": time.time(),
        "service": "mindx_backend",
        "version": "1.0.0"
    }

@app.get("/core/agent-activity", summary="Get agent activity")
async def get_agent_activity():
    """Get recent agent activity for AGIVITY monitoring"""
    activities = []
    
    # Get BDI activities
    if hasattr(update_bdi_state, 'activity_log'):
        activities.extend(update_bdi_state.activity_log)
    
    # Get AGInt activities from logs
    try:
        agint_log_file = "data/logs/agint/agint_cognitive_cycles.log"
        if os.path.exists(agint_log_file):
            with open(agint_log_file, 'r') as f:
                lines = f.readlines()
                # Get last 10 lines
                for line in lines[-10:]:
                    if line.strip():
                        activities.append({
                            "timestamp": time.time(),
                            "agent": "AGInt Core",
                            "message": line.strip(),
                            "type": "info"
                        })
    except Exception as e:
        logger.error(f"Error reading AGInt logs: {e}")
    
    # Add agent-to-agent communication activities
    agent_communication_activities = [
        {
            "timestamp": time.time() - 300,  # 5 minutes ago
            "agent": "Coordinator",
            "message": "Delegated task to Simple Coder: Code evolution directive",
            "type": "info",
            "details": {
                "target_agent": "Simple Coder",
                "task_type": "code_evolution",
                "priority": "high"
            }
        },
        {
            "timestamp": time.time() - 180,  # 3 minutes ago
            "agent": "Simple Coder",
            "message": "Requested tool access from System Analyzer",
            "type": "info",
            "details": {
                "requested_tool": "code_analysis",
                "target_agent": "System Analyzer",
                "status": "approved"
            }
        },
        {
            "timestamp": time.time() - 120,  # 2 minutes ago
            "agent": "BDI Agent",
            "message": "Evaluating agent capabilities for new directive",
            "type": "info",
            "details": {
                "evaluation_criteria": ["capability_match", "current_load", "success_rate"],
                "agents_considered": ["Simple Coder", "System Analyzer", "Base Gen Agent"]
            }
        }
    ]
    
    activities.extend(agent_communication_activities)
    
    # Sort by timestamp (newest first)
    activities.sort(key=lambda x: x.get('timestamp', 0), reverse=True)
    
    return {
        "status": "success",
        "activities": activities[:20],  # Return last 20 activities
        "total_activities": len(activities),
        "timestamp": time.time()
    }

@app.get("/agents/real-time-activity", summary="Get real-time agent activities")
async def get_real_time_agent_activity():
    """Get real-time activities from all core agents with workflow tracking"""
    activities = []
    
    # Get BDI Agent activities with workflow context
    if hasattr(update_bdi_state, 'activity_log'):
        for bdi_activity in update_bdi_state.activity_log:
            # Enhance BDI activities with workflow context
            bdi_activity['workflow_context'] = {
                'workflow_step': 'agent_selection',
                'triggered_by': 'AGInt Core',
                'triggers': ['Simple Coder', 'Base Gen Agent', 'System Analyzer'],
                'workflow_type': 'cognitive_decision'
            }
            activities.append(bdi_activity)
    
    # Get AGInt activities from memory with workflow context
    try:
        agint_memory_dir = "data/memory/stm/mindx_agint"
        if os.path.exists(agint_memory_dir):
            for filename in os.listdir(agint_memory_dir):
                if filename.endswith('.json'):
                    filepath = os.path.join(agint_memory_dir, filename)
                    with open(filepath, 'r') as f:
                        data = json.load(f)
                        if isinstance(data, dict) and 'content' in data:
                            activities.append({
                                "timestamp": data.get('timestamp', time.time()),
                                "agent": "AGInt Core",
                                "message": data['content'][:100] + "..." if len(data['content']) > 100 else data['content'],
                                "type": "info",
                                "workflow_context": {
                                    'workflow_step': 'cognitive_processing',
                                    'triggers': ['BDI Agent'],
                                    'workflow_type': 'cognitive_cycle',
                                    'cycle_phase': 'perception_orientation_decision_action'
                                },
                                "details": {
                                    "memory_type": "STM",
                                    "file": filename,
                                    "full_content": data['content']
                                }
                            })
    except Exception as e:
        logger.error(f"Error reading AGInt memory: {e}")
    
    # Get AGInt cognitive cycle logs for workflow tracking
    try:
        agint_log_file = "data/logs/agint/agint_cognitive_cycles.log"
        if os.path.exists(agint_log_file):
            with open(agint_log_file, 'r') as f:
                lines = f.readlines()
                for line in lines[-5:]:  # Last 5 lines
                    if line.strip():
                        activities.append({
                            "timestamp": time.time(),
                            "agent": "AGInt Core",
                            "message": line.strip(),
                            "type": "info",
                            "workflow_context": {
                                'workflow_step': 'cognitive_cycle',
                                'triggers': ['User Directive'],
                                'workflow_type': 'poda_cycle',
                                'cycle_phase': 'perception_orientation_decision_action'
                            }
                        })
    except Exception as e:
        logger.error(f"Error reading AGInt logs: {e}")
    
    # Get Simple Coder activities - including pending requests with workflow context
    try:
        # Check for pending update requests
        simple_coder_requests = await get_simple_coder_update_requests()
        if simple_coder_requests and len(simple_coder_requests) > 0:
            activities.append({
                "timestamp": time.time(),
                "agent": "Simple Coder",
                "message": f"Generated {len(simple_coder_requests)} pending update requests",
                "type": "info",
                "workflow_context": {
                    'workflow_step': 'code_generation',
                    'triggered_by': 'BDI Agent',
                    'triggers': ['User Approval'],
                    'workflow_type': 'code_evolution',
                    'status': 'awaiting_approval'
                },
                "details": {
                    "pending_requests": len(simple_coder_requests),
                    "requests": simple_coder_requests[:3]  # First 3 requests for details
                }
            })
        
        # Get Simple Coder status
        simple_coder_status = await get_simple_coder_status()
        if simple_coder_status:
            activities.append({
                "timestamp": time.time(),
                "agent": "Simple Coder",
                "message": f"Status: {simple_coder_status.get('status', 'Unknown')} - {simple_coder_status.get('message', 'No recent activity')}",
                "type": "success" if simple_coder_status.get('status') == 'active' else "warning",
                "workflow_context": {
                    'workflow_step': 'agent_status',
                    'triggered_by': 'BDI Agent',
                    'workflow_type': 'code_evolution',
                    'status': simple_coder_status.get('status', 'unknown')
                }
            })
        
        # Get Simple Coder log activities
        simple_coder_log = "data/logs/simple_coder.log"
        if os.path.exists(simple_coder_log):
            with open(simple_coder_log, 'r') as f:
                lines = f.readlines()
                for line in lines[-3:]:  # Last 3 lines
                    if line.strip():
                        activities.append({
                            "timestamp": time.time(),
                            "agent": "Simple Coder",
                            "message": line.strip(),
                            "type": "info",
                            "workflow_context": {
                                'workflow_step': 'code_execution',
                                'triggered_by': 'BDI Agent',
                                'workflow_type': 'code_evolution'
                            }
                        })
    except Exception as e:
        logger.error(f"Error reading Simple Coder activities: {e}")
    
    # Get Coordinator Agent activities
    try:
        # Check if coordinator is available through command_handler
        if command_handler and hasattr(command_handler, 'mastermind') and command_handler.mastermind.coordinator_agent:
            activities.append({
                "timestamp": time.time(),
                "agent": "Coordinator Agent",
                "message": "Infrastructure management and autonomous improvement active",
                "type": "success",
                "workflow_context": {
                    'workflow_step': 'infrastructure_management',
                    'triggers': ['MastermindAgent'],
                    'workflow_type': 'system_orchestration',
                    'status': 'active'
                },
                "details": {
                    "capabilities": ["Infrastructure Management", "Autonomous Improvement", "Component Evolution"],
                    "ethereum_address": "0x7371e20033f65aB598E4fADEb5B4e400Ef22040A"
                }
            })
    except Exception as e:
        logger.error(f"Error getting Coordinator Agent status: {e}")
    
    # Get MastermindAgent activities
    try:
        if command_handler and hasattr(command_handler, 'mastermind'):
            activities.append({
                "timestamp": time.time(),
                "agent": "MastermindAgent",
                "message": "Strategic orchestration with Mistral AI reasoning active",
                "type": "success",
                "workflow_context": {
                    'workflow_step': 'strategic_orchestration',
                    'triggers': ['User Commands', 'System Events'],
                    'workflow_type': 'system_coordination',
                    'status': 'active'
                },
                "details": {
                    "capabilities": ["Strategic Orchestration", "Mistral AI Reasoning", "Agent Coordination"],
                    "ethereum_address": "0xb9B46126551652eb58598F1285aC5E86E5CcfB43"
                }
            })
    except Exception as e:
        logger.error(f"Error getting MastermindAgent status: {e}")
    
    # Get workflow-specific activities
    try:
        # Add workflow tracking activities
        workflow_activities = [
            {
                "timestamp": time.time(),
                "agent": "Workflow Monitor",
                "message": "AGInt → BDI → Simple Coder workflow active",
                "type": "info",
                "workflow_context": {
                    'workflow_step': 'workflow_monitoring',
                    'workflow_type': 'cognitive_code_evolution',
                    'active_workflows': ['AGInt_BDI_SimpleCoder', 'Mastermind_Coordinator_BDI']
                }
            },
            {
                "timestamp": time.time() - 30,
                "agent": "Workflow Monitor",
                "message": "Coordinator Agent managing infrastructure improvements",
                "type": "info",
                "workflow_context": {
                    'workflow_step': 'infrastructure_improvement',
                    'triggered_by': 'MastermindAgent',
                    'workflow_type': 'autonomous_improvement'
                }
            }
        ]
        activities.extend(workflow_activities)
    except Exception as e:
        logger.error(f"Error getting workflow activities: {e}")
    
    # Get dynamic agent list and their activities
    try:
        # Get all available agents from the system
        agents_response = await get_agents()
        if agents_response and 'agents' in agents_response:
            for agent in agents_response['agents']:
                agent_name = agent.get('name', 'Unknown Agent')
                agent_status = agent.get('status', 'unknown')
                
                # Create activity for each agent with workflow context
                activities.append({
                    "timestamp": time.time(),
                    "agent": agent_name,
                    "message": f"Agent {agent_name} is {agent_status}",
                    "type": "success" if agent_status == "active" else "warning",
                    "workflow_context": {
                        'workflow_step': 'agent_status',
                        'workflow_type': 'system_monitoring',
                        'status': agent_status
                    },
                    "details": {
                        "agent_type": agent.get('type', 'Unknown'),
                        "capabilities": agent.get('capabilities', []),
                        "last_activity": agent.get('lastActivity', 'Unknown')
                    }
                })
    except Exception as e:
        logger.error(f"Error getting dynamic agent list: {e}")
    
    # Sort by timestamp (newest first)
    activities.sort(key=lambda x: x.get('timestamp', 0), reverse=True)
    
    return {
        "status": "success",
        "activities": activities[:30],  # Return last 30 activities
        "total_activities": len(activities),
        "timestamp": time.time(),
        "source": "real_agent_activities_with_workflow",
        "agent_count": len(set(activity.get('agent', 'Unknown') for activity in activities)),
        "workflow_summary": {
            "active_workflows": ["AGInt_BDI_SimpleCoder", "Mastermind_Coordinator_BDI"],
            "workflow_types": ["cognitive_decision", "code_evolution", "system_orchestration"],
            "active_agents": list(set(activity.get('agent', 'Unknown') for activity in activities))
        }
    }

